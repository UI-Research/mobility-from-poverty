---
title: ""
author: ""
date: "`r format(Sys.time(), '%B %d, %Y %H:%M')`"
output:
  html_document:
    number_sections: true
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: !expr here::here("05_local-governance", "www", "web_report.css")
    editor_options:
      chunk_output_type: console
---

<style>
@import url('https://fonts.googleapis.com/css?family=Lato&display=swap');
</style>

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

# Voter Turnout

This metric is a county-level estimate of voter turnout. We use Presidential Election turnout as a measure of "Highest Office" for the numerator. We use the Citizen Voting Age Population (CVAP) for the denominator. 

See the [United States Elections Project](http://www.electproject.org/2016g) for more information.

**Process:**

1. Calculate votes in the 2016 Presidential election
2. Calculate the Citizen Voting Age Population
3. Divide 1. by 2. to calculate voter turnout
4. Add data quality flags
5. Save the data

```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r setup}
options(scipen = 999)

library(tidyverse)
library(urbnthemes)
library(sf)
library(rvest)

set_urbn_defaults(style = "print")

```

## 1. Numerator

### MIT Election Data and Science Lab

We use the MIT Election Data and Science Lab for county-level votes in the 2016 Presidential election ([data here](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ/HEIJCQ&version=6.0)). First, we download the data. 

```{r}
# download the data from the Harvard dataverse
mit_directory <- here::here("05_local-governance", 
                        "voter-turnout", 
                        "mit")

mit_data <- here::here("05_local-governance", 
                        "voter-turnout", 
                        "mit",
                        "countypres_2000-2016.csv")

if (!dir.exists(mit_directory)) {
  
  dir.create(mit_directory)
  
}

if (!file.exists(mit_data)) {
  
  download.file(
    "https://dataverse.harvard.edu/api/access/datafile/3641280?format=original&gbrecs=true",
    destfile = mit_data
  )
  
}

```

Next we load and clean the data. 

```{r}
mit <- read_csv(here::here("05_local-governance", 
                           "voter-turnout", 
                           "mit", 
                           "countypres_2000-2016.csv")) %>%
  # fix the FIPS codes
  mutate(FIPS = str_pad(FIPS, width = 5, pad = "0"))

mit <- mit %>%
  tidylog::filter(year == 2016)

```

There are three localities without FIPS codes. `totalvotes` does not vary for these observations. We elected to drop these observations. 

```{r}
mit %>%
  filter(is.na(FIPS)) %>%
  select(state, county, office, candidate, party, candidatevotes, totalvotes)


mit <- mit %>%
  tidylog::filter(!is.na(FIPS))

```

Bedford County, Virginia is missing for `candidatevotes` and lists `totalvotes` as 0, which is clearly incorrect. We set the zeros to `NA`.

```{r}
mit %>%
  filter(is.na(candidatevotes))

problem_counties <- c("51515") # Bedford County, Virginia

mit <- mit %>%
  mutate(totalvotes = if_else(FIPS %in% problem_counties, as.numeric(NA), totalvotes),
         candidatevotes = if_else(FIPS %in% problem_counties, as.numeric(NA), candidatevotes))

```

Alaska is reported as Districts instead of counties. We drop these. 

```{r}
mit <- mit %>%
  mutate(FIPS = if_else(state == "Alaska", "02000", FIPS))
```

There are five places where the summarized candidate votes don't sum to the county votes. The `candidatevotes` variable looks much more accurate than the summed `total` based on the [NYTimes](https://www.nytimes.com/elections/2016/results/president). 

```{r}
mit %>%
  group_by(state, county, FIPS) %>%
  summarize(candidatevotes = sum(candidatevotes),
            totalvotes = max(totalvotes)) %>%
  filter(totalvotes != candidatevotes) %>%
  ungroup()

```

We sum the candidate votes and create `state` and `county`.

```{r}
mit_counties <- mit %>%
  group_by(year, state, county, FIPS) %>%
  summarize(votes = sum(candidatevotes)) %>%
  ungroup()

# create state and county
mit_counties <- mit_counties %>%
  mutate(state = str_sub(FIPS, 1, 2),
         county = str_sub(FIPS, 3, 5)) %>%
  select(year, 
         state, 
         county,
         votes)
```

We compare the aggregated totals to the state total posted on [Wikipedia](https://en.wikipedia.org/wiki/2016_United_States_presidential_election). This code scrapes the vote count: 

```{r}
# scrape data from Wikipedia with rvest
wiki <- read_html("https://en.wikipedia.org/wiki/2016_United_States_presidential_election")

wiki_votes <- wiki %>%
  html_nodes("td:nth-child(22)") %>%
  html_text() %>%
  # clean numbers as characters to numerics
  str_replace_all(",", "") %>%
  str_replace_all("\n", "") %>%
  as.numeric()

# the name column int he data doesn't scrape well so we manually state it
state <- c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "District of Columbia", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "subset", "subset", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "subset", "subset", "subset", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio",      "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island","South Carolina", "South Dakota", "Tennessee", "Texas", "Utah",      "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming")     

state_votes <- tibble(state, wiki_votes) %>%
  tidylog::filter(state != "subset")

rm(wiki, wiki_votes, state)

```

The totals are very close for most states. Missouri and Washington are problematic. 

```{r}
# compare the scraped data to the mit data
mit_counties %>%
  group_by(state) %>%
  summarize(mit_votes = sum(votes, na.rm = TRUE)) %>%
  bind_cols(state_votes) %>%
  mutate(mit_votes / wiki_votes) %>%
  select(state = state...3, mit_votes, wiki_votes, `mit_votes/wiki_votes`) %>%
  arrange(`mit_votes/wiki_votes`) %>%
  knitr::kable(digits = 3)

```

The aggregated nationwide total is also very close to the 136,669,276 votes reported on Wikipedia. 

```{r}
mit_counties %>%
  summarize(sum(votes, na.rm = TRUE))

```

At this point, the only missing values are Bedford County, Virginia. Alaska is excluded entirely. 

```{r}
mit_counties %>%
  map_dbl(~sum(is.na(.)))

```

## 2. Denominator

The denominator for the analysis should be the total age-eligible citizen population ([data here](https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap.2016.html))

The US Census Bureau creates a special tabulation of the 2012-2016 ACS that includes county-level estimates of the total number of United States citizens 18 years of age or older. They also report estimates for subgroups within counties and for other geographic areas. 

If the data are not downloaded, the we download and unzip the data.

```{r}

cvap_zip <- here::here("05_local-governance", 
                       "voter-turnout",
                       "CVAP_2012-2016_ACS_csv_files.zip")

cvap_data <- here::here("05_local-governance", 
                        "voter-turnout",
                        "CVAP_2012-2016_ACS_csv_files")

if (!file.exists(cvap_data)) {
  
  download.file(url = "https://www2.census.gov/programs-surveys/decennial/rdo/datasets/2016/2016-cvap/CVAP_2012-2016_ACS_csv_files.zip",
                destfile = cvap_zip)
  
  unzip(zipfile = cvap_zip,
        exdir = cvap_data)
    
}

```

Next, we load and clean the data. The variable of interest is `CVAP_EST`.

> CVAP_EST: The rounded estimate of the total number of United States citizens 18 years of age or older for that geographic area and group.

```{r}
cvap <- read_csv(here::here("05_local-governance", 
                            "voter-turnout",
                            "CVAP_2012-2016_ACS_csv_files", 
                            "County.csv"))

cvap <- cvap %>%
  tidylog::filter(LNTITLE == "Total") %>%
  select(-LNTITLE, -LNNUMBER)

cvap <- cvap %>%
  mutate(state = str_sub(string = GEOID, start = 8, end = 9),
         county = str_sub(string = GEOID, start = 10, end = 12))

cvap <- cvap %>%
  tidylog::filter(state != "72") %>%
  select(state, 
         county, 
         cvap = CVAP_EST,
         cvap_moe = CVAP_MOE)

```

## 3. Combine and calculate turnout

We combine the data. The join works for all counties except for Alaska; Kalawao, Hawaii; and Oglala Lakota County, South Dakota. 

```{r}
joined_data <- left_join(cvap, mit_counties, by = c("state", "county"))

anti_join(cvap, mit_counties, by = c("state", "county")) %>%
  count(state)
```

We calculate turnout and the coefficient of variation for the CVAP estimate. 

```{r}
joined_data <- joined_data %>%
  mutate(election_turnout = votes / cvap) %>%
  mutate(cv = cvap_moe / cvap)

```

Several observations have voter turnout above `1`. This is likely because of sampling error in the denominator. We set these values to one and all of these cases will be flagged. 

```{r}
joined_data %>%
  filter(votes > cvap)

joined_data <- joined_data %>%
  mutate(election_turnout = if_else(condition = election_turnout > 1, true = 1, false = election_turnout))

```

**Check:** Is voter turnout bounded by 0 and 1 inclusive

```{r}
stopifnot(
  max(joined_data$election_turnout, na.rm = TRUE) <= 1
)

stopifnot(
  min(joined_data$election_turnout, na.rm = TRUE) >= 0
)

```

```{r}
joined_data %>%
  ggplot(aes(votes, election_turnout)) +
  geom_point(alpha = 0.1) +
  scale_x_log10() +
  scale_y_continuous(limits = c(0, 1),
                     expand = expansion(mult = c(0, 0.1))) +
  scatter_grid() +
  labs(title = "There Isn't Much Relationship Between Turnout and Votes")

joined_data %>%
  ggplot(aes(cvap, election_turnout)) +
  geom_point(alpha = 0.1) +
  scale_x_log10() +
  scale_y_continuous(limits = c(0, 1),
                     expand = expansion(mult = c(0, 0.1))) +
  scatter_grid() +
  labs(title = "There Isn't Much Relationship Between CVAP and Votes")

```

## 4. Quality flags

Except for the cases excluded above, the quality of the numerator does not seem to be a concern. Sampling error in the denominator is definitely a concern for small counties. 

We flag cases with high and very high coefficients of variation in the denominator. 

* `1` No issue
* `2` CV >= 0.05
* `3` CV >= 0.15

There isn't much concensus on critical values for coefficients of variation. We use `0.15` because it is mentioned [A Compass for Understanding and Using American Community Survey Data](https://www.census.gov/content/dam/Census/library/publications/2009/acs/ACSstateLocal.pdf).

>  While there is no hard-andfast rule, for the purposes of this handbook, estimates with CVs of more than 15 percent are considered cause for caution when interpreting patterns in the data.

If anything, a stricter threshold is necessary because the estimates are used in denominators. Thus, we use `0.05` for a `2`. 

```{r}
joined_data <- joined_data %>%
  mutate(
    election_turnout_quality = case_when(
      is.na(election_turnout) ~ as.numeric(NA),
      cv >= 0.15 ~ 3,
      cv >= 0.05 ~ 2,
      TRUE ~ 1
    )
  )

count(joined_data, election_turnout_quality)

```

```{r}
joined_data %>%
  ggplot(aes(factor(election_turnout_quality), election_turnout)) +
  geom_point(alpha = 0.1) +
  scale_y_continuous(limits = c(0, 1),
                     expand = expansion(mult = c(0, 0.1))) +
  scatter_grid() +
  labs(title = "Very High Turnout is Associated with Poor Data Quality")
```

## 5. Save the data

```{r}
# load the 2016 county file
all_counties <- read_csv(here::here("geographic-crosswalks", "data", "county-file.csv")) %>%
  tidylog::filter(year == 2016) %>%
  select(-year)

all_counties <- left_join(all_counties, joined_data, by = c("state", "county"))

all_counties <- all_counties %>%
  select(year, state, county, election_turnout, election_turnout_quality) 

all_counties %>%
  write_csv(here::here("05_local-governance",
                       "voter-turnout",
                       "voter-turnout.csv"))
  
```
