---
title: ""
author: ""
date: "`r format(Sys.time(), '%B %d, %Y %H:%M')`"
output:
  html_document:
    number_sections: false
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: !expr here::here("05_local-governance", "www", "web_report.css")
editor_options:
  chunk_output_type: console
---

<style>
@import url('https://fonts.googleapis.com/css?family=Lato&display=swap');
</style>

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

# Voter Turnout

This metric is a county-level estimate of voter turnout. We use Presidential Election turnout as a measure of "Highest Office" for the numerator. We use the Citizen Voting Age Population (CVAP) for the denominator. 

See the [United States Elections Project](https://www.electproject.org/2020g) for more information.

**Process:**

1. Calculate votes in the 2020 Presidential election
2. Calculate the Citizen Voting Age Population
3. Divide 1. by 2. to calculate voter turnout
4. Add data quality flags
5. Save the data

```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r setup}
options(scipen = 999)

library(tidyverse)
library(urbnthemes)
library(sf)
library(rvest)

set_urbn_defaults(style = "print")

```

## 1. Numerator

### 1.1 MIT Election Data and Science Lab

We use the MIT Election Data and Science Lab for county-level votes in the 2020 Presidential election ([data here](https://dataverse.harvard.edu/file.xhtml?fileId=6104822&version=10.0)). First, we download the data. 

To download the data manually, go to [this link](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ). On the right side of the page, click "Access Dataset" and under "Download Options" select "Original Format ZIP." Complete the License/Data Use Agreement by providing your name, email, institution, and position, and then click "Accept." Once you've downloaded the data, unzip the file and move it into the `05_local-governance/voter-turnout/data/mit` directory.

Alternatively, from the [landing page](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ), scroll down to the file list and right click on the tabular data file (e.g., `countypres_2000-2020.tab` for 2020 - the only other file is an `md` file). Select "Copy Link Address." This link should include a 7 digit string after `fileID=`. Replace the 7 digit string in the `download.file()` command below with the new string (between `datafile/` and `?format=`). This will download the data directly. 

```{r}
# create a data folder for intermediate data files
intermediate_files <- here::here("05_local-governance",
                                 "voter-turnout",
                                 "data")

if (!dir.exists(intermediate_files)) {
  
  dir.create(intermediate_files)
  
}

# download the data from the Harvard dataverse
mit_directory <- here::here("05_local-governance", 
                            "voter-turnout", 
                            "data",
                            "mit")

mit_data <- here::here("05_local-governance", 
                       "voter-turnout",
                       "data",
                       "mit",
                       "countypres_2000-2020.csv")

if (!dir.exists(mit_directory)) {
  
  dir.create(mit_directory)
  
}

if (!file.exists(mit_data)) {
  
  download.file(
    "https://dataverse.harvard.edu/api/access/datafile/6104822?format=original&gbrecs=true",
    destfile = mit_data
  )
  
}

```

Next we load and clean the data. 

```{r}
mit <- read_csv(here::here("05_local-governance", 
                           "voter-turnout", 
                           "data",
                           "mit", 
                           "countypres_2000-2020.csv")) %>%
  # rename the FIPS code variable to match 2016
  rename(FIPS = county_fips)

mit <- mit %>%
  tidylog::filter(year == 2020)

```

[Shannon County, South Dakota (FIPS 46113) changed to Oglala Lakota County, South Dakota (FIPS 46102) in 2015.](https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.html) The MIT data have the correct county name but they do not have the correct FIPS code.

In 2019 there were 3,220 counties in the US including Washington DC and Puerto Rico. In 2020, the Valdez-Cordova Census Area in Alaska (FIPS 02261) has been split into two new Census Areas/FIPS: Copper River Census Area (FIPS 02066) and Chugach Census Area (FIPS 02063), so there are now [3,221 counties.](https://www.esri.com/arcgis-blog/products/arcgis-living-atlas/mapping/acs-2016-2020-updated-boundaries/) However, as discussed later, Alaska is reported as Districts instead of counties, so we standardize the FIPS codes for all Alaska districts to "02000" - thus, we don't need to worry about the county change in Alaska.


```{r}
mit %>%
  filter(FIPS %in% c("46113", "46102"))

mit <- mit %>%
  mutate(FIPS = if_else(FIPS == "46113", "46102", FIPS))

```

There are nine observations without FIPS codes. Five of these observations are District of Columbia, which has a FIPS code of 11001, so we correct the missing FIPS for DC. The other four observations are Rhode Island, where the county name is "FEDERAL PRECINCT." Rhode Island has five counties, all of which are included in the data. The four RI observations where county name is "FEDERAL PRECINCT" all have a `totalvotes` value of 1374. Since I cannot identify which counties these observations should be associated with, and they don't have an exceptionally high number of votes, I elect to drop these observations.

```{r}
mit %>%
  filter(is.na(FIPS)) %>%
  select(state, county_name, office, candidate, party, candidatevotes, totalvotes)
  
mit %>%
  filter(state_po %in% c("DC", "RI"))


mit <- mit %>%
  mutate(FIPS = case_when(county_name == "DISTRICT OF COLUMBIA"  ~ "11001",
                          TRUE ~ FIPS)) %>%
  tidylog::filter(!(state == "RHODE ISLAND" & county_name == "FEDERAL PRECINCT"))

```

There are no missing observations for `candidatevotes` or `totalvotes` and no observations for which `totalvotes` is 0.

```{r}
mit %>%
  filter(is.na(candidatevotes))

mit %>% 
  filter(is.na(totalvotes))

mit %>%
  filter(totalvotes == 0)

```

Alaska is reported as Districts instead of counties. We replace the FIPS codes for all Alaska observations with `02000`. 
```{r}
mit <- mit %>%
  mutate(FIPS = if_else(state == "ALASKA", "02000", FIPS))

mit %>%
  filter(state == "ALASKA") %>%
  select(state, FIPS)

```

Alaska is reported as Districts instead of counties. We replace the FIPS codes for all Alaska districts with "02000"

There are no places where the summarized candidate votes don't sum to the county votes.

```{r}
mit %>%
  group_by(state, county_name, FIPS) %>%
  summarize(candidatevotes = sum(candidatevotes),
            totalvotes = max(totalvotes),
            .groups = 'drop') %>%
  filter(totalvotes != candidatevotes)

```

We sum the candidate votes and create `state` and `county`.

```{r}
mit_counties <- mit %>%
  group_by(year, state, county_name, FIPS) %>%
  summarize(votes = sum(candidatevotes)) %>%
  # the above step isn't necessary because unlike the 2016 data, there are no
  # places in 2020 where the summarized candidate votes don't sum to the total
  # votes. so we could just use `totalvotes`. but leaving this for consistency
  # between years
  ungroup()

# create state and county
mit_counties <- mit_counties %>%
  mutate(state = str_sub(FIPS, 1, 2),
         county = str_sub(FIPS, 3, 5)) %>%
  select(year, 
         state, 
         county,
         votes)
```

We compare the aggregated totals to the state total posted on [Wikipedia](https://en.wikipedia.org/wiki/2020_United_States_presidential_election). This code scrapes the vote count: 

```{r}
# scrape data from Wikipedia with rvest
wiki <- read_html("https://en.wikipedia.org/wiki/2020_United_States_presidential_election")

wiki_votes <- wiki %>%
  html_elements("td:nth-child(20)") %>%
  html_text() %>%
  # clean numbers as characters to numerics
  str_replace_all(",", "") %>%
  str_replace_all("\n", "") %>%
  as.numeric()

# the name column in the data doesn't scrape well so we manually state it
state <- c(state.name[1:8],
           'District of Columbia',
           state.name[9:19],
           rep('subset', 2),
           state.name[20:27],
           rep('subset', 3),
           state.name[28:50]
           )    

state_votes <- tibble(state, wiki_votes) %>%
  tidylog::filter(state != "subset")

rm(wiki, wiki_votes, state)

```

The totals are very close for most states. Missouri and potentially New York are problematic. 

```{r}
# compare the scraped data to the mit data
mit_counties %>%
  group_by(state) %>%
  summarize(mit_votes = sum(votes, na.rm = TRUE)) %>%
  bind_cols(state_votes) %>%
  mutate(mit_votes / wiki_votes) %>%
  select(state = state...3, mit_votes, wiki_votes, `mit_votes/wiki_votes`) %>%
  arrange(`mit_votes/wiki_votes`) %>%
  knitr::kable(digits = 3)

```

The aggregated nationwide total from MIT of 158,476,336 is also very close to the 158,429,631 votes reported on Wikipedia. We have 46,705 more votes than Wikipedia.

```{r}
state_votes %>%
  summarize(sum(wiki_votes))

mit_counties %>%
  summarize(sum(votes, na.rm = TRUE))

```

There are no missing values.

```{r}
mit_counties %>%
  map_dbl(~sum(is.na(.)))

```

## 2. Denominator

The denominator for the analysis should be the total age-eligible citizen population ([data here](https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap.2020.html))

The US Census Bureau creates a special tabulation of the 2016-2020 ACS that includes county-level estimates of the total number of United States citizens 18 years of age or older. They also report estimates for subgroups within counties and for other geographic areas. 

If the data are not downloaded, then we download and unzip the data.

```{r}
cvap_zip <- here::here("05_local-governance", 
                       "voter-turnout",
                       "data",
                       "CVAP_2016-2020_ACS_csv_files.zip")

cvap_data <- here::here("05_local-governance", 
                        "voter-turnout",
                        "data",
                        "CVAP_2016-2020_ACS_csv_files")

if (!file.exists(cvap_data)) {
  
  download.file(url = "https://www2.census.gov/programs-surveys/decennial/rdo/datasets/2020/2020-cvap/CVAP_2016-2020_ACS_csv_files.zip",
                destfile = cvap_zip)
  
  unzip(zipfile = cvap_zip,
        exdir = cvap_data)
  
  file.remove(cvap_zip)  
  
}

```

Next, we load and clean the data. The variable of interest is `cvap_est`.

> cvap_est: The rounded estimate of the total number of United States citizens 18 years of age or older for that geographic area and group.

```{r}
cvap <- read_csv(here::here("05_local-governance", 
                            "voter-turnout",
                            "data",
                            "CVAP_2016-2020_ACS_csv_files", 
                            "County.csv"))

cvap <- cvap %>%
  tidylog::filter(lntitle == "Total") %>%
  select(-lntitle, -lnnumber)

cvap <- cvap %>%
  mutate(state = str_sub(string = geoid, start = 10, end = 11),
         county = str_sub(string = geoid, start = 12, end = 14),
         FIPS = str_c(state, county))

cvap <- cvap %>%
  tidylog::filter(state != "72") %>% # Drop Puerto Rico
  select(state, 
         county, 
         FIPS,
         cvap = cvap_est,
         cvap_moe)

```

## 3. Combine and calculate turnout

We combine the data. The join works for all counties except for counties in Alaska and [Kalawao County, Hawaii (FIPS 15005 which is a judicial district of Maui County (FIPS 15009))](https://en.wikipedia.org/wiki/Kalawao_County,_Hawaii). Alaska is dropped entirely because it doesn't have a coutny that exists in `cvap`.

```{r}
joined_data <- left_join(cvap, mit_counties, by = c("state", "county"))

anti_join(cvap, mit_counties, by = c("state", "county"))

```

We calculate turnout and the standard error for the CVAP estimate. 

```{r}
joined_data <- joined_data %>%
  mutate(
    election_turnout = votes / cvap,
    cvap_se = cvap_moe / 1.645
  ) %>%
  mutate(cv = cvap_se / cvap)

```

Six observations have voter turnout above `1`. This is likely because of sampling error in the denominator. We set these values to one and all of these cases will be flagged. 

```{r}
joined_data %>%
  filter(votes > cvap)

joined_data <- joined_data %>%
  mutate(election_turnout = if_else(condition = election_turnout > 1, true = 1, false = election_turnout))

```

**Check:** Is voter turnout bounded by 0 and 1 inclusive

```{r}
stopifnot(
  max(joined_data$election_turnout, na.rm = TRUE) <= 1
)

stopifnot(
  min(joined_data$election_turnout, na.rm = TRUE) >= 0
)

```

```{r}
joined_data %>%
  ggplot(aes(votes, election_turnout)) +
  geom_point(alpha = 0.1) +
  scale_x_log10() +
  scale_y_continuous(limits = c(0, 1),
                     expand = expansion(mult = c(0, 0.1))) +
  scatter_grid() +
  labs(title = "There Isn't Much Relationship Between Turnout and Votes")

joined_data %>%
  ggplot(aes(cvap, election_turnout)) +
  geom_point(alpha = 0.1) +
  scale_x_log10() +
  scale_y_continuous(limits = c(0, 1),
                     expand = expansion(mult = c(0, 0.1))) +
  scatter_grid() +
  labs(title = "There Isn't Much Relationship Between CVAP and Votes")

```

## 4. Quality flags

Except for the cases excluded above, the quality of the numerator does not seem to be a concern. Sampling error in the denominator is definitely a concern for small counties. 

We flag cases with high and very high coefficients of variation in the denominator. 

* `1` No issue
* `2` CV >= 0.05
* `3` CV >= 0.15

There isn't much consensus on critical values for coefficients of variation. We use `0.15` because it is mentioned [A Compass for Understanding and Using American Community Survey Data](https://www.census.gov/content/dam/Census/library/publications/2009/acs/ACSstateLocal.pdf).

>  While there is no hard-and-fast rule, for the purposes of this handbook, estimates with CVs of more than 15 percent are considered cause for caution when interpreting patterns in the data.

If anything, a stricter threshold is necessary because the estimates are used in denominators. Thus, we use `0.05` for a `2`. 

```{r}
joined_data <- joined_data %>%
  mutate(
    election_turnout_quality = case_when(
      is.na(election_turnout) ~ NA_real_,
      cv >= 0.15 ~ 3,
      cv >= 0.05 ~ 2,
      TRUE ~ 1
    )
  )

count(joined_data, election_turnout_quality)

```

```{r}
joined_data %>%
  ggplot(aes(factor(election_turnout_quality), election_turnout)) +
  geom_point(alpha = 0.1) +
  scale_y_continuous(limits = c(0, 1),
                     expand = expansion(mult = c(0, 0.1))) +
  scatter_grid() +
  labs(title = "Very High Turnout is Associated with Poor Data Quality")
```

## 5. Save the data

```{r}
# load the 2020 county file
all_counties <- read_csv(here::here("geographic-crosswalks", "data", "county-populations.csv")) %>%
  tidylog::filter(year == 2020) %>%
  select(-year)

all_counties <- left_join(all_counties, joined_data, by = c("state", "county"))

all_counties <- all_counties %>%
  mutate(year = 2020) %>%
  select(year, state, county, election_turnout, election_turnout_quality, population) 

all_counties %>%
  select(-population) %>%
  write_csv(here::here("05_local-governance",
                       "voter-turnout",
                       "voter-turnout-2020.csv"))
  
```

## Benchmark against 2016

### Compare turnout

```{r}
turnout2016 <- read_csv(here::here("05_local-governance",
                                   "voter-turnout",
                                   "voter-turnout-2016.csv"))


turnout_combined <- left_join(
  all_counties,
  turnout2016,
  by = c("state", "county"),
  suffix = c("_2020", "_2016")
)

turnout_combined <- turnout_combined %>%
  mutate(change = election_turnout_2020 - election_turnout_2016)

turnout_combined %>%
  ggplot(aes(election_turnout_2016, election_turnout_2020, color = population < 10000)) +
  geom_abline() +
  geom_point(alpha = 0.1) +
  labs(
    title = "Most voter turnouts increased modestly",
    subtitle = "Counties with fewer than 10,000 people in yellow"
  ) +
  coord_equal() +
  scatter_grid()

turnout_combined %>%
  filter(population < 1000000) %>%
  ggplot(aes(population, change)) +
  geom_point(alpha = 0.1) +
  labs(
    title = "Large changes in turnout are in low-population areas",
    subtitle = "Exclusing counties with 1+ million people"
    ) +
  scatter_grid()

turnout_combined %>%
  arrange(desc(abs(change))) %>%
  select(-year_2020, -year_2016)

```

### Compare quality

```{r}
turnout_combined %>%
  count(election_turnout_quality_2016, election_turnout_quality_2020)

```
