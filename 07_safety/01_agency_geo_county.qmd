---
title: "Agencies - County"
author: "Vincent Pancini"
date: "`r format(Sys.time(), '%B %d, %Y %H:%M')`"
output:
  html_document:
    number_sections: false
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    editor_options:
      chunk_output_type: console
---

<style>
@import url('https://fonts.googleapis.com/css?family=Lato&display=swap');
</style>

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />


```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r setup}
options(scipen = 999)

library(tidyverse)
library(tidycensus)
library(skimr)
library(tidylog)
library(urbnthemes)

set_urbn_defaults(style = "print")

```

This file is a prerequisite file to the following files:

* `reported-crime-county-all.Rmd` which creates the county-level metric for reported property crimes per 100,000 people and reported violent crimes per 100,000 people
* `juvenile-arrests-county-all.Rmd` which creates the county-level metric for juvenile arrests per 100,000 juveniles

You must run this file before either of the above files to create either metric at the county-level.

This file pulls in a universe of law enforcement agencies that have reported criminal activity and arrests in 2023. It then joins on county FIPS codes to those agencies. For agencies that serve more than one county, this program assigns a weight to that agency to determine the percentage of activity that should be associated with each county served by that agency. Next, it pulls in population and demographic information from the American Community Survey (ACS). Lastly, it creates several files that are used in the creation of each metric.

The rest of this file is organized as follows:

1. Background and NIBRS Batch Header File download
2. Load and clean NIBRS Batch Header File
3. Join county FIPS codes onto NIBRS agencies that are missing county using Law Enforcement Agency Identifiers Crosswalk
4. Construct county-level population and demographics using ACS
5. Join Batch Header File onto ACS county demographics by county
6. Create county-agency weights
7. Write out data

All data used in this file and to create the two safety metrics are available on Box [here](https://urbanorg.box.com/s/poqnegsa6i74phcdr1eap7tacpe4x1gf). Data stored on Box are only available to Urban Institute researchers.

This file assumes that you have cloned the GitHub repository for this project to your local computer. You can find the project repository [here](https://github.com/UI-Research/mobility-from-poverty) and learn how to clone a repository [here](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository).

## 1. Background and NIBRS Batch Header File download
This program and the safety metrics rely on National Incident-based Reporting System (NIBRS) data. NIBRS is an annual data collection that compiles information on criminal incidents and arrests reported by participating law enforcement agencies. It is a part of the Uniform Crime Reporting Program (UCR) which is administered by the Federal Bureau of Investigation (FBI).

NIBRS data as constructed and formatted by the FBI are stored in a single file. These data are organized by various segment levels (record types). Working with the NIBRS data in its single-file format is difficult. To facilitate use of NIBRS data, criminologist [Jacob Kaplan](https://www.jacobdkaplan.com/) has cleaned and processed the data. We use these data which are available on the [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CIQIVF&version=1.0). (Note that prior to data year 2023, these data were accessed from the National Archive of Criminal Justice Data (NACJD), the criminal justice archive within ICPSR, available [here](https://www.icpsr.umich.edu/web/NACJD/series/128).)

The segment of NIBRS data this file is concerned with is called the Batch Header File (also called the Batch Header Segment). Prior to the 2013 data, the Batch Header information was released as three segments. Due to the NIBRS data rapidly growing in size, the FBI released a single file instead. The Batch Header File identifies individual police agencies by originating agency identifier (ORI). An individual police agency (ORI) will appear in the batch header segment once. It also includes variables for each county served by each agency, which is what we are particularly interested in. The data used for both safety metrics (arrests and crimes) are reported at the agency-level. The purpose of using the Batch Header File is to be able to link the agencies to counties for those metrics.

To learn more about NIBRS data, consult Jacob Kaplan's book titled [Uniform Crime Reporting (UCR) Program Data: An Opinionated Guide to FBI Data](https://ucrbook.com/). For these metrics, the most important thing to know about these data is that most police agencies do not report NIBRS data prior to 2021. In 2019, only 8,500 out of approximately 18,000 police agencies in the United States (covering about 45% of the US population) reported NIBRS data. Instead, agencies primarily reported UCR data for 2020 and before. However, the FBI has moved entirely to NIBRS data starting in 2021 and no longer collects UCR data, which is why we use NIBRS data instead ([source](https://ucrbook.com/nibrs-overview.html)). 

We do not want to use NIBRS data for some years and UCR data for others. However, because of lack of reporting, **there are a lot of missing values prior to 2021 for NIBRS data**. Future updates of the safety metrics may want to include historical NIBRS data back to 2014 and should keep this in mind.

Note that we only use the 2023 Batch Header File, and in past updates, we only used the 2022 Batch Header File for both 2021 and 2022. Using the Batch Header File from each year might be more accurate, but for the most part it won't matter, especially because so few agencies reported through NIBRS prior to 2021. Future updates may consider using the Batch Header Files for each year. Prior to data year 2023 each file was only available separately, but they are now available in a single file via Harvard Dataverse.
    
Manually downloading these data from the Harvard Dataverse is a four-step process, but you will only need to do each of these steps once for the creation of this metric:

  1. Navigate to the Uniform Crime Reporting (UCR) Program Data > National Incident-Based Reporting System (NIBRS) data portal hosted on Harvard Dataverse [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CIQIVF).
  2. Scroll down to `nibrs_batch_header_1991_2023.rds` and select the file [here](https://dataverse.harvard.edu/file.xhtml?fileId=10592187&version=1.0).
  3. Select `Access File`
      + Select `Gzip Archive` under `Download Options`
      + Agree to the Dataset Terms by entering your `Name`, `Email`, `Institution`, `Position`, and answer `How will this data be used`, and then select `Accept` at the bottom of the pop-up
  4. This will download an `.rds` file titled `nibrs_batch_header_1991_2023.rds`. Move this file to the `mobility-from-poverty\07_safety\data` directory after you have cloned the repository for this project from GitHub.


## 2. Load and clean NIBRS Batch Header File
This section reads in and cleans the reporting agency data contained in the Batch Header File.

### 2.1 Get universe of agencies from the 2022 NIBRS Batch Header File
Load Batch Header File
```{r load-bhf, message=FALSE}
batch_header_file_full <- readRDS(here::here("07_safety", "data", "nibrs_batch_header_1991_2023.rds"))

bhf22 <- read_tsv(here::here("07_safety", "data", "38925-0001-Data.tsv"))

```

Filter the file to the appropriate year, select relevant necessary, and rename as necessary. We use the codebook (`ICPSR_38925\DS0001\38925-0001-Codebook-ICPSR`) to determine what each variable represents.
```{r clean-bhf}
batch_header_file <- batch_header_file_full |>
  filter(year==2023) |>
  select(
    ori,
    agency_indicator,
    year,
    state_name = state,
    state_abbreviation,
    city_name,
    core_city,
    fips_county_code_1,
    fips_county_code_2,
    fips_county_code_3,
    fips_county_code_4,
    fips_county_code_5
  ) |>
  # Edit county FIPS codes to have three digits
  mutate(
    across(starts_with("fips_county_code_"),
           ~ str_pad(.x, 3, side = "left", pad = "0"))
  )

```
Change the values for core city indicator from `Y`/`N` to `0`/`1`
```{r}
batch_header_file <- batch_header_file |>
  mutate(
    core_city = case_when(
      core_city=="Y" ~ as.numeric(1),
      core_city=="N" ~ as.numeric(0),
      TRUE ~ NA_real_
    )
  )
```


Clean geography information on the batch header file.
```{r clean-bhf}
# See what states/territories are included
batch_header_file |>
  group_by(state_name, state_abbreviation) |>
  count()

batch_header_file <- batch_header_file |>
  # Remove US territories by name because no FIPS codes
  filter(!state_name %in% c("Guam", "Puerto Rico", "Virgin Islands")) |>
  mutate(
    # The NIBRS data abbreviates Nebraska as "NB" instead of its correct abbreviation "NE"
    state_abbreviation = if_else(state_abbreviation=="NB", "NE", state_abbreviation),
    # Wyoming is also named "Wyoming V2" but it is unclear why
    state_name = if_else(state_name=="Wyoming V2", "Wyoming", state_name)
  )

```

The batch header file identifies state by name and abbreviation, but not state FIPS code. We manually add on state FIPS codes to the batch header file
```{r}
# Create crosswalk of state FIPS codes to state names/abbreviations
state_fips_xw <- tribble(
  ~state_fips, ~state_abbreviation, ~state_name,
  "01",	"AL", "Alabama",
  "02",	"AK", "Alaska",
  "04",	"AZ", "Arizona", 
  "05",	"AR", "Arkansas",	
  "06",	"CA", "California",	
  "08",	"CO", "Colorado",
  "09",	"CT", "Connecticut",
  "10",	"DE", "Delaware",
  "11",	"DC", "District of Columbia",
  "12",	"FL", "Florida",
  "13",	"GA", "Georgia",	
  "15",	"HI", "Hawaii",
  "16",	"ID", "Idaho",
  "17",	"IL", "Illinois",
  "18",	"IN", "Indiana",
  "19",	"IA", "Iowa",	
  "20",	"KS", "Kansas",	
  "21",	"KY", "Kentucky",	
  "22",	"LA", "Louisiana",
  "23",	"ME", "Maine",
  "24",	"MD", "Maryland",
  "25",	"MA", "Massachusetts",
  "26",	"MI", "Michigan",	
  "27",	"MN", "Minnesota",	
  "28",	"MS", "Mississippi",	
  "29",	"MO", "Missouri",	
  "30",	"MT", "Montana",	
  "31",	"NE", "Nebraska",	
  "32",	"NV", "Nevada",	
  "33",	"NH", "New Hampshire",	
  "34",	"NJ", "New Jersey",	
  "35",	"NM", "New Mexico",	
  "36",	"NY", "New York",	
  "37",	"NC", "North Carolina",
  "38",	"ND", "North Dakota",	
  "39",	"OH", "Ohio",	
  "40",	"OK", "Oklahoma",	
  "41",	"OR", "Oregon",	
  "42",	"PA", "Pennsylvania",	
  "44",	"RI", "Rhode Island",	
  "45",	"SC", "South Carolina",	
  "46",	"SD", "South Dakota",
  "47",	"TN", "Tennessee",
  "48",	"TX", "Texas",	
  "49",	"UT", "Utah",	
  "50",	"VT", "Vermont",	
  "51",	"VA", "Virginia",	
  "53",	"WA", "Washington",	
  "54",	"WV", "West Virginia",	
  "55",	"WI", "Wisconsin",	
  "56",	"WY", "Wyoming"
)

# Join state FIPS codes onto the batch header file
batch_header_file <- batch_header_file |> 
  tidylog::left_join(
    y = state_fips_xw, by = c("state_name", "state_abbreviation")
  )

# Remove crosswalk
rm(state_fips_xw)

```


### 2.3 Exclude state police and other state agencies
Check distribution of agency types. There are 7 types of agencies. Note that I'm not sure what an agency indicator of "5" represents, and I can't find any information about it in the [available documentation](https://ucrbook.com/). In data year 2022, a value of 4 represented "special agencies" (last year's values shown below), so it could be an error in the pre-processing of this data. 

| Value | Label                     |
|:-----:|:--------------------------|
|   0   | Covered by another agency |
|   1   | City                      |
|   2   | County                    |
|   3   | University or college     |
|   4   | State Police              |
|   5   | Special Agency            |
|   6   | Other state agencies      |
|   7   | Tribal agencies           |
|   8   | Federal agencies          |

```{r count-agency-types}
batch_header_file |>
  count(agency_indicator) |>
  mutate(percent = n/nrow(batch_header_file))

```

State agencies cover multiple counties, so we remove these agencies for simplicity. Note that in data year 2022, we also removed "other state agencies" but that isn't a category in data year 2023. They could be included in the new "other agencies" category, but I'm not sure how to be certain, so leaving this category for now.
```{r remove-state-agencies}
batch_header_file <- batch_header_file |>
  filter(!agency_indicator %in% c("state police"))

```

376 observations have a missing county FIPS value in 2023.
```{r check-missing-county}
# Subset data to examine further
bhf_missing_county <- batch_header_file |>
  filter(is.na(fips_county_code_1))

```


## 3. Join county FIPS codes onto NIBRS agencies that are missing county using Law Enforcement Agency Identifiers Crosswalk

The goal of this section is to match a county FIPS code onto every agency in the 2022 NIBRS Batch Header File. The Batch Header File already includes a county FIPS code for each county associated with a place, but we just showed that 260 agencies still do not have a county associated with them. We attempt to get county information for these agencies using the Law Enforcement Agency Identifiers Crosswalk (LEAIC).

### 3.1 Background on LEAIC and manual download
To address the agencies that are missing county information, we use the 2012 Law Enforcement Agency Identifiers Crosswalk (LEAIC)

The LEAIC facilitates linking reported crime data with socio-economic data. The LEAIC file is available for download from the National Archive of Criminal Justice Data (NACJD) available through ICPSR at the following link:

  * [LEAIC](https://www.icpsr.umich.edu/web/NACJD/studies/35158)
  
Note that 2012 is the most recent year for which this crosswalk is available. This may present issues in harmonizing data across years, because some counties have changed since 2012. Future updates should check if a more recent crosswalk is available yet.
  
Accessing these data requires an ICPSR account. Manually downloading these data is a five-step process, but you will only need to do each of these steps once for the creation of this metric:

  1. Create an ICPSR account [here](https://www.icpsr.umich.edu/cgi-bin/newacct).
  2. Navigate to the National Archive of Criminal Justice Data (NACJD) landing page for the LEAIC [here](https://www.icpsr.umich.edu/web/NACJD/studies/35158)).
  3. Select `Download`
      + Select `Delimited`
      + Select `Agree` on the `Terms of Use`
  4. Sign into your ICPSR account
  5. This will download a zip file titled `ICPSR_35158-V2`. Unzip the file and navigate to `ICPSR_35158\DS0001\35158-0001-Data.tsv`. Move this file to the `mobility-from-poverty\07_safety\data` directory after you have cloned the repository for this project from GitHub.

### 3.2 Load and clean LEAIC
After downloading the LEAIC, read it in. This file has a county FIPS linked to every reporting agency.
```{r load-leaic}
# Read in crosswalk
leaic <- read_tsv(here::here("07_safety", "data", "35158-0001-Data.tsv"))

```

324 of the 376 agencies with missing county information from the Batch Header File are in the LEAIC.
```{r check-missing}
# Check how many agencies with missing county are in LEAIC
sum(bhf_missing_county$ori %in% leaic$ORI9)

```

Limit file to necessary variables and rename. We use the codebook (`ICPSR_35158\DS0001\35158-0001-Codebook`) to determine what each variable represents.
```{r clean-leaic}
leaic <- leaic |>
  select(
    ori = ORI9,
    # state = FIPS_ST,
    county = FIPS_COUNTY
  ) |>
  # Remove agencies with invalid ORI
  filter(ori != "-1") # Not in UCR/NCIC 

```

### 3.3 Join LEAIC onto NIBRS data with missing counties by agency identifier
Join the LEAIC to the 2023 NIBRS Batch Header File by agency.
52 agencies still have no county after using the county information from LEAIC. Most of these observations are tribal or other agencies.
```{r join-missing-bhf-leaic}
bhf_missing_county <- left_join(
  x = bhf_missing_county |>
    select(-starts_with("fips_county_code")),
  y = leaic,
  by = c("ori")
)

bhf_missing_county |>
  filter(is.na(county)) |>
  count(agency_indicator)

```

### 3.4 Use LEAIC to create final agency-county data
Replace county information in NIBRS data for observations that initially had a missing county value of with the updated county information from LEAIC.
```{r replace-counties}
batch_header_file <- batch_header_file %>%
  # Drop the 376 NIBRS agencies with a missing county value
  filter(!is.na(fips_county_code_1)) %>%
  # Append those 376 agencies back onto main data with the county info gleaned from LEAIC
  bind_rows(bhf_missing_county)

batch_header_file <- batch_header_file |>
  # Drop the 54 NIBRS agencies that had no county info in LEAIC
  # filter(!is.na(county)) %>%
  # Assign county fips from LEAIC to the NIBRS county fips variable
  mutate(fips_county_code_1 = if_else(
    is.na(fips_county_code_1) & !is.na(county),
    county,
    fips_county_code_1
  )
  ) |>
  select(-county)


# Remove obsolete files
#rm(leaic, bhf_missing_county)

```


## 4. Construct county-level population and demographics using ACS
Recall that this file serves as a precursor file to the files that create both of our metrics, which are:

* Reported violent crimes per 100,000 people and reported property crimes per 100,000 people
* Juvenile arrests per 100,000 juveniles

Additionally, for the juvenile arrests metric, we are interested in subgroups by age, race, and sex. To calculate these rates (both total and by subgroup), we need total population and demographic information for our denominators. We pull total population and demographic data from the 5-year ACS files for each year 2021-2022.

This section relies on the `tidycensus` package, which requires a Census API key. You can acquire a key [here](https://api.census.gov/data/key_signup.html) and learn more about installing your key [here](https://walker-data.com/tidycensus/reference/census_api_key.html). Replace `[YOUR-KEY-HERE]` in the code below with your Census API key (leave the quotation marks).
```{r set-api-key}
# set Census API once
# tidycensus::census_api_key("[YOUR-KEY-HERE]", install=TRUE, overwrite = TRUE)

```

### 4.1 Check ACS variable names and identify those we need
Load ACS variables for our first and last years. Manually explore each file and spot check several observations. The naming conventions of ACS variables do not seem to change during our time period.
Note that if they did we would need to split up the code that reads in the years below.
Note that future updates of the safety metrics may want to pull data back to 2014, in which case the first year should be changed below.
```{r check-acs-variables}
# Check ACS variables for the first and last years to see if they change over time
#variables_fy <- tidycensus::load_variables(2021, "acs5")
variables_ly <- tidycensus::load_variables(2023, "acs5")

test <- variables_ly |> filter(name %in% c("B01003_001", "B01001_005", "B01001_006", "B01001_029", "B01001_030", "B01001A_005", "B01001B_005", "B01001C_005", "B01001D_005", "B01001E_005"))

rm(test)

```

### 4.2 Create vectors for years and variables of interest
Note that the `two or more race` variable is not appearing and may not be available at the county level.
Note that if additional subgroups for either safety metric are desired in future updates, the variables pulled here may need updated.
Note that future updates of the safety metrics may want to pull data back to 2014, in which case the list of years should be changed below.
```{r specify-acs-years-vars}
# Create a list of all our years
# years <- lst(2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023)
years <- lst(2023)

# Create a vector for our ACS variables of interest
my_vars <- c(
  total_people = "B01003_001",
  age_m_1014 = "B01001_005", 
  age_m_1517 = "B01001_006",
  age_f_1014 = "B01001_029", 
  age_f_1517 = "B01001_030",
  age_m_1014_white = "B01001A_005", 
  age_m_1014_black = "B01001B_005",
  age_m_1014_aian = "B01001C_005", 
  age_m_1014_asin = "B01001D_005",
  age_m_1014_nhpi = "B01001E_005", 
  age_m_1014_othr = "B01001F_005",
  age_m_1014_twom = "B01001G_005",
  age_m_1014_white_nh = "B01001H_005",
  age_m_1014_hispanic = "B01001I_005",
  age_m_1517_white = "B01001A_006", 
  age_m_1517_black = "B01001B_006",
  age_m_1517_aian = "B01001C_006", 
  age_m_1517_asin = "B01001D_006",
  age_m_1517_nhpi = "B01001E_006", 
  age_m_1517_othr = "B01001F_006",
  age_m_1517_twom = "B01001G_006",
  age_m_1517_white_nh = "B01001H_006", 
  age_m_1517_hispanic = "B01001I_006",
  age_f_1014_white = "B01001A_020", 
  age_f_1014_black = "B01001B_020",
  age_f_1014_aian = "B01001C_020", 
  age_f_1014_asin = "B01001D_020",
  age_f_1014_nhpi = "B01001E_020", 
  age_f_1014_othr = "B01001F_020",
  age_f_1014_twom = "B01001G_020",
  age_f_1014_white_nh = "B01001H_020",
  age_f_1014_hispanic = "B01001I_020",
  age_f_1517_white = "B01001A_021", 
  age_f_1517_black = "B01001B_021",
  age_f_1517_aian = "B01001C_021", 
  age_f_1517_asin = "B01001D_021",
  age_f_1517_nhpi = "B01001E_021",
  age_f_1517_othr = "B01001F_021",
  age_f_1517_twom = "B01001G_021",
  age_f_1517_white_nh = "B01001H_021", 
  age_f_1517_hispanic = "B01001I_021"
)

```

### 4.3 Pull 5-year ACS data for all years 2021-2022 at the county level
Pull 5-year ACS data at the county level for each year
```{r load-acs-data}
# Pull data
county_demo_full <- map_dfr(
  years,
  ~ tidycensus::get_acs(
    geography = "county",
    variables = my_vars,
    year = .x,
    survey = "acs5",
    output = "wide",
    geometry = FALSE
  ),
  # Create a year variable for each year
  .id = "year"
)

# Remove Puerto Rico from ACS data
county_demo <- county_demo_full |>
  mutate(state = substr(GEOID, 1, 2)) |>
  filter(state != "72")

# Remove obsolete files
rm(variables_fy, variables_ly, years, my_vars)

```


### 4.4 Clean ACS data
Clean variable names and drop margins of error
```{r clean-acs-data}
county_demo <- county_demo |>
  rename_with(~ sub("E$", "", .x), everything()) |>
  select(-c(ends_with("M")))

```

#### 4.4a Construct subgroups for race/ethnicity, sex, and age subgroups
For the rate of juvenile arrests per 100,000 juveniles metric, we want subgroups by race, sex, and age subgroups. These are subgroups of all observations ages 10-17, so the sum of each subgroup should equal the total number of observations ages 10-17.

  * Race: white, Black, Hispanic, Asian/other
  * Sex: male, female
  * Age: ages 10-14, ages 15-17

Note that there is a Non-Hispanic white category, but not a Non-Hispanic category for other races (Black, Asian, etc.). This means that the categories will have a small but non-zero overlap. The race/ethnicity categories actually used in the `juvenile-arrests` metric are white, Black, Asian/other, and Hispanic. These are not mutually exclusive (e.g., someone could be counted as both Black and Hispanic), which matches the population denominators created here (this is because ACS doesn't have counts of non-Hispanic Black or other non-Hispanic races other than white).
```{r create-subgroups}
# Create the total for ages 10-17 and the race, sex, and age subgroups
county_demo <- county_demo |>
  mutate(
    # Total age 10-17
    age_1017 = age_m_1014 + age_m_1517 + age_f_1014 + age_f_1517,
    # Race subgroups
    age_1017_white = age_m_1014_white + age_m_1517_white + age_f_1014_white + age_f_1517_white,
    age_1017_black = age_m_1014_black + age_m_1517_black + age_f_1014_black + age_f_1517_black,
    age_1017_aian = age_m_1014_aian + age_m_1517_aian + age_f_1014_aian + age_f_1517_aian,
    age_1017_asin = age_m_1014_asin + age_m_1517_asin + age_f_1014_asin + age_f_1517_asin,
    age_1017_nhpi = age_m_1014_nhpi + age_m_1517_nhpi + age_f_1014_nhpi + age_f_1517_nhpi,
    age_1017_othr = age_m_1014_othr + age_m_1517_othr + age_f_1014_othr + age_f_1517_othr,
    # age_1017_twom = age_m_1014_twom + age_m_1517_twom + age_f_1014_twom + age_f_1517_twom,
    age_1017_hispanic = age_m_1014_hispanic + age_m_1517_hispanic + age_f_1014_hispanic + age_f_1517_hispanic,
    age_1017_white_nh = age_m_1014_white_nh + age_m_1517_white_nh + age_f_1014_white_nh + age_f_1517_white_nh,
    # Sex subgroups
    sex_1017_m = age_m_1014 + age_m_1517,
    sex_1017_f = age_f_1014 + age_f_1517,
    # Age subgroups
    age_1014_all = age_m_1014 + age_f_1014,
    age_1517_all = age_m_1517 + age_f_1517
  )

# Edit race variables  
county_demo <- county_demo |>  
  mutate(
    # Manually create "two or more" race variable
    age_1017_twom = age_1017 - age_1017_white - age_1017_black - 
      age_1017_aian - age_1017_asin - age_1017_nhpi - age_1017_othr,
    # Combine all asian races, other races, and two or more races
    age_1017_asian_other = age_1017_aian + age_1017_asin + age_1017_nhpi +
      age_1017_othr + age_1017_twom
  )
  
```

Limit ACS data to relevant variables
```{r limit-acs-vars}
# Limit to relevant variables
county_demo <- county_demo |>
  select(year, GEOID, total_people, starts_with("age_1017"), starts_with("sex_1017"), ends_with("_all"))

```

Test that construction of each subgroup worked as expected
```{r test-race}
stopifnot(
  rowSums(select(county_demo, matches("age_1017_asian_other|age_1017_white$|age_1017_black")), na.rm = T) == county_demo$age_1017
)

```

```{r test-age}
stopifnot(
  rowSums(select(county_demo, matches("age_1517_all|age_1014_all")), na.rm = T) == county_demo$age_1017
)

```

```{r test-sex}
stopifnot(
  rowSums(select(county_demo, matches("sex_1017_m|sex_1017_f")), na.rm = T) == county_demo$age_1017
)

```



## 5. Join Batch Header File onto ACS county demographics by county

### 5.1 Reshape BHF to be long by agency and county
The NIBRS batch header file is currently long by `ori` (agency), such that there is one observation for each agency. These agencies have variables that contain county FIPS codes for each of the counties that agency serves. 

692 agencies cover 2 counties, 69 agencies cover 3 counties, 10 agencies cover 4 counties, 0 agencies cover 5 counties
```{r check-agencies-multiple-counties}
sum(!is.na(batch_header_file$fips_county_code_2))
sum(!is.na(batch_header_file$fips_county_code_3))
sum(!is.na(batch_header_file$fips_county_code_4))
sum(!is.na(batch_header_file$fips_county_code_5))

```

We reshape the data to be long by `ori` and `county` such that each observation represents each unique `ori` and `county` pair.
```{r reshape-bhf}
# Reshape NIBRS data to be long by agency AND county
batch_header_file_long <- batch_header_file |>
  pivot_longer(
    cols = starts_with("fips_county_code_"),
    values_to = "fips_county_code"
  ) |>
  # Remove observations that are not relevant to more that one county
  drop_na(fips_county_code) |>
  select(-c(name))
  
  #mutate(across(starts_with("fips"), ~str_pad(., 3, pad = "0"))) |>
  select(c(ori, agency_indicator, core_city, starts_with("state"), starts_with("fips"))) |>
  pivot_longer(-c(ori, core_city), values_to = "county")


batch_header_file <- batch_header_file |>
  filter(!is.na(county))

```

### 5.2 Join the NIBRS data (Batch Header File) onto the ACS county population and demographics
Join agency/county pairs onto the ACS county/year-level population and demographics
```{r join-acs-bhf}
# Create GEOID
batch_header_file_long <- batch_header_file_long |>
  mutate(GEOID = str_c(state_fips, fips_county_code))

# Join data
joined_data <- left_join(
  x = county_demo |> 
    select(year, GEOID, total_people),
  y = batch_header_file_long,
  by = "GEOID"
)

```

#### 5.2a Investigate unmatched observations
##### 5.2a.i Observations in pooled ACS data but not in the 2023 Batch Header File
7 observations are in the pooled ACS data but not in the 2023 Batch Header File.
```{r check-unmatched-bhf}
test <- anti_join(
  x = county_demo,
  y = batch_header_file_long, 
  by = c("GEOID")
)

# Check which states the unmatched observations come from
test |>
  mutate(state = substr(GEOID, 1, 2)) |>
  group_by(state) |>
  count()

```

6 of the unmatched observations that are in the ACS but not the Batch Header File are from Alaska, and 1 is from Hawaii.
    Note that Connecticut adopted the state's nine Councils of Government as the county-equivalent geographic unit, and this change is reflected in ACS data products for the first time in 2022 ([source](https://www.census.gov/programs-surveys/acs/technical-documentation/table-and-geography-changes/2022/geography-changes.html)). This update to the safety metric ignores this change for now, but future updates may be interested in harmonizing Connecticut counties across years. [These relationship files](https://www.census.gov/geographies/reference-files/time-series/geo/relationship-files.html) may (or may not) be helpful in accomplishing that task.
```{r check-unmatched-bhf-2}
test |>
  mutate(state = substr(GEOID, 1, 2)) |>
  filter(state == "09") |>
  group_by(state, year) |>
  count()

```

Note that Kalawao County, HI is the smallest county in the 50 states by land area and the second-smallest county by population. Because of the small population, it does not have the same functions as other Hawaii counties and is instead a judicial district of Maui County. It is entirely plausible that this county is missing from the Batch Header File because it does not have any police agencies, or if it does, the agencies have not reported NIBRS data. We ignore these observations.
```{r check-unmatched-bhf-3}
test |>
  mutate(state = substr(GEOID, 1, 2)) |>
  filter(state == "15") |>
  group_by(GEOID, year) |>
  count(total_people)

```

The remaining unmatched observations that are in the ACS but not the Batch Header File are from Alaska. There are 6 observations for 2021 and 6 observations for 2022. [This documentation](https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.2010.html#list-tab-957819518) explains the following changes to counties in Alaska that account for 4/12 of these unmatched observations.

  * Chugach Census Area (02063) was created from part of former Valdez-Cordova Census Area (02261) effective January 02, 2019
  * Copper River Census Area (02066) was created from part of former Valdez-Cordova Census Area (02261) effective January 02, 2019
    
Note that future updates may want to account for the change to these counties. 

The other 8/12 unmatched observations are from the following counties: Denali Borough (02068), Lake and Peninsula Borough (02164), Southeast Fairbanks Census Area (02240), and the City and Borough of Yakutat (02282). Note that all four of these counties have very small populations. It is entirely plausible that these counties are missing from the Batch Header File because they do not have any police agencies, or if they do, the agencies have not reported NIBRS data. We ignore these observations.
```{r check-unmatched-bhf-4}
test |>
  mutate(state = substr(GEOID, 1, 2)) |>
  filter(state == "02") |>
  group_by(GEOID, year) |>
  count(total_people)

```

##### 5.2a.ii Observations in the 2022 Batch Header File but not in the pooled ACS data
9 observations are in the 2022 Batch Header File but not the pooled ACS data.
```{r check-unmatched-acs}
rm(test)

test <- anti_join(
  x = batch_header_file_long,
  y = county_demo,
  by = c("GEOID")
)

# Check which counties the unmatched observations come from
test |>
  group_by(GEOID) |>
  count()

```

3/5 of the unmatched observations that are in the 2022 Batch Header File but not the pooled ACS data are from Valdez-Cordova Census Area, Alaska (02261). [This documentation](https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.2010.html#list-tab-957819518) explains that Valdez-Cordova Census Area was split into Chugach Census Area, Alaska (02063) and Copper River Census Area (02066) effective January 02, 2019. It appears that at least some of the 2022 Batch Header File agencies have not accounted for this change. Note that future updates may want to account for the change to this county, but we ignore these observations for now.

2/5 of the unmatched observations that are in the 2022 Batch Header File but not the pooled ACS data are from Shannon County, South Dakota (46113). [This documentation](https://www.census.gov/programs-surveys/geography/technical-documentation/county-changes.2010.html#list-tab-957819518) explains that Shannon County, SD changed its name and FIPS code to Oglala Lakota County (46102) effective May 1, 2015. We correct the 2023 Batch Header File for this change below
```{r check-unmatched-acs-2}
batch_header_file_long <- batch_header_file_long |>
  mutate(
    fips_county_code = ifelse(state_fips=="46" & fips_county_code=="113", "102", fips_county_code),
    GEOID = ifelse(state_fips=="46"& GEOID=="46113", "46102", GEOID)
    )

```

#### 5.2b Re-join the NIBRS data (Batch Header File) onto the ACS county population and demographics after harmonizing county changes over time
```{r rejoin-acs-bhf}
# Join data
joined_data <- left_join(
  x = county_demo |> 
    select(year, GEOID, total_people),
  y = batch_header_file_long |>
    mutate(year = as.character(year)),
  by = c("GEOID", "year")
)

```


## 6. Create county-agency weights
For agencies that cover multiple counties, assign weight based on county population (e.g., if Agency A has jurisdiction in both County 1 which has 10,000 people and County 2 which has 5,000 people, the weights will be 0.667 and 0.333, respectively).
```{r create-agency-weights}
# Make agency weights based on population of counties they cover
joined_data <- joined_data |>
  filter(!is.na(total_people)) |>  
  group_by(year, ori) |>
  mutate(
    weight = total_people / sum(total_people),
    weight = if_else(is.na(ori), NA, weight)
  ) |>
  ungroup()

```


Count number of agencies in each county.
```{r count-agencies-in-counties}
county_agency <- joined_data |>
  group_by(GEOID, year) |>
  summarize(
    n_agencies = n_distinct(ori),
    n_wt = sum(weight),
    n_core_city = sum(core_city==1),
    core_city = max(core_city),
    #n_agen_city = sum(agency_type==1),
    #n_agen_cnty = sum(agency_type==2),
    #n_agen_univ = sum(agency_type==3),
    #n_agen_spcl = sum(agency_type==5),
   # n_agen_trbl = sum(agency_type==7)
  ) |>
  ungroup()

```


## 7. Write out data

Write out county demographics only
```{r write-county-demos}
write_csv(county_demo, file = here::here("07_safety", "data", "all_county_demo.csv"))

```

Write out county demographics plus agency info
```{r write-county-demos-agency}
# Join these data
county_demo_agency <- left_join(
  x = county_demo,
  y = county_agency, 
  by = c("year", "GEOID")
)

# Write out
write_csv(county_demo_agency, file = here::here("07_safety", "data", "all_county_demo_agency.csv"))

```

Write out agency-county level file with weights
```{r write-weights}
write_csv(joined_data, file = here::here("07_safety", "data", "all_agency_county.csv"))

```

