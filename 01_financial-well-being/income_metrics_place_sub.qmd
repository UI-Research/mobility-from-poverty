---
title: "Opportunity for Income Predictor, place-level, subgroups"
author: "JP Walsh"
date: today
format:
  html:
    toc: true
    toc_float: true
    embed-resources: true
    code-fold: show
execute: 
  warning: false
editor_options: 
  chunk_output_type: console
---

*Program for the creation of the Opportunity for Income Predictor at the place level for subgroups*

ACS Code: Initially written by Tina Chelidze and updated by JP Walsh 2022-2023.

Primary data derived from the IPUMS API.

Based on processes developed by Paul Johnson and Kevin Werner in SAS.

*User warnings* 

    + The ACS micro data used to create this metric is large and will take time to read in. It is strongly recommended that you use a server with large computing power to run this.
     + Please check that no folders in the filepath that you have cloned this repostiory to include the acronym "UMF" - this will throw an error from the extract_ipums function. To check your file path you can use the function here::here().

## Housekeeping

Read in packages for use. If you do not have an IPUMS API key you will need to make one via the [IPUMS website](https://www.ipums.org/).

```{r}
library(tidyverse)
library(Hmisc)
library(ipumsr)
library(reactable)
library(srvyr)
library(scales)

options(scipen = 999)

theme_set(theme_minimal())

# DO NOT PUSH YOUR API KEY. You only have to run this once and then comment it out as below.
#set_ipums_api_key("Your KEY", save = TRUE)

source(here::here("functions", "API", "extract_ipums.R"))
source(here::here("functions", "API", "ipums_repwt_household.R"))
source(here::here("01_financial-well-being", "R", "finalize_metric.R"))
source(here::here("01_financial-well-being", "R", "calc_income_quantiles.R"))
source(here::here("01_financial-well-being", "R", "calc_income_quantiles_subgroup.R"))
```

## Read ACS Data

### Household-Level Data

Read in the ACS extracts using the `extract_ipums()` function. Make sure to change the survey list to reflect what years you want to include in the data. Currently we are including two years of 5-year data (2018c and 2021c). 5-year 2022 data will be added pending its release.

```{r}
acs <- extract_ipums(
  extract_name = "umf_data_18_22_5year",
  extract_description = "Microdata pull for Mobility Metric Predictors.
  American Community Survey, subgroups, years 2018, 2021 (5-year).",
  survey = list("us2018c", "us2021c")
)

```

Isolate data to include each household only once (PERNUM == 1 counts head of household only).

```{r}
acs_hh <- acs %>%
  filter(pernum == 1)

```

Look at the distribution of survey samples in the data. The number of unique samples in the data should match the number of surveys selected in the `extract_ipums()` function above.

```{r}
count(acs_hh, sample)
```

### Replicate Weights 

Read in household-level replicate weights for the entire population. These will be used in creating standard errors for the income quantile calculation. 
```{r}
repwts <- ipums_repwt_household(
  extract_name = "household_replicate_weights_5year",
  extract_description = "Household replicate weights for Income Opportunities 
  Metric Predictors. American Community Survey, years 2018 and 2021 
  (5-year).",
  survey = list("us2018c", "us2021c")
)  %>% 
  select(-cbserial, -cbpernum)

```

Look at the distribution of ACS survey samples in the data. The number of different samples should align with the number of surveys selected in the extract ipums function.

```{r}
count(repwts, sample)
```

Remove the sample variable.

```{r}
repwts_hh <- repwts %>% 
  select(-sample)
```

### Merge on repwts

Merge the replicate weights on to the ACS samples.
```{r}
length(unique(pull(acs_hh, unique_person_id)))

length(unique(pull(repwts_hh, unique_person_id)))

acs_combined <- 
  left_join(
    acs_hh,
    repwts_hh,
    by = "unique_person_id"
  )

length(unique(pull(acs_combined, unique_person_id)))

rm(acs_hh)
rm(repwts_hh)

```

## Clean Data

Missing data is reported in a variety of ways by IPUMS data. This step walks through the missing values in key variables and checks that we are dealing with them appropriately. 

* **Vacancy:** reported as "0". Note there should be no vacancy results by default of the structure of census data read in (all should be "0"). Confirm this is true with the following test.

```{r}
stopifnot(all(acs_combined$vacancy == "0"))
```

* **HHINCOME:** N/As reported as "9999999".
There is a large share of records missing HHINCOME. However, note there are no vacancy results by default of the structure of census data read in.

```{r}
acs_combined %>% 
  ggplot(aes(x = hhincome)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Household Income Variable Results") +
  ylab("Density")
```

Turn the missing/"not in universe" values for the `hhincome` variable into NAs. Rename to the more meaningful "household_income". 

```{r}

acs_clean <- acs_combined %>%
  mutate(household_income = ifelse(hhincome == 9999999, NA_integer_,
                          hhincome)
  )

```

Look at distribution of `household_income` after adjustment. Some outliers will still exist but bunching around the missing value should not be present.

```{r}

acs_clean %>% 
  ggplot(aes(x = household_income)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Household Income Variable Results") +
  ylab("Density")

```

Select our group quarters, we want to keep only households including additional households under the 2000 definition. With household income we do not consider group quarters.
```{r}
acs_clean %>% 
  group_by(gq) %>% 
  count()
```

```{r}
acs_clean <- acs_clean %>%
  filter(gq %in% c("Households under 1970 definition", 
                   "Additional households under 1990 definition",
                   "Additional households under 2000 definition"))
```

Check that group quarters fall only into household categories.

```{r}
acs_clean %>% 
  count(gq) %>% 
  ggplot(mapping = aes(x = gq, y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("GQ, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "GQ",
       y = NULL) +
  scale_x_discrete(labels = label_wrap(10))

```


### Create race variable

Evaluate the values in the RACE and HISPAN variables.

* IPUMS documented values for RACE: 
    + 1 White
    + 2 Black/African American/Negro
    + 3 American Indian or Alaska Native 
    + 4 Chinese 
    + 5 Japanese
    + 6 Other Asian or Pacific Islander 
    + 7 Other race 
    + 8 Two major races 
    + 9 Three or more major races

* IPUMS documented values for HISPAN: 
    + 0 Not Hispanic 
    + 1 Mexican 
    + 2 Puerto Rican 
    + 3 Cuban 
    + 4 Other 
    + 9 Not Reported 

Look at the distribution of values for the race and hispan variables.
```{r}
acs_clean %>% 
  count(race) %>% 
  ggplot(mapping = aes(x = race, y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Race, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Race",
       y = NULL)+
  scale_x_discrete(labels = label_wrap(10))

acs_clean %>% 
  count(hispan) %>% 
  ggplot(mapping = aes(x = hispan, y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Hispan, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Hispan",
       y = NULL)+
  scale_x_discrete(labels = label_wrap(10))
```

Create the race/ethnicity variable. For race/ethnicity categories that are not coded as Hispanic, Hispan must be equal to "Not Hispanic". 

Rename the values from number category to race label: 
  +Race is Black/African American and Hispan is Not Hispanic = "Black, Non-Hispanic"
  +Hispan is not equal to Not Hispanic = "Hispanic"
  +Race is not Black or White and Hispan is Not Hispanic  = "Other Races and Ethnicities" 
  +Race is White and Hispan is Not Hispanic = "White, Non-Hispanic" 
```{r}

acs_clean <- acs_clean %>%
  mutate(
    subgroup_race = case_when(
      hispan != "Not Hispanic" ~ "Hispanic",
      race == "White" ~ "White, Non-Hispanic",
      race == "Black/African American" ~ "Black, Non-Hispanic",
      !race %in% c("Black/African American", "White") ~ "Other Races and Ethnicities"
    )
  )

```

Look at the race/ethnicity subgroup distribution.
```{r}

acs_clean %>% 
  count(subgroup_race) %>% 
  ggplot(mapping = aes(x = factor(subgroup_race), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Race/ethnicity, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Race/ethnicity",
       y = NULL)+
  scale_x_discrete(labels = label_wrap(10))
```

## Crosswalk

Read in the PUMA to place crosswalk file. This file is created by the program generate_puma_place_crosswalks.rmd in the geographic-crosswalks folder. 

```{r}
puma_place_crosswalk <- read_csv(
  here::here("geographic-crosswalks", "data", "crosswalk_puma_to_place.csv")
)
```

Create a version with just unique counties for creating a version of the data that matches the UMF place list.

```{r}
place_list <- puma_place_crosswalk %>% 
  select(statefip, place) %>% 
  filter(statefip != 72) %>% 
  unique()
```

## Merge Crosswalk 

Create a variable in the ACS data indicating whether the survey is pre or post-2022. This will be used to join on the correct crosswalk information.

```{r}
acs_clean <- acs_clean %>% 
  mutate(crosswalk_period = ifelse(year < 2022, "pre-2022", "2022"))

```

Check that the assignment worked. All years prior to 2022 should be designated "pre-2022".

```{r}
count(acs_clean, crosswalk_period, year)

```

Join the cleaned ACS data onto the crosswalk.

```{r}
acs_crosswalked <- left_join(
  acs_clean, 
  puma_place_crosswalk, 
  by = c("crosswalk_period", "statefip","puma"),
  relationship = "many-to-many"
)

rm(acs_clean)

```

Check that each place has joined to many ACS records. We select the largest 486 places in our crosswalk, all 486 unique places should be connected to multiple records.
```{r}
acs_crosswalked %>% 
  group_by(place, statefip) %>% 
  count()
```

Drop any observations with NA for `afact` (i.e. there is no place of interest overlapping this PUMA).
```{r}
count(acs_crosswalked, is.na(afact))

acs_crosswalked <- acs_crosswalked %>% 
  drop_na(afact)

```

Also filter out cases where `afact` is equal to zero. These cases will not be counted in the metric calculation.

```{r}
count(acs_crosswalked, afact == 0)

acs_crosswalked <- acs_crosswalked %>% 
  filter(afact > 0)

```

Adjust the household weight to account for PUMA-to-place mapping (those where the PUMA is not entirely inside the place).

```{r}
select(acs_crosswalked, hhwt, repwt1, repwt80, afact)

acs_crosswalked <- acs_crosswalked %>%
  mutate(hhwt = hhwt * afact,
         across(matches("repwt[0-9]+"), ~.x * afact))

select(acs_crosswalked, hhwt, repwt1, repwt80, afact) 

```

Apply the Adjust variable to `household_income`. Adjust converts the dollar amounts to the amount that they would have been had they been earned entirely during the calendar year. This is to deal with households being surveyed at different times during the year.

```{r}

acs_crosswalked <- acs_crosswalked %>%
  mutate(
    household_income = household_income*adjust
  ) 

```

Confirm there are no missing values remaining in the data set for the household income variable. 

```{r}
acs_crosswalked %>%
  filter(is.na(household_income)) %>% 
  count()

```

Confirm there are no vacant properties included in the data.

```{r}
stopifnot(sum(is.na(acs_crosswalked$vacancy)) == 0)
```

## Create income metric: All

Create the income metric. 

Objective: calculate the 20th, 50th and 80th quantiles of income by place for all households.

Aggregation should be weighted by HHWT (this is a household level statistic).

### Pre-drop suppressed cells

First, to save time when processing the metric, calculate the effective sample count for each place, defined as the sum of the `afact` variable. This is used to create a cutoff for data quality based on the actual number of survey records being used in the calculation. We will not include counties with less than 30 effective samples.

```{r}
#| label: all-effective-samples
acs_all <- acs_crosswalked %>%
  group_by(year, sample, crosswalk_period, statefip, place) %>%
  mutate(effective_sample = sum(afact)) %>% 
  ungroup()

# calculate the number of statistics after suppressing values
acs_all %>%
  group_by(year, sample, crosswalk_period, statefip, place) %>%
  summarise(
    effective_sample = max(effective_sample)
  ) %>%
  ungroup() %>%
  summarise(
    original_stats = n(),
    unsuppressed_stats = sum(effective_sample >= 30)
  )
```

Remove records from counties below the size quality cutoff. 

```{r}
#| label: subset-all
acs_all <- acs_all %>% 
  filter(effective_sample >= 30)
```

### Calculate metric

Calculate the place-level metrics. 

```{r}
#| label: calc-all
results_all <- acs_all %>%
  group_split(statefip) %>% 
  map_dfr(~ calc_income_quantiles(.data = .x, .geo_level = place))
```

Clean up the confidence interval bounds and sort the data.

```{r}
#| label: finalize-all
results_all <- finalize_metric(results_all)
```

```{r}
rm(acs_all)
```

## Add Suppressed Rows to Data

To create the metric we suppressed counties that did not meet the threshold for sample size but we need to include these in the final data. Create an all version of the data that includes counties that were suppressed prior to the survey_mean calculation. 
```{r}
expanded_place_list <- place_list %>% 
  left_join(results_all, by = c("statefip", "place"), relationship = "many-to-many") %>%
  mutate(geoid = paste0(statefip, place)) %>% 
  expand(year, geoid) %>% 
  mutate(statefip = str_sub(geoid, 1, 2),
         place = str_sub(geoid, 3, 7)) 

results_all_expand <- expanded_place_list %>% 
  left_join(results_all, by = c("year", "statefip", "place")) %>% 
  filter(!is.na(year))

stopifnot(nrow(results_all_expand) == 486 * 2)
```

## Create income metric: subgroups

## Race/Ethnicity

To save time when processing the metric, calculate the effective sample count for each race-ethnicity group in each place, defined as the sum of the `afact` variable. This is used to create a cutoff for data quality based on the actual number of survey records being used in the calculation. We will not include counties with less than 30 effective samples.

```{r}
#| label: race-ethnicity-effective-samples
acs_race_ethnicity <- acs_crosswalked %>%
  group_by(year, sample, crosswalk_period, statefip, place, subgroup_race) %>%
  mutate(effective_sample = sum(afact)) %>% 
  ungroup()
# calculate the number of statistics after suppressing values
acs_race_ethnicity %>%
  group_by(year, sample, crosswalk_period, statefip, place, subgroup_race) %>%
  summarise(
    effective_sample = max(effective_sample)
  ) %>%
  ungroup() %>%
  summarise(
    original_stats = n(),
    unsuppressed_stats = sum(effective_sample >= 30)
  )
```

Create the income metric for the race/ethnicity subgroup. 

Remove records from counties below the size quality cutoff. 

```{r}
#| label: subset-race-ethnicity
acs_race_ethnicity <- acs_race_ethnicity %>% 
  filter(effective_sample >= 30)
```

### Calculate metric

```{r}
#| label: calc-race-ethnicity
results_race_ethnicity <- acs_race_ethnicity %>%
  group_split(statefip) %>% 
  map_dfr(~ calc_income_quantiles_subgroup(.data = .x,
                                      .geo_level = place,
                                      .subgroup = subgroup_race))
```

```{r}
#| label: finalize-race-ethnicity
results_race_ethnicity <- finalize_metric(results_race_ethnicity)
```

```{r}
rm(acs_race_ethnicity)
```

### Add Suppressed Rows to Data

To create the metric we suppressed counties that did not meet the threshold for sample size but we need to include these in the final data. Create an all version of the data that includes counties that were suppressed prior to the survey_mean calculation. 

Create expanded version for race-ethnicity.
```{r}
expanded_place_list_race <- place_list %>% 
  left_join(results_race_ethnicity, by = c("statefip", "place"), relationship = "many-to-many") %>%
  mutate(geoid = paste0(statefip, place)) %>% 
  expand(year, geoid, subgroup_race) %>% 
  mutate(statefip = str_sub(geoid, 1, 2),
         place = str_sub(geoid, 3, 7)) 

results_race_ethnicity_expanded <- expanded_place_list_race  %>% 
  left_join(results_race_ethnicity, by = c("year", "statefip", "place", "subgroup_race")) %>% 
  filter(!is.na(year), !is.na(subgroup_race)) %>% 
  mutate(subgroup_type = "race-ethnicity") %>% 
  rename(subgroup = subgroup_race)

stopifnot(nrow(results_race_ethnicity_expanded) == 486 * 2 * 4)
```

## Data Quality Flags

Add a flag for data quality, this is a numeric variable between 1 and 3 with 1 representing the best quality and 3 representing the worst. 

First combine the subgroup data sets.
```{r}
metrics_income_sub <- results_all_expand %>% 
  mutate(subgroup = "All",
         subgroup_type = "all") %>% 
  bind_rows(results_race_ethnicity_expanded)
```


The `pctl_income_quality `variable combines quality information on the quality of the crosswalk and the sample size (effective sample) to create a final quality flag. Note that any place with NA for the `pctl_income_*` variables, the metric is being suppressed due to sample size and is given a quality flag of 3.  

```{r}
metrics_income_sub <- metrics_income_sub %>% 
  mutate(
    pctl_income_quality = if_else(
      is.na(pctl_income_20), 
      NA_real_,
      geographic_allocation_quality
    )
  )
```

## Validation

Summarize the predictors for the 5-year data.

```{r}
metrics_income_sub %>% 
  select(pctl_income_20:pctl_income_80) %>% 
  summary()

```

Look at distributions of income percentiles by place for all (2021).

```{r}
metrics_income_sub %>% 
  filter(year == 2021, subgroup == "All") %>% 
  select(pctl_income_20, pctl_income_50, pctl_income_80) %>% 
  pivot_longer(cols = c(pctl_income_20, pctl_income_50, pctl_income_80), names_to = "income", values_to = "percentile") %>% 
  ggplot(aes(x = percentile, color = income, fill = income)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Income percentiles (5-year data)") +
  ylab("Density")
  
```

Break out distributions by subgroup (2021).
```{r}
metrics_income_sub %>% 
  filter(year == 2021, subgroup_type == "race-ethnicity") %>%
  select(place, pctl_income_20, pctl_income_50, pctl_income_80) %>% 
  pivot_longer(!subgroup, cols = c(pctl_income_20, pctl_income_50, pctl_income_80), 
               names_to = "income", values_to = "percentile") %>% 
  ggplot(aes(x = percentile, color = income, fill = income)) +
  geom_density(alpha = 0.15) +
  facet_wrap(~subgroup) +
  labs(
    title = "Income percentiles, race/ethnicity, by place 2021 (5-year data)",
    y = "Density"
  ) +
  theme_minimal()
```

Look at the counts of the quality flag (all years).
```{r}
metrics_income_sub %>% 
  select(pctl_income_quality) %>% 
  ggplot(aes(x = pctl_income_quality)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1.0) +
  theme_minimal() +
  ggtitle("Quality Flag (5-year data") +
  ylab("Count")
```

Tabulate share of data suppressed by year.
```{r}
metrics_income_sub %>% 
  group_by(year) %>% 
  filter(is.na(pctl_income_20)) %>% 
  count()
```

## Export 

Rename state.

```{r}
metrics_income_sub  <- metrics_income_sub  %>% 
  rename("state" = "statefip") %>% 
  arrange(year, state, county, subgroup)
```

Order the variables how we want.

```{r}
metrics_income_sub  <- metrics_income_sub  %>% 
  select(year, state, place, subgroup, subgroup_type, pctl_income_20, pctl_income_20_lb, 
         pctl_income_20_ub, 
         pctl_income_50, pctl_income_50_lb, 
         pctl_income_50_ub, 
         pctl_income_80, pctl_income_80_lb, 
         pctl_income_80_ub,
         pctl_income_quality)
```

Export as CSV.

```{r}

write_csv(metrics_income_sub, here::here("01_financial-well-being", "data", "final", "metrics_income_place_race-ethnicity_longitudinal.csv"))

```





