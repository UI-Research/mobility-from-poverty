---
title: "Opportunity for Income Predictor, place, subgroups"
author: "JP Walsh"
date: today
format:
  html:
    toc: true
    toc_float: true
    embed-resources: true
    code-fold: show
execute: 
  warning: false
editor_options: 
  chunk_output_type: console
---

*Program for the creation of the Opportunity for Income Predictor, subgroups, place level*

ACS Code: Initially written by Tina Chelidze and updated by JP Walsh 2022-2023.

Primary data derived from an IPUMS extract for 2021 ACS data (5-year).

Based on processes developed by Paul Johnson and Kevin Werner in SAS.

-   [Housekeeping](#housekeeping)
-   [Create Crosswalk](#create-crosswalk)
-   [Pull microdata](#pull-microdata)
-   [Merge microdata](#merge-microdata)
-   [Create income metric](#create-income-metric)
-   [Export](#export)

## Housekeeping

Read in packages for use. If you do not have an IPUMS API key you will need to make one via the [IPUMS website](https://www.ipums.org/).

```{r}
library(tidyverse)
library(Hmisc)
library(ipumsr)
library(reactable)

options(scipen = 999)

#set_ipums_api_key("Your KEY", save = TRUE)
```

## Create Crosswalk

Prepare the PUMA to Place crosswalk. First read in the crosswalk file from the geographic-crosswalks folder.

```{r}

puma_place_2021 <- read_csv(here::here("geographic-crosswalks", "data", "geocorr2012_PUMA_Places_2020.csv"))

```

Rename variables for working purposes. Add leading zeros to state fips, PUMAs and places to make them uniform in length.

```{r}

puma_place_2021 <- puma_place_2021 %>%
  rename(
    puma = puma12,
    statefip = state) %>%
  mutate(
    statefip = sprintf("%0.2d", as.numeric(statefip)),
    puma = sprintf("%0.5d", as.numeric(puma)),
    place = sprintf("%0.5d", as.numeric(place))
  )


```

We want to limit the crosswalk only to Places that will be used in the final mobility metric data set. Bring in the Places population file (place-populations.csv) to select only places included in the UMF data. Keep only 2021 place population data.

```{r}
places <- read_csv(here::here("geographic-crosswalks", "data", "place-populations.csv")) %>%
  filter(year == 2021)
```

Rename the Place population variables to prep for merge.

```{r}

places <- places %>% 
  rename(statefip = state)

```

Left join crosswalk data onto the Place population file to get rid of irrelevant places data (this is in an effort to make our working files smaller).

```{r}

puma_place_2021 <- left_join(places, puma_place_2021, by=c("statefip","place"))

```

Check on the distribution of key crosswalk variables AFACT and Pop20. We want to ensure there are no abnormal outliers or missing values. 

```{r}

puma_place_2021 %>% 
  ggplot(aes(x = afact)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 0.02) +
  theme_minimal() +
  ggtitle("AFACT distribution, PUMA to Place crosswalk") +
  ylab("Count")

puma_place_2021 %>% 
  ggplot(aes(x = pop20)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Population distribution in PUMAs, PUMA to Place crosswalk") +
  ylab("Density") 

```

Keep only the variables we will need from the crosswalk file.

```{r}

puma_place_2021 <- puma_place_2021 %>% 
  select(statefip, puma, place, pop20, afact, afact2)

```

Drop observations where the weight adjustment is zero. These PUMAs have no overlap with the places we want to include in the data.

```{r}
puma_place_2021 <- puma_place_2021 %>%
  filter(afact != 0.000)
```

### Create quality variable

Add the necessary components to the crosswalk for producing a data quality flag.

Create flags in the PUMA-place crosswalk for places where a high percentage of the data comes from outside of the Place. Per agreed upon guidance, 75% or more from the place is good, below 35% is bad, in between is marginal. This is calculated by taking the product of percentage of PUMA in place and percentage of place in PUMA for each place-PUMA pairing, and summing across the place.

Create new vars of interest. Products is the sum of the share of the place captured in the PUMA (afact2) and the share of the PUMA captured in the place (afact).

```{r}

puma_place <- puma_place_2021 %>%
  mutate(products = afact * afact2)
```

Calculate the total place population by summing pop20. Pop20 is the population in the PUMA that overlaps with the place - note that GeoCorr presents these numbers so that it already accounts for afact (see What is a Correlation List? on the GeoCorr website https://mcdc.missouri.edu/applications/docs/geocorr-help.html#weightVar).

```{r}
puma_place <- puma_place %>%
  group_by(statefip, place) %>%
  mutate(sum_products = sum(products),
         place_pop = sum(pop20)) %>% 
  ungroup() 

```

The average sum of products is 76% (more PUMAs have good quality than less than good).
We also want to know particularly small places, defined by the bottom percentile of population. The table below shows us that the first quartile of place population is 110,629.

```{r}
summary(puma_place %>% 
          select(sum_products, place_pop)) 
```

Crate an indicator of data quality based on these results. Create an indicator based on sum_product result (1 to 3 with 1 being best). Also create an indicator of small places (1 is small - define the cutoff as the first quartile calcualted above).

```{r}

puma_place <- puma_place %>%
  mutate(
    puma_flag = 
      case_when(
        sum_products >= 0.75 ~ 1,
        sum_products >= 0.35 ~ 2,
        sum_products < 0.35 ~ 3
      ),
    small_place = 
      case_when(
        place_pop >= 110629 ~ 0,
        place_pop < 110629 ~ 1
      )
  )

```

Save as "puma_place.csv" in the intermediate file.

```{r}
write_csv(puma_place, here::here("01_financial-well-being", "data", "intermediate", "puma_place.csv"))

```

Save a version with just the place-level values of data quality variables

```{r}

place_puma <- puma_place %>%
  group_by(statefip, place) %>% 
  summarise(puma_flag = mean(puma_flag), 
            small_place = mean(small_place)) %>% 
  ungroup()

```

Save as "place_puma.csv" in the intermediate file.

```{r}
write_csv(place_puma, here::here("01_financial-well-being", "data", "intermediate", "place_puma.csv"))
```

## Pull microdata

### API Pull

Using the API, read in the IPUMS micro data. To check on available surveys you can use the function get_sample_info("usa"). This version of the code is currently pulling from "2021c" which is 5-year 2021 ACS data.

Submit the extract. The directory is set to download into the "raw" data folder inside of the 01_financial-well-being folder. If the data already exists this step will be skipped.

```{r}

if(!file.exists(here::here("01_financial-well-being", "data", "raw", "income_5year.dat.gz"))){
  
    usa_ext_umf <-
      define_extract_usa(
        description = "5-year ACS microdata pull for the Opportunity for Income Predictor at the place level, subgroups",
        samples = c("us2021c"),
         variables = list(
      "ADJUST",
      "STATEFIP",
      "PUMA",
      "GQ",
      "HHINCOME",
      "VACANCY",
      "PERNUM",
      "RACE",
      "HISPAN"
    )
      )
    
    usa_ext_umf_submitted <- submit_extract(usa_ext_umf)
    
    usa_ext_complete <- wait_for_extract(usa_ext_umf_submitted)
    
    filepath <-
      download_extract(
        usa_ext_umf_submitted,
        download_dir = here::here("01_financial-well-being", "data", "raw"),
        progress = FALSE
      )
  }


```

Rename the IPUMS raw files. Filter for .GZ and .XML files in the raw data folder and change the names to income_5year. Note that we filter out files that have income in the name before renaming, this is to prevent changing downloads from the income non-subgroup code. 

```{r}

if(!file.exists(here::here("01_financial-well-being", "data", "raw", "income_5year.dat.gz"))){
  
    ipums_files <-
      list.files(paste0(here::here("01_financial-well-being", "data", "raw")), full.names = TRUE) %>%
      as_tibble() %>%
      filter(str_detect(value, "dat.gz|xml"), !str_detect(value, "income")) %>%
      pull()
    
    file.rename(ipums_files, c(
      here::here("01_financial-well-being", "data", "raw", "income_5year.dat.gz"),
      here::here("01_financial-well-being", "data", "raw", "income_5year.xml")
    ))
  }
```

### Read in data

Read in the micro data extract from the raw data folder.

```{r}

ddi <-
  read_ipums_ddi(here::here("01_financial-well-being", "data", "raw", "income_5year.xml"))

micro_data <-
  read_ipums_micro(
    ddi,
    data_file = here::here("01_financial-well-being", "data", "raw", "income_5year.dat.gz")
  )


```

Reformat variable names to lowercase for easier reference throughout the program.

```{r}

acs_2021 <- micro_data %>%
  rename_with(tolower) 

```

Drop labels using zap_labels and define variable formats. Household income takes an unknown format upon reading in the raw data, we redefine it as numeric.
Provide leading zeros to statefip and PUMA so they match the crosswalk. 

```{r}

acs_2021 <- acs_2021 %>%
  mutate(
    across(where(is.labelled), ~ zap_labels(.x)),
    hhincome = as.numeric(hhincome),
    statefip = sprintf("%0.2d", as.numeric(statefip)),
    puma = sprintf("%0.5d", as.numeric(puma))
  )

```

Missing data is reported in a variety of ways by IPUMS - listed below:

HHINCOME is missing it is reported as "9999999".
Vacancy is reported as "0". 

There is a large share of records missing HHINCMOE. Hownever, note there are no vacancy results by default of the structure of census data read in.
```{r}
acs_2021 %>% 
  ggplot(aes(x = hhincome)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Household Income Variable Results") +
  ylab("Density")

acs_2021 %>% 
  ggplot(aes(x = vacancy)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Vacancy Variable Results") +
  ylab("Density")
```

Turn the missing/"not in universe" variable into NAs.

```{r}

acs2021clean <- acs_2021 %>%
  mutate(hhincome = ifelse(hhincome == 9999999, NA_integer_,
                          hhincome)
  )

```

Look at distribution of HHINCOME after adjustment. Some outliers will still exist but bunching around the missing value should not be present.

```{r}

acs2021clean %>% 
  ggplot(aes(x = hhincome)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Household Income Variable Results") +
  ylab("Density")

```

Remove group quarters, we want to keep only households (GQ 1, 2 and 5).

```{r}

acs2021clean <- acs2021clean %>%
  filter(gq %in% c(1, 2, 5))

```

Check that group quarters fall only in 1, 2 and 5.

```{r}

acs2021clean %>% 
  count(gq) %>% 
  ggplot(mapping = aes(x = factor(gq), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("GQ, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "GQ",
       y = NULL)


```

Check the race and hispan variables.

Values for RACE variable: 1 White
2 Black/African American/Negro
3 American Indian or Alaska Native 4 Chinese 5 Japanese
6 Other Asian or Pacific Islander 7 Other race 8 Two major races 9 Three or more major races

Values for HISPAN variable: 0 Not Hispanic 1 Mexican 2 Puerto Rican· 3 Cuban 4 Other 9 Not Reported. 

The data show no cases of non-reporting for Hispan (no values of 9).

```{r}

acs2021clean %>% 
  count(race) %>% 
  ggplot(mapping = aes(x = factor(race), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Race, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Race",
       y = NULL)

acs2021clean %>% 
  count(hispan) %>% 
  ggplot(mapping = aes(x = factor(hispan), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Hispan, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Hispan",
       y = NULL)

```

Create race/ethnicity variable.

```{r}

acs2021clean <- acs2021clean %>%
  mutate(subgroup = case_when((hispan == 0 & race == 1) ~ 4,
                              (hispan == 0 & race == 2) ~ 1,
                              (hispan == 0 & race %in% 3:9) ~ 3,
                              (hispan %in% 1:4) ~ 2
  ))

```

Rename the values from number category to race label 4 = "White, Non-Hispanic" 1 = "Black, Non-Hispanic" 3 = "Other Races and Ethnicities" 2 = "Hispanic"

```{r}
acs2021clean <- acs2021clean %>%
  mutate(subgroup = case_when(subgroup %in% 1 ~ 'Black, Non-Hispanic',
                              subgroup %in% 2 ~ 'Hispanic',
                              subgroup %in% 3 ~ 'Other Races and Ethnicities',
                              subgroup %in% 4 ~ 'White, Non-Hispanic'
  ))

```

Look at subgroup distribution.

```{r}

acs2021clean %>% 
  count(subgroup) %>% 
  ggplot(mapping = aes(x = factor(subgroup), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Subgroup, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Subgroup",
       y = NULL)
```

## Merge microdata 

Join the cleaned ACS data onto the crosswalk.

```{r}

acs2021clean  <- left_join(acs2021clean, puma_place, by=c("statefip","puma"), relationship = "many-to-many")

```

The ACS data now has 3,886,784 observations. Run anti_join to see how many cases on the left did not have a match on the right

```{r}

test  <- anti_join(acs_2021, puma_place, by=c("statefip","puma"))

```

1,656,456 obs from the microdata (makes sense since we limit the records to only PUMAs that are overlapping with Places of interest).

Drop any observations with NA for afact (i.e. there is no place of interest overlapping this PUMA).

```{r}

acs2021clean <- acs2021clean %>% 
  filter(!is.na(afact))

```

3,886,784 obs to 2,230,328 obs. Also filter out cases where AFACT is equal to zero.

```{r}
acs2021clean <- acs2021clean %>% 
  filter(afact > 0)
```

Adjust weight to account for PUMA-to-county mapping (those where unique_types do not equal 1).Drop PUMA flag variable from PUMA_place.

Apply the Adjust variable to household income. Adjust converts the dollar amounts to the amount that they would have been had they been earned entirely during the calendar year. This is to deal with households being surveyed at different times during the year.

```{r}

acs2021clean <- acs2021clean %>%
  mutate(hhwt = hhwt*afact, 
         hhincome = hhincome*adjust,
  ) %>% 
  select(-puma_flag)

```

Save as "microdata_subgroup.csv"

```{r}
write_csv(acs2021clean, here::here("01_financial-well-being", "data", "intermediate", "2021microdata_subgroup.csv"))

```

## Create income metric

Create the income metric (subgroup).

Objective: Calculate the 20th, 50th and 80th percentile of household income for all  unique state+place combinations in year 2021.

Aggregation should be weighted by HHWT (this is a household level statistic).

Isolate data to include each household only once (PERNUM == 1 counts head of household only).

```{r}
acs2021income <- acs2021clean %>%
  filter(pernum == 1)
```

Confirm there are no missing values remaining in the data set for the household income variable. 

```{r}

acs2021income %>%
  filter(is.na(hhincome)) %>% 
  group_by(pernum) %>% 
  count()

```

Confirm there are no vacant properties included in the data.

```{r}

acs2021income %>%
  filter(is.na(vacancy)) %>% 
  group_by(pernum) %>% 
  count()

```

Calculate quantiles by grouping variable place.

```{r}

metrics_income <- acs2021income %>%
  group_by(statefip, place, subgroup) %>%
  summarise(pctl_20 = Hmisc::wtd.quantile(hhincome, weights = hhwt, probs = 0.2), 
                   pctl_50 = Hmisc::wtd.quantile(hhincome, weights = hhwt, probs = 0.5),
                   pctl_80 = Hmisc::wtd.quantile(hhincome, weights = hhwt, probs = 0.8),
                   count = n()) %>% 
  ungroup()

```

### Finish the Data Quality variable

For Income metric: total number of households is the sample size we are checking.

```{r}

metrics_income <- metrics_income %>% 
  mutate(size_flag = case_when((count < 30) ~ 1,
                               (count >= 30) ~ 0))
```

Merge the PUMA flag in & create the final data quality metric based on both size and puma flags

```{r}
metrics_income <- left_join(metrics_income, place_puma, by=c("statefip","place"))
```

Generate the quality var

```{r}

metrics_income <- metrics_income %>% 
  mutate(pctl_20_quality = case_when(size_flag==0 & puma_flag==1 ~ 1,
                                     size_flag==0 & puma_flag==2 ~ 2,
                                     size_flag==0 & puma_flag==3 ~ 3,
                                     size_flag==1 ~ 3),
         pctl_50_quality = case_when(size_flag==0 & puma_flag==1 ~ 1,
                                     size_flag==0 & puma_flag==2 ~ 2,
                                     size_flag==0 & puma_flag==3 ~ 3,
                                     size_flag==1 ~ 3),
         pctl_80_quality = case_when(size_flag==0 & puma_flag==1 ~ 1,
                                     size_flag==0 & puma_flag==2 ~ 2,
                                     size_flag==0 & puma_flag==3 ~ 3,
                                     size_flag==1 ~ 3),
         subgroup_type = "race-ethnicity"
  )

```

Keep only relevant variables

```{r}

metrics_income <- metrics_income %>% 
  select(statefip, place, subgroup_type, subgroup, pctl_20, pctl_20_quality, 
         pctl_50, pctl_50_quality, pctl_80, 
         pctl_80_quality, size_flag, 
         puma_flag)

```

### Evaluate results

Look at distributions of income percentiles by place for each subgroup category.

```{r}

metrics_income %>% 
  ungroup() %>% 
  filter(subgroup == "Black, Non-Hispanic") %>% 
  select(place, pctl_20, pctl_50, pctl_80) %>% 
  pivot_longer(cols = c(pctl_20, pctl_50, pctl_80), names_to = "income", values_to = "percentile") %>% 
  ggplot(aes(x = percentile, color = income, fill = income)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Income percentiles, Black") +
  ylab("Density")
  
metrics_income %>% 
  ungroup() %>% 
  filter(subgroup == "Hispanic") %>% 
  select(place, pctl_20, pctl_50, pctl_80) %>% 
  pivot_longer(cols = c(pctl_20, pctl_50, pctl_80), names_to = "income", values_to = "percentile") %>% 
  ggplot(aes(x = percentile, color = income, fill = income)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Income percentiles, Hispanic") +
  ylab("Density")
  
metrics_income %>% 
  ungroup() %>% 
  filter(subgroup == "Other Races and Ethnicities")  %>% 
  select(place, pctl_20, pctl_50, pctl_80) %>% 
  pivot_longer(cols = c(pctl_20, pctl_50, pctl_80), names_to = "income", values_to = "percentile") %>% 
  ggplot(aes(x = percentile, color = income, fill = income)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Income percentiles, Other") +
  ylab("Density")
  
   
metrics_income %>% 
  ungroup() %>% 
  filter(subgroup == "White, Non-Hispanic")  %>% 
  select(place, pctl_20, pctl_50, pctl_80) %>% 
  pivot_longer(cols = c(pctl_20, pctl_50, pctl_80), names_to = "income", values_to = "percentile") %>% 
  ggplot(aes(x = percentile, color = income, fill = income)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Income percentiles, white") +
  ylab("Density")
```

Look at the counts of the quality flag.

```{r}

metrics_income %>% 
  select(place, pctl_20_quality) %>% 
  ggplot(aes(x = pctl_20_quality)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1.0) +
  theme_minimal() +
  ggtitle("Quality Flag") +
  ylab("Count")
  
```

## Export 

Rename state.

```{r}
metrics_income <- metrics_income %>% 
  rename("state" = "statefip")
```

Add a variable for the year of the data

```{r}

metrics_income <- metrics_income %>%
  mutate(
    year = 2021
  )


```


Order the variables how we want

```{r}

metrics_income <- metrics_income %>% 
  select(year, state, place, subgroup_type, subgroup, pctl_20, pctl_20_quality, pctl_50, 
         pctl_50_quality, pctl_80, pctl_80_quality)

```

### Add on all variable

Read in the income percentile variable for all households in the place.

```{r}

income_all <- read_csv(here::here("01_financial-well-being", "data", "final", "metrics_income_city_2021.csv"))

income_all <- income_all %>%
  mutate(
    subgroup_type = "all",
    subgroup = "All"
  )

```

Append the "All" version of the data

```{r}
metrics_income <- bind_rows(metrics_income, income_all)
```

Sort by place again to double check we have 5 observations per place (All, Black, White, Hispanic, Other)

```{r}
metrics_income <- metrics_income %>%
  arrange(state, place)

```

Export as CSV

```{r}

write_csv(metrics_income, here::here("01_financial-well-being", "data", "final", "metrics_income_city_subgroup_2021.csv"))

```





