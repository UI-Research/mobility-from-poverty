---
title: "Employment metric, non-subgroup"
author: "JP Walsh"
date: today
format:
  html:
    toc: true
    toc_float: true
    embed-resources: true
    code-fold: true
execute: 
  warning: false
editor_options: 
  chunk_output_type: console
---

# Employment metric, non-subgroup

ACS Code: Employment metric, non-subgroup at the place level. Initially written by Tina Chelidze and updated by JP Walsh 2022-2023

Using IPUMS extract for 2021 (1-year ACS)

Based on processes developed by Paul Johnson and Kevin Werner in SAS.

# Table of Contents

-   [Housekeeping](#place-level-ranking)
-   [Pull microdata](#read-data)
-   [Merge microdata](#merge-microdata)
-   [Create income percentiles](#create-income-percentiles)
-   [Export](#export)


## Housekeeping

Read in the packages you will need. If you do not have an IPUMS API key you will need to make one via the [IPUMS website](https://www.ipums.org/).

```{r}
library(tidyverse)
library(Hmisc)
library(ipumsr)
library(reactable)
library(tidyr)
library(dplyr)
library(readr)

options(scipen = 999)

#set_ipums_api_key("Your KEY", save = TRUE)
```

## Pull microdata

### API Pull

Only run this code if you do not already have the Microdata in your working directory.

Using the API, read in the IPUMS micro data. To check on available surveys you can use the function get_sample_info("usa"). This version of the code is currently pulling from "2021a" which is 1-year 2021 ACS data.

```{r}
usa_ext_umf <-
  define_extract_usa(
    description = "USA extract for UMF Income metric",
    samples = c("us2021a"),
    variables = list(
      "ADJUST",
      "STATEFIP",
      "PUMA",
      "GQ",
      "OWNERSHP",
      "OWNCOST",
      "RENT",
      "RENTGRS",
      "HHINCOME",
      "VALUEH",
      "VACANCY",
      "PERNUM",
      "PERWT",
      "EDUC",
      "EDUCD",
      "GRADEATT",
      "EMPSTAT",
      "AGE"
    )
  )

```

Submit the extract defined above.The directory is set to download to the raw data folder inside of the 01_financial-well-being folder.

```{r}

usa_ext_umf_submitted <- submit_extract(usa_ext_umf)

usa_ext_complete <- wait_for_extract(usa_ext_umf_submitted)

filepath <- download_extract(usa_ext_umf_submitted, download_dir = paste0(here::here(), "/09_employment/data/raw"), 
                             progress = FALSE)

```

### Read in data

Read in the microdata extract from the working directory. IPUMSR allows you to reference the data through the file path object created above. You can also reference the files directly if you have already read them in.

```{r}

ddi <- read_ipums_ddi(filepath)
micro_data <- read_ipums_micro(ddi)

```

If data has already been read in and you want to skip the re-import, fill in the code below with the path to the XML file provided by IPUMS.

```{r}

#ddi <- read_ipums_ddi("data/raw/{YOUR DATA EXTRACT}")
#micro_data <- read_ipums_micro(ddi)
```

Select and rename the variables needed for merging and creating the metric.

```{r}

acs_2021 <- micro_data %>%
  select(HHWT, ADJUST, STATEFIP, PUMA, GQ, PERNUM, PERWT, EDUC, EDUCD, GRADEATT, EMPSTAT, AGE)

```

Clean up variable names for matching purposes (these will be used to join on the crosswalk data).

```{r}

acs_2021 <- acs_2021 %>% 
  rename("puma" = "PUMA",
                "statefip" = "STATEFIP") %>% 
  mutate(statefip = sprintf("%0.2d", as.numeric(statefip)),
                puma = sprintf("%0.5d", as.numeric(puma)),
  )

```

## Merge microdata {#merge-microdata}

### Read in and clean 2021 crosswalk

Prepare the Census PUMA to place crosswalk. First read in the relevant crosswalk file.

```{r}

puma_place_2021 <- read_csv(paste0(here::here(), "/geographic-crosswalks/data/geocorr2012_PUMA_Places_2020.csv"))

```

Rename variables for working purposes.

```{r}

puma_place_2021 <- puma_place_2021 %>% 
  rename(puma = puma12,
                statefip = state)

puma_place_2021 <- puma_place_2021 %>%
  mutate(statefip = sprintf("%0.2d", as.numeric(statefip)),
         puma = sprintf("%0.5d", as.numeric(puma)),
         place = sprintf("%0.5d", as.numeric(place))
  )


```

Limit the crosswalk to the Places that will be used in the final data set. Bring in the places crosswalk (place-populations.csv) to select only places included in the UMF data. Keep only year 2020.

```{r}
places <- read_csv(paste0(here::here(), "/geographic-crosswalks/data/place-populations.csv"))%>%
  filter(year == 2020)
```

Rename the Place population variables to prep for merge.

```{r}

places <- places %>% 
  dplyr::rename("statefip" = "state")

```

Left join to get rid of irrelevant places data (this is in an effort to make our working files smaller).

```{r}

puma_place_2021 <- left_join(places, puma_place_2021, by=c("statefip","place"))

```

Check on distribution of crosswalk variables.

```{r}

puma_place_2021 %>% 
  ggplot(aes(x = afact)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("AFACT distribution, PUMA to Place crosswalk") +
  ylab("Density") 

puma_place_2021 %>% 
  ggplot(aes(x = pop20)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Population distribution in PUMAs, PUMA to Place crosswalk") +
  ylab("Density") 

```

Keep only the variables we will need from the crosswalk file.

```{r}

puma_place_2021 <- puma_place_2021 %>% 
  select(statefip, puma, place, pop20, afact, afact2)

```

Drop observations where the weight adjustment is zero.

```{r}
puma_place_2021 <- puma_place_2021 %>%
  filter(afact!= 0.000)
```

Create a variable that assigns a weight to each place based on the total 2020 population. First, create a variable for the total population.

```{r}
puma_place_2021 <- puma_place_2021 %>%
  mutate(totpop = sum(pop20))

```

Then, create a variable for the share of total population comprised by each place (unique state fip + county pairs)

```{r}
puma_place_2021 <- puma_place_2021 %>% 
  group_by(statefip, place) %>% 
  mutate(placepop = sum(pop20),
                placewgt = placepop/totpop)

```

Look at distribution of place total population shares (unique). NYC, LA and Chicago all hold disproportionate shares of the population.

```{r}

puma_place_2021 %>%
  select(statefip, place, placewgt) %>%
  unique() %>%
  ggplot(aes(x = placewgt)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Place pop weight") +
  ylab("Density")


```

### Create quality variable

Prepare for Data Quality flag (at end).

Create flags in the PUMA-place crosswalk for high percentage of data from outside of place. Per Greg (for counties), 75% or more from the county - in this case, place - is good, below 35% is bad, in between is marginal. This is calculated by taking the product of percentage of PUMA in place and percentage of place in PUMA for each place-PUMA pairing, and summing across the place.

Create new vars of interest.Products is the sum of the share of the place captured in the PUMA (afact) and the share of the PUMA captured in the place (afact2).

```{r}

puma_place <- puma_place_2021 %>%
  mutate(products = afact*afact2)

puma_place <- puma_place %>%
  group_by(statefip, place) %>%
  mutate(sum_products = sum(products),
                place_pop = sum(pop20))


```

Sum_products mean is 0.76.
Bottom percentile of population starts at 110629.

```{r}
summary(puma_place)
```

```{r}

puma_place <- puma_place %>%
  mutate(
    puma_flag = 
      case_when(
        sum_products >= 0.75 ~ 1,
        sum_products >= 0.35 ~ 2,
        sum_products < 0.35 ~ 3
      ),
    small_place = 
      case_when(
        placepop >= 110629 ~ 0,
        placepop < 110629 ~ 1
      )
  )

```

Save as "puma_place.csv" in the intermediate file.

```{r}
write_csv(puma_place, paste0(here::here(), "/09_employment/data/intermediate/puma_place.csv"))

```

Save a version with just the place-level values of data quality variables

```{r}

place_puma <- puma_place %>%
  group_by(statefip, place) %>% 
  summarise(puma_flag = mean(puma_flag), 
            small_place = mean(small_place))

```

Save as "place_puma.csv" in the intermediate file.

```{r}
write_csv(place_puma, paste0(here::here(), "/09_employment/data/intermediate/place_puma.csv"))
```

### Prepare microdata

First convert the IPUMS ACS missing values into NAs.

Missing data is reported in a variety of ways - listed below:

IPUMS says EMPSTAT missing: 0 is N/A
AGE: No missing value indicator

```{r}

acs_2021 %>% 
  ggplot(aes(x = EMPSTAT)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1) +
  theme_minimal() +
  ggtitle("EMPSTAT Variable Results, All Records") +
  ylab("Count")

acs_2021 %>% 
  ggplot(aes(x = AGE)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1) +
  theme_minimal() +
  ggtitle("AGE Variable Results, All Records") +
  ylab("Count")


```

Turn the missing/"not in universe" variable into NAs.

```{r}

acs2021clean <- acs_2021 %>%
  mutate(EMPSTAT = ifelse(EMPSTAT == 0, NA_integer_,
                          EMPSTAT)
  )

```

Look at distriubtion after adjustment (outliers should still exist)

```{r}

acs2021clean %>% 
  ggplot(aes(x = EMPSTAT)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1) +
  theme_minimal() +
  ggtitle("EMPSTAT Variable Results, All Records") +
  ylab("Count")

```

```{r}

acs2021clean  <- left_join(acs2021clean, puma_place, by=c("statefip","puma"))

```

Now have 3,886,784 observations Run anti_join to see how many cases on the left did not have a match on the right

```{r}

test  <- anti_join(acs_2021, puma_place, by=c("statefip","puma"))

```

1,656,456 obs from the microdata (makes sense since we limited to only PUMAs that are overlapping with Places of interest).

Drop any observations with NA for afact (i.e. there is no place of interest overlapping this PUMA).

```{r}

acs2021clean <- acs2021clean %>% 
  filter(!is.na(afact))

```

3,886,784 obs to 2,230,328 obs. Also filter out cases where AFACT is equal to zero.

```{r}
acs2021clean <- acs2021clean %>% 
  filter(afact > 0)
```

Create a variable for the number of places per PUMA population per place (e.g., in unique statefip+place pairs).

```{r}
acs2021clean  <- acs2021clean  %>%
  group_by(puma, statefip) %>%
  mutate(places_per_PUMA = n_distinct(statefip, place))
```

Create a variable for the number of PUMAs per place.

```{r}

acs2021clean  <- acs2021clean %>%
  group_by(place, statefip) %>%
  mutate(PUMAs_per_place = n_distinct(statefip, puma))


```

Adjust weight to account for PUMA-to-county mapping (those where unique_types are not equal to 1).
Drop PUMA flag variable from PUMA_place.

```{r}

acs2021clean <- acs2021clean %>%
  mutate(HHWT = HHWT*afact, 
         PERWT = PERWT*afact
  ) %>% 
  select(-puma_flag)

```

Remove group quarters.

```{r}

acs2021clean <- acs2021clean %>%
  filter(GQ < 3)

```


Check that GQ only contains 1 and 2 (Households)

```{r}

acs2021clean %>% 
  ggplot(aes(x = GQ)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1.0) +
  theme_minimal() +
  ggtitle("GQ, All Records") +
  ylab("Count")

```

Save as "microdata.csv"

```{r}
write_csv(acs2021clean, paste0(here::here(), "/09_employment/data/intermediate/2021microdata.csv"))

```

## Create employment metric

Create employment metric (non-subgroup)

Objective: get the percent of individuals between the ages 25 and 54 that are employed from the EMPSTAT variable.

Aggregation should be weighted by PERWT

Remove records where EMPSTAT is missing - NA.

```{r}
acs2021clean <- acs2021clean %>%
  filter(!is.na(EMPSTAT))
```

First, isolate the dataset to 25-54 year olds.

```{r}
microdata_emp_age <- acs2021clean %>% 
  filter(AGE >= 25 & AGE <= 54) 
```


Collapse # of 25-54 year olds by place
Also create a collapse var for people that age who are employed (EMPSTAT == 1)
These vars needed to calculate metric: share employed

```{r}
metrics_employment <- microdata_emp_age %>%
  group_by(statefip, place) %>%
  summarise(
    num_in_emp_age = sum(PERWT),
    num_employed = sum((EMPSTAT == 1) * PERWT),
    count = n()
  )
```

Compute the ratio (share employed)

```{r}

metrics_employment <- metrics_employment %>%
  mutate(share_employed = num_employed/num_in_emp_age)

```


### Finish the Data Quality variable

For Income metric: total number of households is the sample size we are checking.

```{r}

metrics_employment <- metrics_employment %>% 
  mutate(size_flag = case_when((count < 30) ~ 1,
                               (count >= 30) ~ 0))
```

Merge the PUMA flag in & create the final data quality metric based on both size and puma flags

```{r}
metrics_employment <- left_join(metrics_employment, place_puma, by=c("statefip","place"))
```

Generate the quality var

```{r}

metrics_employment <- metrics_employment %>% 
  mutate(share_employed_quality = case_when(size_flag==0 & puma_flag==1 ~ 1,
                                     size_flag==0 & puma_flag==2 ~ 2,
                                     size_flag==0 & puma_flag==3 ~ 3,
                                     size_flag==1 ~ 3)
  )

```

Keep only relevant variables

```{r}

metrics_employment <- metrics_employment %>% 
  select(statefip, place, share_employed, share_employed_quality, size_flag, 
         puma_flag)

```

### Evaluate results

Look at distributions of income percentiles by place.

```{r}

metrics_employment %>% 
  ungroup() %>% 
  select(place, share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Distribution share employed, by place") +
  ylab("Density")
  
```

## Export {#export}

Rename state.

```{r}
metrics_employment <- metrics_employment %>% 
  rename('state' = 'statefip')
```

Add a variable for the year of the data

```{r}

metrics_employment <- metrics_employment %>%
  mutate(
    year = 2021
  )


```

Order the variables how we want

```{r}

metrics_employment <- metrics_employment %>% 
  select(year, state, place, share_employed, share_employed_quality)

```

Export as CSV

```{r}

write_csv(metrics_employment, here::here(), paste0("data/final/metrics_employment_city_2021.csv"))

```

