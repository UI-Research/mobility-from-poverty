---
title: "Employment Opportunities Predictor, County-level"
author: "JP Walsh and Aaron R. Williams"
date: today
format:
  html:
    toc: true
    toc_float: true
    embed-resources: true
    code-fold: show
execute: 
  warning: false
editor_options: 
  chunk_output_type: console
---

*Program for the creation of the Employment Opportunities Upward Mobility Predictor at the County-level*

ACS Code: Initially written by Tina Chelidze and updated by JP Walsh 2022-2023.

Primary data derived from the IPUMS API.

Based on processes developed by Paul Johnson and Kevin Werner in SAS.

## Housekeeping

Read in packages for use. If you do not have an IPUMS API key you will need to make one via the [IPUMS website](https://www.ipums.org/).

```{r}
library(tidyverse)
library(ipumsr)
library(reactable)
library(srvyr)
library(scales)
library(furrr)
library(tictoc)

options(scipen = 999)

theme_set(theme_minimal())

# DO NOT PUSH YOUR API KEY. You only have to run this once and then comment it out as below.
#set_ipums_api_key("Your KEY", save = TRUE)

source(here::here("functions", "API", "extract_ipums.R"))
source(here::here("functions", "API", "ipums_repwt_employment.R"))
source(here::here("09_employment", "R", "finalize_metric.R"))
source(here::here("09_employment", "R", "calc_survey_mean.R"))
source(here::here("09_employment", "R", "calc_survey_mean_subgroup.R"))

```


## Read ACS Data

### Person-Level Data

Read in the ACS extracts using the `extract_ipums()` function. Make sure to change the survey list to reflect what years you want to include in the data. Currently we are including three years of 1-year data (2018a, 2021a, and 2022a) for the overall calculation.

```{r}
acs <- extract_ipums(
  extract_name = "umf_data_18_22",
  extract_description = "Microdata pull for Mobility Metric Predictors.
  American Community Survey, overall, years 2018, 2019 and 2022 (1-year).",
  survey = list("us2018a", "us2021a", "us2022a")
)

```

```{r}
acs <- acs %>%
  filter(sample %in% c("2018 ACS", "2021 ACS", "2022 ACS"))

```

Look at the distribution of survey samples in the data. The number of unique samples in the data should match the number of surveys selected in the `extract_ipums()` function above.

```{r}
count(acs, sample)
```

Isolate the data to 25-54 year-olds. This is the age-range included in the employment calculation. Note: the replicate weights are limited to these ages during the data pull. 
```{r}
acs_age <- acs %>% 
  filter(age >= 25 & age <= 54) 

```

### Replicate Weights 

Read in person-level replicate weights for the 25 to 54 year old population. These will be used in creating standard errors for the employment opportunity calculation. 

*Warning* This is a large data pull and will take time to finish (likely between 15-20 minutes). It is highly recommended you run this program on a server with large computing power.
```{r}
repwts <- ipums_repwt_employment(
  extract_name = "employment_replicate_weights",
  extract_description = "Person replicate weights for Employment Opportunities 
  Metric Predictors. American Community Survey, years 2018, 2019 and 2022 
  (1 and 5-year).",
  survey = list("us2018a", "us2021a", "us2022a", "us2018c", "us2021c")
)  %>% 
  select(-cbserial, -cbpernum)
```

Look at the distribution of ACS survey samples in the data. The number of different samples should align with the number of surveys selected in the extract ipums function.

```{r}
count(repwts, sample)
```

Remove the sample variable.

```{r}
repwts_person <- repwts %>% 
  select(-sample, -multyear)

```

### Merge on repwts

Merge the replicate weights on to the ACS samples. The length calls let us know the count of records going in and coming out of the join. 
The number of unique persons in acs_age should be the same as acs_combined. Check that this is the case.
```{r}

acs_combined <- 
  left_join(
    acs_age,
    repwts_person,
    by = "unique_person_id"
  )

stopifnot(length(unique(pull(acs_combined, unique_person_id))) == length(unique(pull(acs_age, unique_person_id))))

rm(acs_age)
rm(repwts_person)

```

Check that the merge did not result in any missing values.
```{r}
stopifnot(all(map_dbl(acs_combined, ~sum(is.na(.x))) == 0))
```

## Clean Data

Missing data is reported in a variety of ways by IPUMS data. This step walks through the missing values in key variables and checks that we are dealing with them appropriately. 

* **Age:** No missing values reported in variable description. Check the distribution to confirm there are no abnormalities: the distribution of age looks reasonable (no bunching and all values are between 25 and 54).

```{r}
acs_combined %>% 
  ggplot(aes(x = age)) +
  geom_density(adjust = 5, color = "blue", fill = alpha("blue", 0.3)) +
  labs(
    title = "Age Variable Results",
    y = "Density"
  )
```

* **Vacancy:** reported as "0". 
Note there are no vacancy results by default of the structure of census data read in.

```{r}
acs_combined %>% 
  ggplot(aes(x = vacancy)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  labs(
    title = "Vacancy Variable Results",
    y = "Density"
  )

```

* **Empstat:** N/As reported as "0".
There are many records with the value missing for `empstat`. 

```{r}
acs_combined %>% 
  count(empstat) %>% 
  ggplot(mapping = aes(x = factor(empstat), y = n)) +
  geom_col() +
  geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(
    title = "Empstat, All Records",
    x = "Employment Status",
    y = NULL
  )
```

Turn the missing/"not in universe" value from the empstat variable into NAs. Rename to the more meaningful "employment_status". 

```{r}
acs_clean <- acs_combined %>%
  mutate(
    employment_status = ifelse(
      empstat == 0, 
      NA_integer_,
      empstat)
  )

```

Look at distribution of `employment_status` after adjustment. There should be no more records with the value "0".

```{r}
acs_clean %>% 
  count(employment_status) %>% 
  ggplot(mapping = aes(x = factor(employment_status), y = n)) +
  geom_col() +
  geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(
    title = "Employment, All Records",
    x = "Employment Status",
    y = NULL
  )

```

Filter for group quarters (GQ), we want to keep only households including additional households under updated definitions.

```{r}
count(acs_clean, gq)

```

```{r}
acs_clean <- acs_clean %>%
  filter(gq %in% c("Households under 1970 definition", 
                   "Additional households under 1990 definition",
                   "Additional households under 2000 definition"))
```

Check that group quarters fall only into household categories.

```{r}
acs_clean %>% 
  count(gq) %>% 
  ggplot(mapping = aes(x = gq, y = n)) +
  geom_col() +
  geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  scale_x_discrete(labels = label_wrap(10)) +
  labs(
    title = "GQ, All Records",
    x = "GQ",
    y = NULL
  )

```

## Crosswalk

Read in the PUMA to county crosswalk file. This file is created by the program generate_puma_county_crosswalks.rmd in the geographic-crosswalks folder. 

```{r}
puma_county_crosswalk <- read_csv(
  here::here("geographic-crosswalks", "data", "crosswalk_puma_to_county.csv")
)
```

## Merge Crosswalk 

Create a variable in the ACS data indicating whether the survey is pre or post-2022. This will be used to join on the correct crosswalk information.

```{r}
acs_clean <- acs_clean %>% 
  mutate(crosswalk_period = ifelse(year < 2022, "pre-2022", "2022"))

```

Check that the assignment worked. All years prior to 2022 should be designated "pre-2022".

```{r}
count(acs_clean, crosswalk_period, year)

```

Join the cleaned ACS data onto the crosswalk.

```{r}
acs_crosswalked <- left_join(
  acs_clean, 
  puma_county_crosswalk, 
  by = c("crosswalk_period", "statefip","puma"),
  relationship = "many-to-many"
)

```

Run an anti_join to see what data does not combine. We keep all counties so there should be no observations resulting from the anti-join.

```{r}
anti_join(acs_clean, 
          puma_county_crosswalk, 
          by = c("crosswalk_period", "statefip","puma")
)
```


Drop any observations with NA for `afact` (i.e. there is no county of interest overlapping this PUMA).

Create a count of how many observations this applies to.
```{r}
count(acs_crosswalked, is.na(afact))

acs_crosswalked <- acs_crosswalked %>% 
  drop_na(afact)

```

Also filter out cases where `afact` is equal to zero. These cases will not be counted in the metric calculation.

Create a count of how many observations this applies to.
```{r}
count(acs_crosswalked, afact == 0)

acs_crosswalked <- acs_crosswalked %>% 
  filter(afact > 0)

```

Adjust the person weight to account for PUMA-to-county mapping (those where the PUMA is not entirely inside the county).

Select an example of the repwtp variables before and after this step. The weighting should show in slightly adjusted repwtp variables after this process. 
```{r}
select(acs_crosswalked, perwt, repwtp1, repwtp80, afact)

acs_crosswalked <- acs_crosswalked %>%
  mutate(perwt = perwt * afact,
         across(matches("repwtp[0-9]+"), ~.x * afact))

select(acs_crosswalked, perwt, repwtp1, repwtp80, afact) 
```


Create a binary employed variable for calculating the share employed. IPUMS data codes "Employed" as equal to 1.

```{r}

acs_crosswalked <- acs_crosswalked %>% 
  mutate(employed = employment_status == 1) 

```

Check how many records, if any, have NA reported for `employment_status` after filtering (this should be zero).

```{r}
count(acs_crosswalked, is.na(employment_status))

```

Confirm there are no vacant properties included in the data.

```{r}
acs_crosswalked %>%
  filter(is.na(vacancy)) %>% 
  count(pernum)

```

## Create employment metric: All

### Pre-drop suppressed cells

First, to save time when processing the metric, calculate the effective sample count for each county, defined as the sum of the `afact` variable. This is used to create a cutoff for data quality based on the actual number of survey records being used in the calculation. We will not include counties with less than 30 effective samples.

```{r}
#| label: all-effective-samples

acs_all <- acs_crosswalked %>%
  group_by(year, sample, crosswalk_period, statefip, county) %>%
  mutate(effective_sample = sum(afact)) %>% 
  ungroup()

# calculate the number of statistics after suppressing values
acs_all %>%
  group_by(year, sample, crosswalk_period, statefip, county) %>%
  summarize(
    effective_sample = max(effective_sample)
  ) %>%
  ungroup() %>%
  summarize(
    original_stats = n(),
    unsuppressed_stats = sum(effective_sample >= 30)
  )

```

Create the employment metric. 

Objective: get the percent of individuals between the ages 25 and 54 that are employed from the EMPSTAT variable.

Aggregation should be weighted by PERWT (this is a person level statistic).

Remove records from counties below the size quality cutoff. 

```{r}
#| label: subset-all

acs_all <- acs_all %>% 
  filter(effective_sample >= 30)

```

### Calculate metric

Calculate the county-level metrics. We use `group_split` by statefips so that this process happens to each state individually and then joins together. This is to save time and reduce the number of srvyr data sets that ever exist at the same time as these tend to be very large.

```{r}
#| label: calc-all

results_all <- acs_all %>% 
  group_split(statefip) %>% 
  map_dfr(~ calc_survey_mean(.data = .x))

```

Clean up the confidence interval bounds and sort the data.

```{r}
#| label: finalize-all

results_all <- finalize_metric(results_all)

```

```{r}
rm(acs_all)

```

## Add Suppressed Rows to Data

To create the metric we suppressed counties that did not meet the threshold for sample size but we need to include these in the final data. Create an all version of the data that includes counties that were suppressed prior to the survey_mean calculation. 
Include a test that we have all of the records anticipated.
```{r}
results_all_expand <- acs_crosswalked %>% 
  mutate(geoid = paste0(statefip, county)) %>% 
  group_by(year, geoid) %>% 
  count() %>% 
   expand_grid() %>%  
   mutate(statefip = str_sub(geoid, 1, 2),
         county = str_sub(geoid, 3, 5)) %>% 
  left_join(results_all, by = c("year", "statefip", "county"))

stopifnot(nrow(results_all_expand) == 3143 * 3)
```

## Data Quality Flags

Add a flag for data quality, this is a numeric variable between 1 and 3 with 1 representing the best quality and 3 representing the worst. 

The `employed_quality `variable combines quality information on the quality of the crosswalk and the sample size (effective sample) to create a final quality flag. Note that any county with NA for the share_employed metric is being suppressed due to sample size and is given a quality flag of 3.  

```{r}
metrics_employment_all <- results_all_expand %>% 
  mutate(
    share_employed_quality = if_else(
      is.na(share_employed), 
      NA_real_,
      geographic_allocation_quality
    )
  )
```

## Validation

Show summary statistics for the metric across all counties in the 1-year data.
```{r}
metrics_employment_all %>% 
  select(share_employed:share_employed_quality) %>% 
  summary()
```

Calculate the coefficient of variation for each year for the `share_employed` variable.
The higher this number the greater variability in the data. 
```{r}
metrics_employment_all %>% 
  group_by(statefip, county) %>% 
  summarise(sd_employ = sd(share_employed, na.rm = TRUE),
         mean_employ = mean(share_employed, na.rm = TRUE),
         cv = sd_employ/mean_employ) %>% 
  reactable()
```

Look at distribution of `share_employed` for all counties. We generally see a normal distribution. 
```{r}
metrics_employment_all %>% 
  filter(year == 2022) %>% 
  select(share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Distribution of share employed, by county 2022 (1-year data)") +
  ylab("Density")
```

Look at the counts of the quality flag. For the 1-year data at the place level there are still a fair amount of quality "3" observations that we would suggest users disregard or use with caution. 
```{r}
metrics_employment_all %>% 
  select(share_employed_quality) %>% 
  ggplot(aes(x = share_employed_quality)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1.0) +
  theme_minimal() +
  ggtitle("Quality Flag (1-year data)") +
  ylab("Count")
```

Tabulate share of data suppressed by year.
```{r}
metrics_employment_all %>% 
  group_by(year) %>% 
  filter(is.na(share_employed)) %>% 
  count()
```

## Export 

Rename state.

```{r}
metrics_employment_all <- metrics_employment_all %>% 
  rename("state" = "statefip")

```

Order the variables how we want.

```{r}
metrics_employment_all <- metrics_employment_all %>% 
  select(year, state, county, share_employed, share_employed_lb,
         share_employed_ub, share_employed_quality)

```

Export as CSV.

```{r}
write_csv(metrics_employment_all, here::here("09_employment", "data", "final", "metrics_employment_county_all_longitudinal.csv"))

```
