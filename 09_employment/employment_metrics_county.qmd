---
title: "Employment Opportunities Predictor, County-level"
author: "JP Walsh"
date: today
format:
  html:
    toc: true
    toc_float: true
    embed-resources: true
    code-fold: show
execute: 
  warning: false
editor_options: 
  chunk_output_type: console
---

*Program for the creation of the Employment Opportunities Upward Mobility Predictor at the County-level*

ACS Code: Initially written by Tina Chelidze and updated by JP Walsh 2022-2023.

Primary data derived from the IPUMS API.

Based on processes developed by Paul Johnson and Kevin Werner in SAS.

-   [Housekeeping](#housekeeping)
-   [Read Data](#read-data)
-   [Clean Data](#clean-data)
-   [Merge Crosswalk](#merge-crosswalk)
-   [Setup Survey Design](#setup-survey-design)
-   [Create Employment Metric](#create-employment-metric)
-   [Evaluate Results](#evaluate-results)
-   [Export](#export)

## Housekeeping

Read in packages for use. If you do not have an IPUMS API key you will need to make one via the [IPUMS website](https://www.ipums.org/).

```{r}
library(tidyverse)
library(Hmisc)
library(ipumsr)
library(reactable)
library(srvyr)
library(scales)

options(scipen = 999)

# DO NOT PUSH YOUR API KEY. You only have to run this once and then comment it out as below.
#set_ipums_api_key("Your KEY", save = TRUE)

source(here::here("functions", "API", "extract_ipums.R"))
```

## Read Data

Read in the ACS extracts using the extract_ipums function. Make sure to change the survey list to reflect what years you want to include in the data. Currently we are including three years of 1-year data (2018a, 2021a and 2022a) and two years of 5-year data (2018c and 2021c). 5-year 2022 data will be added pending its release.
```{r}
acs <- extract_ipums(
  extract_name = "umf_data_18_22",
  extract_description = "Microdata pull for Mobility Metric Predictors. American Community Survey, years 2018, 2019 and 2022 (1 and 5-year).",
  survey = list("us2018a", "us2021a", "us2022a", "us2018c", "us2021c")
) 
```

Look at the distribution of survey samples in the data. The number of unique samples in the data should match the number of surveys selected in the extract_ipums function above.
```{r}
acs %>% 
  count(sample) %>% 
  ggplot(mapping = aes(x = sample, y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Samples, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Samples",
       y = NULL)
```

Read in the PUMA to county crosswalk file. This file is created by the program generate_puma_county_crosswalks.rmd in the geographic-crosswalks folder. 
```{r}
puma_county_crosswalk <- read_csv(here::here("geographic-crosswalks", "data", "crosswalk_puma_to_county.csv"))
```

Crate a version of the crosswalk with just the county-level values of data quality variables for each crosswalk period.
```{r}
county_puma <- puma_county_crosswalk %>%
  group_by(crosswalk_period, statefip, county) %>% 
  summarise(geographic_allocation_quality = mean(geographic_allocation_quality)) %>% 
  ungroup()
```

## Clean Data

Missing data is reported in a variety of ways by IPUMS - listed below:

Age: No missing values reported in variable description.
Empstat: N/As reported as "0".
Vacancy is reported as "0". 

There are many records with the value missing for empstat. The distribution of age looks reasonable (no bunching or extreme outliers). Note there are no vacancy results by default of the structure of census data read in.

```{r}

acs %>% 
  count(empstat) %>% 
  ggplot(mapping = aes(x = factor(empstat), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Empstat, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Employment Status",
       y = NULL)

acs %>% 
  ggplot(aes(x = age)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Age Variable Results") +
  ylab("Density")

acs %>% 
  ggplot(aes(x = vacancy)) +
  geom_density(color = "blue", fill = alpha("blue", 0.3)) +
  theme_minimal() +
  ggtitle("Vacancy Variable Results") +
  ylab("Density")
```

Turn the missing/"not in universe" value from the empstat variable into NAs.
```{r}
acs_clean <- acs %>%
  mutate(empstat = ifelse(empstat == 0, NA_integer_,
                          empstat)
  )
```

Look at distribution of empstat after adjustment. There should be no more records with the value "0".
```{r}

acs_clean %>% 
  count(empstat) %>% 
  ggplot(mapping = aes(x = factor(empstat), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Empstat, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Employment Status",
       y = NULL)

```

Filter for group quarters (GQ), we want to keep only households including additional households under updated definitions.
```{r}
acs_clean %>% 
  group_by(gq) %>% 
  count()
```

```{r}
acs_clean <- acs_clean %>%
  filter(gq %in% c("Households under 1970 definition", 
                   "Additional households under 1990 definition",
                   "Additional households under 2000 definition"))
```

Check that group quarters fall only into household categories.

```{r}
acs_clean %>% 
  count(gq) %>% 
  ggplot(mapping = aes(x = gq, y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("GQ, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "GQ",
       y = NULL) +
  scale_x_discrete(labels = label_wrap(10))
```

### Create race variable

Evaluate the values in the RACE and HISPAN variables.

* IPUMS documented values for RACE: 
  + 1 White
  + 2 Black/African American/Negro
  + 3 American Indian or Alaska Native 
  + 4 Chinese 
  + 5 Japanese
  + 6 Other Asian or Pacific Islander 
  + 7 Other race 
  + 8 Two major races 
  + 9 Three or more major races

* IPUMS documented values for HISPAN: 
  + 0 Not Hispanic 
  + 1 Mexican 
  + 2 Puerto Rican 
  + 3 Cuban 
  + 4 Other 
  + 9 Not Reported 

Look at the distribution of values for the race and hispan variables.

```{r}
acs_clean %>% 
  count(race) %>% 
  ggplot(mapping = aes(x = race, y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Race, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Race",
       y = NULL) +
  scale_x_discrete(labels = label_wrap(10))

acs_clean %>% 
  count(hispan) %>% 
  ggplot(mapping = aes(x = hispan, y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Hispan, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Hispan",
       y = NULL) +
  scale_x_discrete(labels = label_wrap(10))

```

Create the race/ethnicity variable. For race/ethnicity categories that are not coded as Hispanic, Hispan must be equal to "Not Hispanic". 

Rename the values from number category to race label: 
  +Race is Black/African American and Hispan is Not Hispanic = "Black, Non-Hispanic"
  +Hispan is not equal to Not Hispanic = "Hispanic"
  +Race is not Black or White and Hispan is Not Hispanic  = "Other Races and Ethnicities" 
  +Race is White and Hispan is Not Hispanic = "White, Non-Hispanic" 
```{r}

acs_clean <- acs_clean %>%
  mutate(subgroup = case_when((hispan == "Not Hispanic" & race == "White") ~ "White, Non-Hispanic",
                              (hispan == "Not Hispanic" & race == "Black/African American") ~ "Black, Non-Hispanic",
                              (hispan == "Not Hispanic" & !race %in% c("Black/African American", "White")) ~ "Other Races and Ethnicities",
                               hispan != "Not Hispanic" ~ "Hispanic"
  ))

```

Look at subgroup distribution.
```{r}

acs_clean %>% 
  count(subgroup) %>% 
  ggplot(mapping = aes(x = factor(subgroup), y = n)) +
  geom_col() +
  theme_minimal() +
  ggtitle("Subgroup, All Records") +
 geom_text(mapping = aes(label = n), vjust = -1) +    
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(x = "Subgroup",
       y = NULL) +
  scale_x_discrete(labels = label_wrap(10))

```

## Merge Crosswalk 

Create a variable in the ACS data indicating whether the survey is pre or post-2022. This will be used to join on the correct crosswalk information.
```{r}
acs_clean <- acs_clean %>% 
  mutate(crosswalk_period = ifelse(year < 2022, "pre-2022", "2022"))

```

Check that the assignment worked. All years prior to 2022 should be designated "pre-2022".
```{r}
acs_clean %>% 
  group_by(crosswalk_period, year) %>% 
  count()
```

Join the cleaned ACS data onto the crosswalk.
```{r}

acs_clean <- left_join(acs_clean, puma_county_crosswalk, by=c("crosswalk_period", "statefip","puma"))

```

Drop any observations with NA for afact (i.e. there is no county of interest overlapping this PUMA).

```{r}
acs_clean <- acs_clean %>% 
  drop_na(afact)

```

Also filter out cases where AFACT is equal to zero. These cases will not be counted in the metric calculation.

```{r}
acs_clean <- acs_clean %>% 
  filter(afact > 0)
```

Adjust the person weight to account for PUMA-to-county mapping (those where the PUMA is not entirely inside the county).

```{r}
acs_clean <- acs_clean %>%
  mutate(perwt = perwt*afact) 

```

Create a binary variable to distinguish between 1 and 5 year ACS surveys. 5-year samples include the term "5-year".
```{r}
acs_clean <- acs_clean %>%
  mutate(sample_structure = ifelse(str_detect(sample, "5-year"), "5year", "1year")) 
```

Isolate the data to 25-54 year-olds. This is the age-range included in the employment calculation.
```{r}
acs_clean <- acs_clean %>% 
  filter(age >= 25 & age <= 54) 
```

Create a binary employed variable for calculating the share employed. IPUMS data codes "Employed" as equal to 1.
```{r}
acs_clean <- acs_clean %>% 
  mutate(employed = ifelse(empstat == 1, 1, 0)) 
```

Check how many records, if any, have NA reported for empstat after filtering (this should be zero).
```{r}
acs_clean %>%
  filter(is.na(empstat)) %>% 
  group_by(pernum) %>% 
  count()
```

Confirm there are no vacant properties included in the data.
```{r}
acs_clean %>%
  filter(is.na(vacancy)) %>% 
  group_by(pernum) %>% 
  count()
```

## Setup Survey Design 

Set up the survey design using instructions from IPUMS. To speed up the srvyr calculation we combine the data by grouping the employed variable and summing the perwt variable - this limits the number of rows that have to go through the survey_mean function. 
```{r}
acs_survey_all <- acs_clean %>%
  filter(sample_structure == "1year") %>% 
  group_by(year, crosswalk_period, statefip, county, employed) %>% 
  summarise(perwt = sum(perwt)) %>% 
  as_survey_design(weights = perwt) %>% 
  ungroup()

acs_survey_subgroups <- acs_clean %>%
  filter(sample_structure == "5year") %>% 
  group_by(year, crosswalk_period, statefip, county, employed, subgroup) %>% 
  summarise(perwt = sum(perwt)) %>% 
  as_survey_design(weights = perwt) %>% 
  ungroup()

```

## Create employment metric

Create the employment metric. 

Objective: get the percent of individuals between the ages 25 and 54 that are employed from the EMPSTAT variable.

Aggregation should be weighted by PERWT (this is a person level statistic).

Check national employment ratio. Compute the ratio (share employed) for 2018, 2021 and 2022 nationally and show results.
```{r}
acs_survey_all %>%
  group_by(year) %>%
  summarise(
    share_employed = survey_mean(employed),
    count = unweighted(n())
  ) %>% 
  ungroup() %>% 
  reactable()
```

### All

Create share employed for all individuals at the county-level (1-year data) using the survey_mean function.
```{r}
metrics_employment_all <- acs_survey_all %>%
  group_by(year, crosswalk_period, statefip, county) %>%
  summarise(
    share_employed = survey_mean(employed, vartype = NULL)
  ) %>% 
  ungroup()
```

Sort by year, state and county.
```{r}
metrics_employment_all <- metrics_employment_all %>%
  arrange(year, statefip, county)
```

*Create an indicator for data quality and suppression*

Calculate the effective sample count for each county, defined as the sum of the afact variable. This is used to create a cutoff for data quality based on the actual number of survey records being used in the calculation.
```{r}
effective_sample <- acs_clean %>%
  filter(sample_structure == "1year") %>% 
  group_by(year, crosswalk_period, statefip, county) %>%
  summarise(effective_sample = sum(afact)) %>% 
  ungroup()
```

Merge the data quality flags from place_puma and effective sample to create the final data quality metric based on both size and geographic allocation.
```{r}
metrics_employment_all <- left_join(metrics_employment_all, county_puma, by=c("crosswalk_period", "statefip","county"))

metrics_employment_all <- left_join(metrics_employment_all, effective_sample, by=c("year", "crosswalk_period", "statefip","county"))
```

Tabulate effective sample counts for each county, defined as the sum of the afact for all records in that county. Look at the distribution of counties by potential cutoffs (30, 100, 300). This is to measure data quality for each county based on the number of records reported. In the 1-year data for all there are no cases of a county with less than 100 observations for 2018, 2021 and 2022.
```{r}
reactable_data <- metrics_employment_all %>%
  mutate(
    effective_sample_cutoffs = case_when(
      effective_sample < 30 ~ "Less than 30",
      effective_sample >= 30 &
        effective_sample <= 100 ~ "Over 30 but 100 or less",
      effective_sample > 100 &
        effective_sample <= 300 ~ "Over 100 but 300 or less",
      TRUE ~ "Greater than 300"
    ),
    effective_sample_cutoffs = factor(
      effective_sample_cutoffs,
      levels = c(
        "Less than 30",
        "Over 30 but 100 or less",
        "Over 100 but 300 or less",
        "Greater than 300"
      )
    )
  ) 

# Get suppression factor for each year of data
suppression_factor <- reactable_data %>%
  group_by(year) %>%
  summarize(yearly_total = n()) %>% 
  select(year, yearly_total)

# Create reactable for further examination
reactable_data %>%
  left_join(suppression_factor, by="year") %>% 
  group_by(year,effective_sample_cutoffs) %>%
  summarize(
    n = n(), 
    suppression_share = n()/unique(yearly_total)
  ) %>% 
  # yearly value has one unique value per year %>%
  reactable()

```

Generate the quality variable for each county.
```{r}
metrics_employment_all <- metrics_employment_all %>% 
  mutate(effective_sample_flag = ifelse(effective_sample < 100, 1, 0),
         share_employed_quality = case_when(effective_sample_flag==0 & geographic_allocation_quality==1 ~ 1,
                                     effective_sample_flag==0 & geographic_allocation_quality==2 ~ 2,
                                     effective_sample_flag==0 & geographic_allocation_quality==3 ~ 3,
                                     effective_sample_flag==1 ~ 3)
  )
```

We do not want to show values that are calculated from less than 30 samples in the data. These points will be suppressed and shown as missing or NA. Suppress the results for values generated from less than 30 samples.
```{r}
metrics_employment_all <- metrics_employment_all %>% 
  mutate_at(c("share_employed"), ~if_else(effective_sample < 30, NA_integer_, .)) 
```

Keep only relevant variables.
```{r}
metrics_employment_all <- metrics_employment_all %>%
  select(year,
         statefip,
         county,
         share_employed,
         share_employed_quality)
```


### Subgroup

Create share employed by race/ethnicity at the county-level (5-year data) using the survey_mean function.
```{r}
metrics_employment_subgroup <- acs_survey_subgroups %>%
  group_by(year, crosswalk_period, statefip, county, subgroup) %>%
  summarise(
    share_employed = survey_mean(employed, vartype = NULL)
  ) %>% 
  ungroup() %>%
  mutate(subgroup_type = "race-ethnicity")
```

Create the share employed measure for all values in the 5-year data (non-subgroup). This will be merged onto the subgroup data. 
```{r}
metrics_employment_subgroup_all <- acs_survey_subgroups %>%
  group_by(year, crosswalk_period, statefip, county) %>%
  summarise(
    share_employed = survey_mean(employed, vartype = NULL)
  ) %>% 
  ungroup() %>%
  mutate(subgroup_type = "all",
         subgroup = "All")
```

Append the "All" version of the data.
```{r}
metrics_employment_sub <- bind_rows(metrics_employment_subgroup, metrics_employment_subgroup_all)
```

Sort by county again to double check we have 5 observations per county (All, Black, White, Hispanic, Other).
```{r}
metrics_employment_sub <- metrics_employment_sub %>%
  arrange(year, statefip, county)
```

*Create an indicator for data quality and suppression*

Calculate the effective sample count for each subgroup in all counties as well as for all records in every county in the 5-year data.
```{r}
effective_sample_sub_all <- acs_clean %>%
  filter(sample_structure == "5year") %>% 
  group_by(year, crosswalk_period, statefip, county) %>%
  summarise(effective_sample = sum(afact)) %>% 
  mutate(subgroup_type = "all",
         subgroup = "All")

effective_sample_sub <- acs_clean %>%
  filter(sample_structure == "5year") %>% 
  group_by(year, crosswalk_period, statefip, county, subgroup) %>%
  summarise(effective_sample = sum(afact)) %>% 
  mutate(subgroup_type = "race-ethnicity") %>% 
  bind_rows(effective_sample_sub_all) %>% 
  ungroup()
```

Merge the data quality flags from place_puma and effective sample to create the final data quality metric based on both size and geographic allocation.
```{r}
metrics_employment_sub <- left_join(metrics_employment_sub, county_puma, by=c("crosswalk_period", "statefip","county"))

metrics_employment_sub <- left_join(metrics_employment_sub, effective_sample_sub, by=c("year", "crosswalk_period", "statefip","county", "subgroup_type", "subgroup"))
```

Tabulate effective sample counts for each county by sugroup, defined as the sum of the afact for all records in that county. Look at the distribution of counties by potential cutoffs (30, 100, 300). This is to measure data quality for each county based on the number of records reported. 
```{r}
reactable_data <- metrics_employment_sub %>%
  mutate(
    effective_sample_cutoffs = case_when(
      effective_sample < 30 ~ "Less than 30",
      effective_sample >= 30 &
        effective_sample <= 100 ~ "Over 30 but 100 or less",
      effective_sample > 100 &
        effective_sample <= 300 ~ "Over 100 but 300 or less",
      TRUE ~ "Greater than 300"
    ),
    effective_sample_cutoffs = factor(
      effective_sample_cutoffs,
      levels = c(
        "Less than 30",
        "Over 30 but 100 or less",
        "Over 100 but 300 or less",
        "Greater than 300"
      )
    )
  ) 

# Create reactable for further examination using suppression factor defined earlier
reactable_data %>%
  left_join(suppression_factor, by="year") %>% 
  group_by(year,subgroup,effective_sample_cutoffs) %>%
  summarize(
    n = n(), 
    suppression_share = n() / unique(yearly_total)
  ) %>% 
  # yearly value has one unique value per year %>%
  reactable()
```

Generate the quality variable for each county.
```{r}
metrics_employment_sub <- metrics_employment_sub %>% 
  mutate(effective_sample_flag = ifelse(effective_sample < 100, 1, 0),
         share_employed_quality = case_when(effective_sample_flag==0 & geographic_allocation_quality==1 ~ 1,
                                     effective_sample_flag==0 & geographic_allocation_quality==2 ~ 2,
                                     effective_sample_flag==0 & geographic_allocation_quality==3 ~ 3,
                                     effective_sample_flag==1 ~ 3)
  )
```

We do not want to show values that are calculated from less than 30 samples in the data. These points will be suppressed and shown as missing or NA. Suppress the results for values generated from less than 30 samples.
```{r}
metrics_employment_sub <- metrics_employment_sub %>% 
  mutate_at(c("share_employed"), ~if_else(effective_sample < 30, NA_integer_, .)) 
```

Keep only relevant variables.
```{r}

metrics_employment_sub <- metrics_employment_sub %>%
  select(year,
         statefip,
         county,
         subgroup_type, 
         subgroup,
         share_employed,
         share_employed_quality)

```

### Evaluate results

Summarize the predictors for the 1-year and 5-year data.
```{r}
metrics_employment_all %>% 
  select(share_employed:share_employed_quality) %>% 
  summary()

metrics_employment_sub %>% 
  select(share_employed:share_employed_quality) %>% 
  summary()
```


Look at distribution of employment share by county.
```{r}

metrics_employment_all %>% 
  filter(year == 2022) %>% 
  select(share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Distribution of share employed, by county 2022 (1-year data)") +
  ylab("Density")

metrics_employment_sub %>% 
  filter(year == 2021, subgroup == "All") %>% 
  select(share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Distribution of share employed, by county 2022 (5-year data)") +
  ylab("Density")
  
```

Look at distribution of employment share by county by race from the subgroup data.
```{r}

metrics_employment_sub %>% 
  filter(year == 2021, subgroup == "Black, Non-Hispanic") %>% 
  select(county, share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Employment Share, Black") +
  ylab("Density")

metrics_employment_sub %>% 
  filter(year == 2021, subgroup == "Hispanic") %>% 
  select(county, share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Employment Share, Hispanic") +
  ylab("Density")

metrics_employment_sub %>% 
  filter(year == 2021, subgroup == "Other Races and Ethnicities") %>% 
  select(county, share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Employment Share, Other Races and Ethnicities") +
  ylab("Density")

metrics_employment_sub %>% 
  filter(year == 2021, subgroup == "White, Non-Hispanic") %>% 
  select(county, share_employed) %>% 
  ggplot(aes(x = share_employed)) +
  geom_density(alpha = 0.15) +
  theme_minimal() +
  ggtitle("Employment Share, White, Non-Hispanic") +
  ylab("Density")

```

Look at the counts of the quality flag.
```{r}
metrics_employment_all %>% 
  select(share_employed_quality) %>% 
  ggplot(aes(x = share_employed_quality)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1.0) +
  theme_minimal() +
  ggtitle("Quality Flag (1-year data)") +
  ylab("Count")

metrics_employment_sub %>% 
  select(share_employed_quality) %>% 
  ggplot(aes(x = share_employed_quality)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.3), binwidth = 1.0) +
  theme_minimal() +
  ggtitle("Quality Flag (5-year data") +
  ylab("Count")
```

Tabulate share of data suppressed by year.
```{r}
metrics_employment_all %>% 
  group_by(year) %>% 
  filter(is.na(share_employed)) %>% 
  count()

metrics_employment_sub %>% 
  group_by(year) %>% 
  filter(is.na(share_employed)) %>% 
  count()
```

## Export 

Rename state.
```{r}
metrics_employment_all <- metrics_employment_all %>% 
  rename("state" = "statefip")

metrics_employment_sub <- metrics_employment_sub %>% 
  rename("state" = "statefip")
```

Order the variables how we want.
```{r}
metrics_employment_all <- metrics_employment_all %>% 
  select(year, state, county, share_employed, share_employed_quality)

metrics_employment_sub <- metrics_employment_sub %>% 
  select(year, state, county, subgroup_type, subgroup, share_employed, share_employed_quality)
```

Export as CSV

```{r}
write_csv(metrics_employment_all, here::here("09_employment", "data", "final", "metrics_employment_county_all_longitudinal.csv"))
write_csv(metrics_employment_sub, here::here("09_employment", "data", "final", "metrics_employment_county_race-ethnicity_longitudinal.csv"))
```





