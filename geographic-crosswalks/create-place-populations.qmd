---
title: "Create Place Population File"
author: "Aaron R. Williams"
date: today
abstract: "This script pulls US Census Bureau Population Estimation Program and Decennial Census data to create a list of places with population estimates for 2015-2023. It then creates a stub file for putting together the population files."
format: 
  html:
    toc: true
embed-resources: true
execute: 
  message: false
  warning: false
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
library(tidyverse)
library(tidycensus)
library(assertr)
library(here)
library(urbnthemes)
set_urbn_defaults("print")
options(scipen = 999)
```

## 2015-2019

```{r}
#| label: get-pop-2015-2019
#' Get population estimates from the US Census Bureau Population Estimation Program
#'
#' @param year An integer for the year of interest
#'
#' @return A data frame with estimate for all US counties
#'
get_pop <- function(year) {
  pop <- tidycensus::get_estimates("place", year = year, variables = "POP") %>%
    mutate(year = year)

  return(pop)
}


# pull county population data for each year from the Population Estimates Program
pep_2015_2019 <- map_dfr(
  .x = 2015:2019,
  .f = ~ get_pop(year = .x)
)
```

## 2020

```{r}
#| label: get-pop-2020
# pull the 2020 decennial census
census2020 <- get_decennial(
  geography = "place",
  year = 2020,
  variables = "P1_001N",
  keep_geo_vars = TRUE
) |>
  select(NAME, GEOID, variable, value) |>
  mutate(year = 2020)
```

## Combine

We combine the PEP data and decennial census data
```{r}
#| label: combine-pop

pop <- bind_rows(pep_2015_2019, census2020)

# drop unnecessary variable and rename the useful variable
pop <- pop %>%
  select(-variable) %>%
  rename(
    population = value,
    place_state_name = NAME,
    state_place = GEOID
  )

pop <- pop |>
  separate(place_state_name, into = c("place_name", "state_name", "c", "d", "e"), sep = ",") |>
  mutate(
    state_name = str_squish(state_name),
    place_name = str_squish(place_name)
  ) |>
  mutate(
    state = str_sub(state_place, start = 1, end = 2),
    place = str_sub(state_place, start = 3, end = 7)
  ) |>
  select(year, state, place, state_name, place_name, population) %>%
  arrange(year, state, place)
```


The [Population Estimates Program](https://www.census.gov/data/datasets/time-series/demo/popest/2020s-counties-total.html) data isn't available through the Census Bureau API for later years. Ideally, we would download the files and use them. Unfortunately, the files have inconsistencies so we skip this step for now. 

## 2021-2023

```{r}
# Specify URL where source data file is online
placeurl <-
  "https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/cities/totals/sub-est2023.csv"

# Specify destination where file should be saved (the .gitignore folder for your local branch)
destfileplace <- here("geographic-crosswalks", "data", "raw", "sub-est2023.csv")

# Import the data file & save locally
if (!file.exists(destfileplace)) {
  download.file(placeurl, destfileplace, mode = "wb")
}

pep_2021_2023 <- read_csv(destfileplace) %>%
  rename_with(tolower) %>%
  # Convert state to character and add a leading zero
  mutate(
    state = str_pad(state, width = 2, pad = "0"),
    place = str_pad(place, width = 2, pad = "0")
  ) %>%
  mutate(across(c(state, place), as.character)) %>%
  filter(sumlev == 162) %>%
  select(
    state, place,
    state_name = stname,
    place_name = name,
    starts_with("popestimate")
  ) %>%
  # remove unnecessary data before reshaping
  filter(place != "00000") %>%
  # reshape by place
  pivot_longer(
    cols = starts_with("popestimate"),
    names_to = "year",
    values_to = "population"
  ) %>%
  mutate(
    year = as.numeric(str_remove(string = year, pattern = "popestimate")),
  ) %>%
  filter(year > 2020)
```

The PEP file includes disaggregations of places and duplicate places. We drop these. 

```{r}
pep_2021_2023 <- pep_2021_2023 |>
  filter(!str_detect(place_name, pattern = "(pt\\.)")) |>
  distinct(year, state, place, state_name, place_name, population)
```

## 2014

```{r}
# Specify URL where source data file is online
placeurl14 <-
  "https://www2.census.gov/programs-surveys/popest/datasets/2010-2014/cities/totals/sub-est2014_all.csv"

# Specify destination where file should be saved (the .gitignore folder for your local branch)
destfileplace14 <- here("geographic-crosswalks", "data", "raw", "sub-est2014.csv")

# Import the data file & save locally
if (!file.exists(destfileplace14)) {
  download.file(placeurl14, destfileplace14, mode = "wb")
}

pep_2014 <- read_csv(destfileplace14) %>%
  rename_with(tolower) %>%
  # Convert state to character and add a leading zero
  mutate(
    state = str_pad(state, width = 2, pad = "0"),
    place = str_pad(place, width = 5, pad = "0")
  ) %>%
  mutate(across(c(state, place), as.character)) %>%
  filter(sumlev == 162) |>
  select(
    state, place,
    state_name = stname,
    place_name = name,
    starts_with("popestimate")
  ) %>%
  # remove unnecessary data before reshaping
  filter(place != "00000") %>%
  # reshape by place
  pivot_longer(
    cols = starts_with("popestimate"),
    names_to = "year",
    values_to = "population"
  ) %>%
  mutate(
    year = as.numeric(str_remove(string = year, pattern = "popestimate")),
  ) %>%
  filter(year > 2013) 
```


The PEP file includes disaggregations of places and duplicate places. We drop these. 

```{r}
pep_2014 <- pep_2014 %>%
  filter(!str_detect(place_name, pattern = "(pt\\.)")) %>%
  distinct(year, state, place, state_name, place_name, population)
```

## Combine Data

```{r}
final_population <- bind_rows(
  pep_2014,
  pop,
  pep_2021_2023
)

final_population <- final_population |>
  arrange(year, state, place, state_name, place_name)
```

## Subset Data

We are only interested in incorporated places with more than 75,000 people in 2020. We use a specific file from PEP to create a list of 486 FIPS of interest. 

```{r}
# Specify URL where source data file is online
placeurl <-
  "https://www2.census.gov/programs-surveys/popest/datasets/2020-2022/cities/totals/sub-est2022.csv"

# Specify destination where file should be saved (the .gitignore folder for your local branch)
destfileplace <- here("geographic-crosswalks", "data", "raw", "sub-est2022.csv")

# Import the data file & save locally
if (!file.exists(destfileplace)) {
  download.file(placeurl, destfileplace, mode = "wb")
}

pep_2022 <- read_csv(here("geographic-crosswalks/data/raw/sub-est2022.csv")) |>
  mutate(state_place = paste0(STATE, PLACE))

my_places <- pep_2022 |>
  filter(POPESTIMATE2020 > 75000, SUMLEV == "162") |>
  pull(state_place)

final_population <- final_population |>
  filter(paste0(state, place) %in% my_places)
```

**Check:** Are there places on the cutoff of our population threshold?

```{r}
# Plotting Population for All Places with Threshold Line
places_near_threshold <-
  pep_2022 |>
  filter(SUMLEV == "162") |>
  mutate(
    distance_from_threshold = if_else(POPESTIMATE2020 < 75 * 1e3,
      75 * 1e3 - POPESTIMATE2020,
      0
    )
  ) |>
  filter(distance_from_threshold > 0) |>
  # filter(between(distance_from_threshold, 1, 10*1e3)) |>
  select(state_place, POPESTIMATE2020, distance_from_threshold)

ggplot(places_near_threshold, aes(x = distance_from_threshold)) +
  geom_histogram(binwidth = 1000) +
  labs(
    title = "Distribution of Places by Distance from 75k Population Threshold",
    x = "Distance from 75,000 Population Threshold",
    y = "Number of Places"
  )
```

Zooming in on places that are 10,000 below our cut-off
```{r}
places_near_threshold |>
  filter(between(distance_from_threshold, 1, 10 * 1e3)) |>
  ggplot(aes(x = distance_from_threshold)) +
  geom_histogram(binwidth = 1000) +
  labs(
    title = "Distribution of Places by Distance from 75k Population Threshold",
    x = "Distance from 75,000 Population Threshold",
    y = "Number of Places"
  )
```


There are `r places_near_threshold |>filter(between(distance_from_threshold, 1, 10*1e3)) |> count(state_place) |> nrow()` places that are within 10,000 of our 75,000 population threshold.

## Evaluation

```{r}
final_population |>
  count(year) |>
  assert(
    in_set(485, 486),
    n
  )
```

```{r}
population_test <- final_population |>
  filter(year > 2015) |>
  group_by(state, place) |>
  mutate(
    pop_change = population - lag(population),
    prop_pop_change = (population - lag(population)) / lag(population)
  ) |>
  ungroup()

population_test |>
  ggplot(aes(population, pop_change)) +
  geom_point(alpha = 0.1) +
  facet_wrap(~year) +
  labs(title = "Population change in different years")

population_test |>
  ggplot(aes(population, prop_pop_change)) +
  geom_point(alpha = 0.1) +
  facet_wrap(~year) +
  labs(title = "Proportional population change in different years")
```

We can look at the places with the largest proportion change. 

```{r}
population_test |>
  slice_max(abs(prop_pop_change), n = 30) |>
  print(n = Inf)
```

We can look at places with the largest absolute change in population. 

```{r}
population_test |>
  slice_max(abs(pop_change), n = 30) |>
  print(n = Inf)
```

We can look at places with FIPS that don't show up in every year. 

```{r}
final_population |>
  group_by(state, place) |>
  mutate(fips_frequency = n()) |>
  filter(fips_frequency != 8) |>
  ungroup() |>
  distinct(state, place, state_name, place_name) |>
  print(n = Inf)
```

We can look at places with place names that don't show up in every year. 

```{r}
final_population |>
  group_by(state_name, place_name) |>
  mutate(fips_frequency = n()) |>
  filter(fips_frequency != 8) |>
  ungroup() |>
  distinct(state, place, state_name, place_name) |>
  print(n = Inf)
```

## Save Data

The PEP data are reported using the geographies at the time the estimates were generated. This means the 2023 data include Connecticut's planning regions in 2021 even though they didn't exist at that point. Accordingly, we will download earlier data. 

```{r}
# We have 486 cities from 2018-2023, so for 6 years we should have 2916 observations.
# South Fulton city, Georgia was incorporated in 2017, so we only
# have population estimates for this city from 2018-2023. Therefore, from 2014-2017, 
# for 4 years we should have 485 observations for each, or 1940 total.
# Overall, should have 2916+1940, which is why we have 4856 total observations

write_csv(
  x = final_population,
  file = here::here("geographic-crosswalks/data/place-populations.csv")
)
```
