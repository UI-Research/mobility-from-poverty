---
title: "Ratios of Housing Units Affordable--and Affordable and Available--to Low-Income Households, by Income Thresholds and Tenure"
author: Will Curran-Groome
date: today
abstract: "This file produces two interrelated metrics describing housing affordability: 1) the ratio between housing units affordable at various income levels and the number of households at or below those income levels; and 2) the ratio between housing units affordable and available at various income levels and the number of households at or below those income levels."
date-format: "MMM YYYY"
params: 
  output_file: "placeholder.html"
  geography: "place"
  county_years: !expr c(2022)
  place_years: !expr c(2022)
format: 
  html:
    toc: true
    code-line-numbers: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Overview

> "These \[metrics\] reflect the availability (or shortage) of housing affordable to households with low incomes. Housing is considered “affordable” when monthly costs fall at or below 30 percent of a household’s income. Affordability addresses whether a community’s housing stock would be sufficient if units were allocated solely to people that could afford them. A unit is affordable and available at a given income level if it (1) meets our definition of affordable for that income level and (2) is either vacant or occupied by a renter or owner with the same or a lower income. Income groups are defined for a family of four." ([Source](https://upward-mobility.urban.org/sites/default/files/2024-09/Upward_Mobility_Data_Dashboard_Appendix.pdf))

First, we aim to describe the ratio of units that are affordable (i.e., cost less than or equal to 30% of household income) to the number of low-income households. We provide these estimates at three income thresholds: 30%, 50%, and 80% of the area median income (AMI), and subset by tenure.

This first metric is insightful but does not account for affordable units that are occupied by households above the low-income AMI thresholds; for example, a household earning 100% of AMI might be renting a housing unit that would be affordable to a household earning 80% of AMI. However, such a unit is not meaningfully available to households earning 80% AMI because it's already occupied. When this phenomenon exists at scale, a community's stock of affordable housing--as measured in the first metric--may appear appropriate relative to its number of low-income households, but many of these low-income household may be unable to access this affordable housing due to competition from relatively higher-income households.

Our second metric accounts for this dynamic and measures the ratio of units that are affordable *and available* to the number of low-income households. We provide these estimates at the same income thresholds (30%, 50%, and 80% of AMI), and subset by tenure.

Below is an example of the structure of the data we will produce. Note that the final data also includes quality indicators for each of the metrics (not shown here). This script is used to produce both county- and place-level estimates, though it must be re-run to generate estimates for each geography, with the geography specified in the file `params` at top.

```{r, echo = FALSE}
tibble::tribble(
  ~ year, ~ state, ~ county, ~subgroup, ~subgroup_type, ~ ratio_affordable_30ami,
  ~ ratio_affordable_50ami, ~ ratio_affordable_80ami, ~ ratio_affordable_available_30ami, 
  ~ ratio_affordable_available_50ami, ~ ratio_affordable_available_80ami,
  2022, "01", "01000", "tenure", "owner", 0.5, 0.6, 0.7, 0.4, 0.5, 0.6) |>
  knitr::kable()
```

### Analysis notes

-   Unlike some other scripts and metrics in the Upward Mobility Metrics repository, this script produces two metrics. This is because these metrics, and the underlying data used to generate them, are closely interrelated. This script also produces estimates at two geographies (the place and county levels). To specify the intended geography, users need only change the `geography` variable in the YAML `params` section at the top of the document. Similarly, the years can be specified in the `params` section.

-   This analysis relies on 1-year American Community Survey (ACS) microdata from IPUMS. These data are used to generate estimates of housing units and households by income at the Public Use Microdata Area (PUMA) geography. We then attribute PUMA-level estimates to our geography of interest (either places or counties).

-   Some of the key features of this analysis include:

    -   Microdata are available for occupied and vacant housing units separately, so we need to submit two queries for microdata from IPUMS.

    -   Housing costs are captured under multiple variables in the microdata, and some housing costs are not itemized in the microdata. Further, housing cost-related variables differ based on tenure. We standardize housing costs across vacant and occupied units and for rented and owned units so that we can compare annual housing costs to annual household incomes, which we benchmark against Department of Housing and Urban Development (HUD)-defined income thresholds.

    -   These income thresholds are defined by HUD relative to the area median income (AMI). Generally, HUD calculates AMI thresholds at the county level, but in some states in New England, AMI thresholds vary at the sub-county level. We need to interpolate these AMI threshold to our geography of interest (either places or counties).

    -   Our estimates of affordable and available units are by definition a subset of our estimate affordable units. That is to say: every affordable and available unit is affordable, but not every affordable unit is available.

    -   Quality checks are consolidated in a single sub-section at the end of this file. Users should refer to comments in the code for clarity on programming decisions and other technical notes (e.g., descriptions relating to joins between datasets). Because joins are such a frequent source of error, every join in this script leverages the `tidylog` wrapper around `dplyr::left_join()`, which automatically generates output describing the join. If undesired, CTRL+F "tidylog::" and replace-all with "".

### Analysis process

0.  [**Configuration and setup**]{.underline}, including specifying parameters for output data (years and geographies) and loading dependencies

1.  [**Download microdata**]{.underline} from the IPUMS API and crosswalk it to our geographies of interest

2.  [**Import microdata**]{.underline}, separately for vacant and occupied units

    -   For vacant units for sale, sum mortgage, taxes, and insurance estimates to produce a `total_monthly_cost` estimate

    -   For vacant units for rent, adjust the existing monthly gross rent variable to account for inconsistencies in measurement of utilities and fuels costs as part of gross rent:

        -   Using the occupied rental unit data, calculate average ratio of monthly cost vs advertised price of renting, i.e., `ratio = RENTGRS / RENT`, by place or county

        -   Join these averages calculated above back to our vacant rental microdata and adjust `RENTGRS` such that `RENTGRS = RENT * ratio`. This improves the comparability of housing costs for vacant rental units to the housing costs of other housing units in our data

3.  [**Import AMI levels**]{.underline} for each Fair Market Rent (FMR) area (the geography at which FMRs are calculated)

    1.  Where there are AMIs at the sub-county level, group by county and take the mean of the sub-county AMIs
    2.  When producing place-level estimates, interpolate county-level AMIs to the place level using a county-place, population-weighted crosswalk

4.  [**Generate AMI indicators**]{.underline} for our vacant and occupied microdata that capture whether each household or housing unit is affordable and, separately, available at each of our three AMI thresholds

5.  [**Aggregate and calculate metrics**]{.underline}, summarizing by county/place and combining the two datasets so that we have a single dataset with counts of households/units by affordability/availability

6.  [**Finalize and export the data**]{.underline}, creating data quality flags, applying data suppression for geographies with unreliable data, and clean and restructuring the data into its final form

7.  [**Conduct quality checks**,]{.underline} with an emphasis on testable assertions (expectations for the form of the data) that return explicit error messages on failure

### Code authorship and updates

-   Will Curran-Groome (2024-2025)

    -   Added estimates based on 2023 microdata.
    -   Backfilled estimates for years 2014:2019, 2021:2022. 
    -   Reorganized scripts and added additional quality checks.

-   Amy Rogin (2023-2024)

-   Tina Chelidze (2022-2023)

-   Based on processes developed by Paul Johnson and Kevin Werner in SAS.

## Step 0: Configuration and setup

```{r}
library(tidyverse)
library(ipumsr)
library(readxl)
library(here)
library(urbnthemes)
library(openxlsx) 
library(testthat)
library(janitor)
options(scipen = 99999) ## no scientific notation

geography = params$geography
place_years = params$place_years %>% unlist()
county_years = params$county_years %>% unlist()

place_years_check = all(place_years %>% as.numeric %in% c(2014:2019, 2021:2023))
county_years_check = all(county_years %>% as.numeric %in% c(2014:2019, 2021:2023))

## valid arguments for the geography parameter are "place" and "county"
stopifnot(geography %in% c("place", "county"))
## valid arguments for the place and county years parameters are 2014-2019 and 2021-2023
stopifnot(all(c(place_years_check, county_years_check)))

source(here("functions", "testing", "evaluate_final_data.R"))
temporary_data_path = here("02_housing", "data", "temp")
```

## Step 1: Download microdata

-   Submit queries to the API, separately, for both occupied and vacant housing unit data
-   Note that this will take approximately one hour if you have not downloaded these data previously.
-   Crosswalk the microdata from PUMAs to the geography of interest

### Basic setup

```{r}
####----Setup-----####
temporary_data_path = here("02_housing", "data", "temp")

if (!dir.exists(temporary_data_path)) {
  dir.create(temporary_data_path, recursive = TRUE)
}
```

### Download occupied housing microdata from the IPUMS API

More information on the API can be found here: <https://cran.r-project.org/web/packages/ipumsr/vignettes/ipums-api.html> If you don't already have one, you will need register for an IPUMS API key here: <https://uma.pop.umn.edu/usa/registration/new>

```{r}
extract_housing_microdata = function(year) {
  define_extract_micro(
    collection = "usa",
    description = "Housing microdata extract", # description of extract
    samples = c(paste0("us", year, "a")), # use ACS data
    variables = c(
      "HHWT", ## household weight -- appropriate for statements about households
      "PERWT", ## person weight -- appropriate for statements about individuals
      "REPWT",
      "PERNUM", 
      "ADJUST", 
      "STATEFIP", ## 2-character state FIPS code
      "PUMA", ## code identifying the public-use microdata area (PUMA)
      "GQ", ## "general quarters"--identifies the household type
      "OWNERSHP", 
      "OWNCOST", 
      "RENT", 
      "RENTGRS", 
      "HHINCOME",
      "VALUEH", 
      "VACANCY", 
      "EDUC", 
      "EDUCD", 
      "GRADEATT", 
      "EMPSTAT", 
      "AGE", 
      "KITCHEN", 
      "PLUMBING"),
    data_structure = "rectangular") %>% 
    submit_extract() %>% 
    wait_for_extract() %>% 
    download_extract(download_dir = temporary_data_path) %>% 
    read_ipums_ddi() %>% 
    # roughly 3.3 million records
    read_ipums_micro() %>% 
    rename(
      "puma" = "PUMA",
      "statefip" = "STATEFIP") %>%
    mutate(
      statefip = sprintf("%0.2d", as.numeric(statefip)),
      puma = sprintf("%0.5d", as.numeric(puma))) %>% 
    arrange(statefip, puma) %>%
    # save temp file with API pull
    write_csv(here(temporary_data_path, paste0("housing_microdata_", year, ".csv")))
}
  
# Helper function to check for the presence of already-downloaded microdata
get_years_to_query = function(
  directory = here("02_housing", "data", "temp"), 
  years, 
  geography) {
  
  extant_years = list.files(directory) %>%
    keep(~ str_detect(.x, str_c("crosswalked_pumas_", geography, "_(", paste0(years, collapse = "|"), ").csv"))) %>%
    str_extract("[0-9]{4}")
  
  years_to_query = years[!years %in% (extant_years)]
}

# If microdata have not been previously queried and stored locally, do so now
# by appplying our microdata function across all outstanding years
years_to_query = get_years_to_query(years = county_years, geography = geography)
if (length(years_to_query) > 0) {
  walk(years_to_query, extract_housing_microdata)
}
```

### Download vacant housing microdata from the IPUMS API

```{r}
# Function for querying the API - vacant unit data
extract_vacancy_microdata = function(year) {
  define_extract_micro(
    collection = "usa",
    description = "Vacancy microdata extract",
    samples = c(paste0("us", year, "a")),
    variables = list( ## a list is necessary to accommodate the var_spec() object
      "HHWT", 
      "REPWT",
      var_spec("GQ", case_selections = c("0")), # just download cases where GQ == 0 (vacant)
      "ADJUST", 
      "STATEFIP", 
      "PUMA", 
      "VALUEH", 
      "VACANCY",
      "RENTGRS",
      "RENT", 
      "KITCHEN", 
      "PLUMBING"),
    data_structure = "hierarchical") %>% 
    submit_extract() %>% 
    wait_for_extract() %>% 
    download_extract(download_dir = temporary_data_path) %>% 
    read_ipums_ddi() %>% 
    read_ipums_micro() %>% 
    rename(
      "puma" = "PUMA",
      "statefip" = "STATEFIP") %>%
    mutate(
      statefip = sprintf("%0.2d", as.numeric(statefip)),
      puma = sprintf("%0.5d", as.numeric(puma))) %>% 
    arrange(statefip, puma) %>%
    write_csv(here(temporary_data_path, paste0("vacancy_microdata_", year, ".csv")))
}
  
# If microdata have not been previously queried and stored locally, do so now
# by appplying our microdata function across all outstanding years
if (length(years_to_query) > 0) {
  walk(years_to_query, extract_vacancy_microdata)
}
```

### Crosswalk microdata from PUMAs to geography of interest

```{r}
# Function for writing lightly tailored crosswalks to a temporary folder for subsequent use

puma_geography_crosswalk = function(year, geography) {
  crosswalk_period = year
  
  if (as.numeric(crosswalk_period) < 2022) {
    crosswalk_period = "pre-2022"
  } 
  ## at a minimum for 2023, the period listed in the crosswalk is 2022
  ## we adjust here accordingly
  else if (as.numeric(crosswalk_period) >= 2022) {
    crosswalk_period = 2022
  }
  
  crosswalk = here("geographic-crosswalks", "data", paste0("crosswalk_puma_to_", geography, ".csv")) %>%
    read_csv() %>% 
    filter(
      statefip != 72, ## dropping PR-based records
      crosswalk_period == !!crosswalk_period,
      afact != 0) %>%
    ## we ensure we have an accurate record of the year for joining purposes later
    { if (crosswalk_period %in% c(2022:2023)) mutate(., year = year) else . }

  crosswalk %>%
    write_csv(here(temporary_data_path, paste0("crosswalked_pumas_", geography, "_", year, ".csv")))
  
  crosswalk %>%
    { if (geography == "place") group_by(., statefip, place) else group_by(., statefip, county) } %>%
    summarize(puma_flag = mean(geographic_allocation_quality)) %>%
    write_csv(here(temporary_data_path, paste0("crosswalked_pumas_quality_", geography, "_", year, ".csv")))
}

## Apply the function across all relevant geography-years
walk(place_years, ~ puma_geography_crosswalk(year = .x, geography = "place"))
walk(county_years, ~ puma_geography_crosswalk(year = .x, geography = "county"))

# Function for applying crosswalks to microdata
crosswalk_microdata = function(year, geography) {
  # we clear out unused objects here due to possible memory constraints
  gc()

  # read in the appropriate crosswalk 
  puma_crosswalk = read_csv(here(temporary_data_path, paste0("crosswalked_pumas_", geography, "_", year, ".csv")))

  # keep only the variables we need
  read_csv(here(temporary_data_path, paste0("housing_microdata_", year, ".csv"))) %>% 
    select(
      HHWT,
      ADJUST,
      statefip,
      puma,
      GQ,
      OWNERSHP,
      OWNCOST,
      RENT,
      RENTGRS,
      HHINCOME,
      VALUEH,
      VACANCY,
      PERNUM,
      PERWT,
      EDUC,
      EDUCD,
      GRADEATT,
      EMPSTAT,
      AGE) %>%
    mutate(
      microdata_id = row_number(),
      statefip = str_pad(statefip, side = "left", width = 2, pad = "0"),
      puma = str_pad(puma, side = "left", width = 5, pad = "0")) %>%
    # Join our PUMA-to-place/county crosswalk to our PUMA-level microdata
    # All, or virtually all, rows should join from both dataframes
    tidylog::left_join(
      puma_crosswalk, 
      by = c("statefip", "puma"),
      relationship = "many-to-many") %>%
    { if (geography == "place") mutate(., geography_code = str_c(statefip, place)) else mutate(., geography_code = str_c(statefip, county)) } %>%
    filter(
      !is.na(afact),
      afact > 0) %>%
    mutate(
      ## these are NA codes that we recode to true missing values
      OWNCOST = if_else(OWNCOST == 99999, NA, OWNCOST),
      # the weight of each person/household is adjusted by the area of the PUMA that falls into a given place
      across(.cols = c(PERWT, HHWT), .fns = ~ .x * afact), 
      # adjusts dollar-denominated variables by the Census's 12-month adjustment factor
      across(.cols = c(HHINCOME, RENT, RENTGRS, OWNCOST), .fns = ~ .x * ADJUST)) %>%
    write_csv(here(temporary_data_path, paste0(geography, "_prepared_microdata_", year, ".csv")))
}

gc()
# Apply crosswalks to all geography-year combinations
walk(county_years, ~ crosswalk_microdata(year = .x, geography = "county"))
walk(place_years, ~ crosswalk_microdata(year = .x, geography = "place"))
```

## Step 2: Prepare microdata

-   Combine data across years
-   Filter to only include "households"--i.e., where `GQ` values are less than 3--and to exclude various types of group quarters, which do not comprise part of the typical housing market
-   Filter to retain only a single record per household--i.e., where `PERNUM == 1`--to avoid double-counting households

For more information: [https://usa.ipums.org/usa-action/variables/GQ#codes_section](https://usa.ipums.org/usa-action/variables/GQ#codes_sectionhttps://usa.ipums.org/usa-action/variables/GQ#codes_section)

```{r}
## combine microdata across years
housing_microdata = list.files(here(temporary_data_path), full.names = TRUE) %>%
  # keep all file names that match the appropriate geography and one of the data years
  keep(
    ~ str_detect(
        .x, 
        str_c(geography, "_prepared_microdata_", 
          str_c("(", paste0(get(str_c(geography, "_years")), collapse = "|"), ")")))) %>%
  # for each filename, read in the data, add the year from the filename,
  # filter to relevant records, and drop unneeded columns
  map_dfr(
    ~ read_csv(.x) %>% 
        mutate(
          # "0" represents NA: https://usa.ipums.org/usa-action/variables/RENT#codes_section
          # And, though not noted in IPUMS documentation, this also applies for the
          # RENTGRS variable
          across(
            .cols = c(RENT, RENTGRS), 
            .fns = ~ if_else(.x == 0, NA, .x)),
          year = str_extract(.x, "[0-9]{4}"),
          VALUEH = if_else(VALUEH == 9999999, NA, VALUEH),
          crosswalk_period = as.character(crosswalk_period)) %>%
        filter(
          PERNUM == 1, # one observation per household
          GQ < 3) %>% # exclude group quarters
        ## dropping columns we don't use in this analysis
        select(-c(PERWT, EDUC, EDUCD, GRADEATT, EMPSTAT, AGE)))

if (geography == "county") {
  years = county_years } else {
  years = place_years
}

test_that(
  "All years are in housing data / no other years are in housing data",
  {
    expect_equal(
      housing_microdata %>%
        count(year) %>%
        pull(year) %>%
        as.numeric %>%
        sort(),
      years) })
```

The housing microdata does not include vacant units, which we query separately from the IPUMS API. Here, we prepare the vacant unit-specific microdata. Later, we will combine vacant units with occupied units to produce estimates of the whole housing stock.

-   Filter to only include units that are vacant for rent, vacant for sale, or rented/sold but not yet occupied (`VACANCY %in% c(1:3)`) -- these are the units that are part of the conventional housing market.
-   Derive an estimate of total monthly housing costs for each vacant unit, incorporating mortgage costs, insurance costs, and property taxes.

Note: `ADJUST` standardizes income variables within a calendar year. See here for more information: <https://usa.ipums.org/usa/acsincadj.shtml>.

```{r}
vacancy_microdata = list.files(here(temporary_data_path), full.names = TRUE) %>%
  # keep all file names that match the appropriate geography and one of the data years
  keep(
    ~ str_detect(
        .x, 
        str_c("vacancy_microdata_", 
          str_c("(", paste0(get(str_c(geography, "_years")), collapse = "|"), ")")))) %>%
  # for each filename, read in the data, add the year from the filename,
  # filter to relevant records, calculate a total monthly cost variable,
  # and drop unneeded columns
  map_dfr(
    ~ read_csv(.x) %>% 
      filter(
        VACANCY %in% c(
          1, # for rent
          2, # for sale
          3)) %>% # rented or sold but not yet occupied
      # Convert 9999999 to NA and then multiply by ADJUST for all non-missing observations
      mutate(
        year = YEAR,
        # "0" represents NA: https://usa.ipums.org/usa-action/variables/RENT#codes_section
        # And, though not noted in IPUMS documentation, this also applies for the
        # RENTGRS variable
        across(
          .cols = c(RENT, RENTGRS), 
          .fns = ~ if_else(.x == 0, NA, .x)),
        VALUEH = if_else(VALUEH == 9999999, NA, VALUEH * ADJUST),
        loan_amount = 0.9 * VALUEH,
        monthly_mortgage_cost = .005, # monthly interest
        # this calculates monthly compounding interest on a 30-year fixed-rate mortgage
        monthly_principal_interest_cost = loan_amount * monthly_mortgage_cost * 
          ((1 + monthly_mortgage_cost) ** 360) / (((1 + monthly_mortgage_cost) ** 360) - 1),
        # typical annual private mortgage insurance is .007 of loan amount per year
        monthly_private_mortgage_insurance_cost = (.007 * loan_amount) / 12, 
        # taxes assumed to be 25% of monthly principal and interest
        monthly_taxes_cost = .25 * monthly_principal_interest_cost, 
        monthly_cost_total = monthly_principal_interest_cost + 
          monthly_private_mortgage_insurance_cost + monthly_taxes_cost,
        crosswalk_period = if_else(year < 2022, "pre-2022", "2022")) %>%
      # drop unneeded columns
      select(year, crosswalk_period, puma, statefip, HHWT, ADJUST, RENT, RENTGRS, VALUEH, monthly_cost_total))

test_that(
  "All years are in vacancy data / no other years are in vacancy data",
  {
    expect_equal(
      vacancy_microdata %>%
        count(year) %>%
        pull(year) %>%
        as.numeric %>%
        sort(),
      years) })
```

`RENTGRS` provides a more comparable estimate of total rental costs than does `RENT`, which may or may not include utilities and fuels. While `RENTGRS` is available for rented units, it is not available for vacant units. To improve the comparability of rental costs for vacant units, we:

-   Calculate the ratio between `RENTGRS` and `RENT` for each rented unit

-   Group by state, geography (county/place), and year, and calculate a weighted average of this `RENTGRS`/`RENT` ratio (weighted by our `HHWT` variable)

-   In a following step, we join these weighted averages back to our vacant unit data and use them to adjust the `RENT` variable

For more information see: [https://usa.ipums.org/usa-action/variables/RENTGRS#description_section](https://usa.ipums.org/usa-action/variables/RENTGRS#description_sectionhttps://usa.ipums.org/usa-action/variables/RENTGRS#description_section)

```{r}
# Import crosswalks to merge PUMAs to places and counties
crosswalk_path = if_else(
  geography == "place", 
  here("geographic-crosswalks", "data", "crosswalk_puma_to_place.csv"),
  here("geographic-crosswalks", "data", "crosswalk_puma_to_county.csv"))

puma_crosswalk = read_csv(crosswalk_path) %>%
  mutate(GEOID = str_c(statefip, .data[[geography]])) %>%
  # omitting Puerto Rico PUMAs, for which we do not calculate estimates
  filter(statefip != 72)

# Calculate RENTGRS/RENT ratios and associated weighted means by geography for 
# occupied units
rent_ratio = housing_microdata %>%
  # Keep only renter households
  filter(OWNERSHP == 2) %>%
  mutate(
    year = year %>% as.numeric,
    ratio_rentgrs_rent = RENTGRS / RENT) %>% 
  # Calculate weighted mean ratio by geography x year
  group_by(statefip, .data[[geography]], year) %>% 
  summarize(
    weighted_mean_ratio_rentgrs_rent = weighted.mean(
      ratio_rentgrs_rent, w = HHWT, na.rm = TRUE)) %>%
  ungroup()

# join places/counties to pumas using the crosswalk
vacant_crosswalk = tidylog::left_join(
    vacancy_microdata, 
    puma_crosswalk, 
    by = c("statefip", "puma", "crosswalk_period"),
    relationship = "many-to-many") %>%
  mutate(
    year = year %>% as.numeric,
    GEOID = str_c(statefip, .data[[geography]])) %>%
  # limit only to places/counties of interest
  filter(GEOID %in% puma_crosswalk$GEOID) %>%
  tidylog::left_join(rent_ratio, by = c("statefip", geography, "year")) %>%
  mutate(
    across(.cols = c(year, statefip, !!geography), .fns = as.character),
    RENTGRS = RENT * weighted_mean_ratio_rentgrs_rent)
```

## Step 3: Import AMI data

HUD publishes annual AMI levels and associated thresholds for 30%, 50%, and 80% of AMI. These levels are available for "Fair Market Rent" (FMR) geographies, which are typically but not always counties.

In this section, we:

-   Import the AMI data from HUD

-   Crosswalk the AMI thresholds to our geographies of interest

```{r}
# Access via https://www.huduser.gov/portal/datasets/il.html#data_2022
income_limits_urls_1 = c(
  "https://www.huduser.gov/portal/datasets/il/il14/Poverty.xls",
  "https://www.huduser.gov/portal/datasets/il/il15/Section8_Rev.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il16/Section8-FY16.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il17/Section8-FY17.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il18/Section8-FY18.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il19/Section8-FY19.xlsx",
# we don't produce 2020-based estimates due to data quality limitations for ACS data
# "https://www.huduser.gov/portal/datasets/il/il21/Section8-FY20.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il21/Section8-FY21.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il22/Section8-FY22.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il23/Section8-FY23.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il23/Section8-FY24.xlsx")

income_limits_urls = tibble(
    urls = income_limits_urls_1,
    url_years = c(2014:2019, 2021:2024)) %>%
  filter(url_years %in% years)

download_hud_income_limits = function(year, url) {
  filename = str_split(url, "/") %>% .[[1]] %>% .[[length(.)]]
  download.file(url = url, destfile = here(temporary_data_path, filename), mode = "wb")

  # Import the data file as a dataframe
  fmr_income_limits = readxl::read_excel(path = here(temporary_data_path, filename)) %>% 
    janitor::clean_names() %>%
    ## the name for the fips variable changes in the 2023 data
    {if (year == 2023) rename(., fips2010 = fips) else (.)} %>%
    transmute(
      year = year,
      fips = fips2010,
      across(
        .cols = c(state, county), 
        .fns = as.character),
      state = str_pad(state, side = "left", width = 2, pad = "0"), 
      county = str_pad(county, side = "left", width = 3, pad = "0"),
      sub_county = str_sub(fips, 6, 10) %>% if_else(. == "99999", NA, .),
      # _4 denotes the level applies to a four-person household
      # ELI_4 is 30% of median rent: Extremely low-income
      # l50_4 is 50% of median rent: Very low-income
      # l80_4 is 80% of median rent: Low-income
      level_30ami = eli_4,
      level_50ami = l50_4,
      level_80ami = l80_4)
  
  return(fmr_income_limits)
}

# download and combine income limits data into one file
fmr_income_limits = map2_dfr(
    years, income_limits_urls$urls, 
    download_hud_income_limits)
```

Income limits are specified at one of two geographies: the county (mostly), or the sub-county (in some areas in New England). We need to translate the income limits to our geography of interest (either the county-level or the place-level). We do this as follows:

-   We aggregate our income limits to the county level. For most counties, this doesn't require any work, because there's only a single income limit for the county. For counties with sub-county-level income limits, we take the mean of these limits.

-   For the case where we're producing place-level estimates, we then interpolate the county-level income limits to the place level, weighting by 2020 population.

```{r}
# stop("Connecticut data are at the former county level (n = 8), rather than the new county level for 2022 onwards (n = 9). This needs to be fixed, if possible...")
county_income_limits1 = fmr_income_limits %>%
  group_by(year, state, county) %>%
  summarize(
    across(
      .cols = matches("ami"),
      .fns = mean)) %>%
  ungroup()
  
geography_pad_width = if_else(geography == "place", 5, 3)

county_income_limits2 = county_income_limits1 %>%
  transmute(
    county,
    GEOID = str_c(state, county),
    statefip = state,
    # "{geography}" := str_pad(
    #   as.numeric(.data[[geography]]), side = "left", width = geography_pad_width, pad = "0"),
    year,
    across(.cols = matches("ami"))) %>%
  filter(!str_detect(statefip, "^72"))

## in 2017, Valdez-Cordova Census Area -- a county-equivalent geography -- is abolished
## and is replaced by Chugach Census Area and Copper River Census Area, both of which
## are also county-equivalent geographies. While Valdez-Cordova is listed in the HUD
## AMI limits data, our ACS microdata are crosswalked to the current Census Areas.
## Accordingly, we adjust our income limits data such that the AMI thresholds for 
## Valdez-Cordova are associated both with Chugach and Copper River Census Areas.

county_income_limits3 = tibble(
  county_current = c("063", "066"),
  county_old = c("261")) %>%
  left_join(
    county_income_limits2 %>%
      filter(statefip == "02"),
    by = c("county_old" = "county"),
    relationship = "many-to-many") %>%
  select(-county_old) %>%
  rename(county = county_current) %>%
  mutate(GEOID = str_c(statefip, county))
  
county_income_limits = county_income_limits2 %>%  
  filter(!(statefip == "02" & county == "261")) %>%
  bind_rows(county_income_limits3) %>%
  rename(state = statefip) %>%
  # american samoa, guam, northern mariana islands, virgin islands
  filter(!state %in% c("60", "66", "69", "78")) %>%
  mutate(across(.cols = c(state, county, year), .fns = as.character))

if (geography == "place") {
  county_place_crosswalk = read_csv(
      here("geographic-crosswalks", "data", "geocorr2022_county_place.csv")) %>% 
    mutate(
      state = str_pad(as.numeric(state), side = "left", width = 2, pad = "0"),
      place = str_pad(as.numeric(place), side = "left", width = 5, pad = "0"))
  
  place_income_limits = county_income_limits %>%
    tidylog::left_join(county_place_crosswalk, by = c("state", "county")) %>%
    group_by(state, place, year) %>%
    summarize(
      across(
        .cols = matches("ami"),
        .fns = ~ weighted.mean(x = .x, na.rm = TRUE, w = pop20))) %>%
    ungroup() %>%
    mutate(
      across(.cols = c(state, place, year), .fns = as.character),
      GEOID = str_c(state, place))
  
  crosswalked_income_limits = place_income_limits
} else { crosswalked_income_limits = county_income_limits }
```

## Step 4: Generate AMI indicators

Here we calculate which units are affordable for a family of four at 80%, 50%, and 30% of AMI (regardless of the actual unit size). We also create variables for total population at 80% AMI, 50% AMI, and 30% AMI, including breakdowns for renter and owner subgroups. "Affordable" means costs are \<= 30% of the household's income. For owners, we use the housing cost, and for renters, we use the gross rent.

```{r}
## these are data on occupied housing units
household_affordability = tidylog::left_join(
    housing_microdata, 
    crosswalked_income_limits, 
    by = c("statefip" = "state", geography, "year"),
    relationship = "many-to-one") %>%
  mutate(
    ## all households below ami levels
    across(
      .cols = matches("ami$"),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        is.na(HHINCOME) ~ NA,
        HHINCOME <= .x ~ 1, 
        TRUE ~ 0),
      .names = "all_below_{.col %>% stringr::str_extract('[0-9]{2}ami')}"),
    ## renters below ami levels
    across(
      .cols = c(all_below_80ami, all_below_50ami, all_below_30ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        OWNERSHP == 1 ~ NA,
        .x == 1 & OWNERSHP == 2 ~ 1, 
        TRUE ~ .x),
      .names = "renter_{.col %>% stringr::str_remove('all_')}"),
    ## owners below ami levels
    across(
      .cols = c(all_below_80ami, all_below_50ami, all_below_30ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        OWNERSHP == 2 ~ NA,
        .x == 1 & OWNERSHP == 1 ~ 1, 
        TRUE ~ .x),
      .names = "owner_{.col %>% stringr::str_remove('all_')}"),
    ## this standardized cost variable simplifies subsequent calculations
    applicable_housing_cost = if_else(OWNERSHP == 2, RENTGRS, OWNCOST),
    ## renter households with affordable housing costs
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(applicable_housing_cost) ~ NA,
        is.na(OWNERSHP) ~ NA,
        OWNERSHP == 1 ~ NA, ## if it is a owner-occupied household, return NA
        OWNERSHP == 2 & applicable_housing_cost * 12 <= .x * .3 ~ 1,
        TRUE ~ 0), 
      .names = "renter_affordable_{.col}"),
    ## owner households with affordable housing costs
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(applicable_housing_cost) ~ NA,
        is.na(OWNERSHP) ~ NA,
        OWNERSHP == 2 ~ NA, ## if it is a renter-occupied household, return NA
        OWNERSHP == 1 & applicable_housing_cost * 12 <= .x * .3 ~ 1,
        TRUE ~ 0), 
      .names = "owner_affordable_{.col}"),
    ## any households with affordable housing costs
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(applicable_housing_cost) ~ NA,
        applicable_housing_cost * 12 <= .x * .3 ~ 1, 
        TRUE ~ 0), 
      .names = "all_affordable_{.col}"),
    ## calculating affordable and available across all subgroups (and overall)
    across(
      .cols = matches("affordable"), # e.g., all_affordable_level_80ami
      # if the unit is affordable at the given AMI level and is occupied by a household 
      # at or below that AMI level
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        is.na(get(str_replace(cur_column(), "affordable_level", "below"))) ~ NA,
        .x == 1 & get(str_replace(cur_column(), "affordable_level", "below")) == 1 ~ 1,
        TRUE ~ 0),
      .names = "{.col %>% stringr::str_replace('affordable', 'available')}"))
```

```{r}
## these are data on vacant housing units
vacant_affordability = tidylog::left_join(
    vacant_crosswalk, 
    crosswalked_income_limits, 
    by = c("statefip" = "state", geography, "year"),
    relationship = "many-to-one") %>%
  mutate(
    ## binary indicators 
    ## for rental units, if adjusted annual rent is less than or equal to the given 
      ## AMI level
    ## for ownership units, if estimated annual housing cost is less than or equal
      ## to the given AMI level for all units
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        RENTGRS > 0 ~ (RENTGRS * 12) <= (.x * .3),
        !is.na(VALUEH) ~ (monthly_cost_total * 12) <= (.x * .3), 
        is.na(VALUEH) ~ NA),
      .names = "all_affordable_{.col}"),
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        RENTGRS > 0 ~ (RENTGRS * 12) <= (.x * .3)),
      .names = "renter_affordable_{.col}"),
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        !is.na(VALUEH) ~ (monthly_cost_total * 12) <= (.x * .3), 
        is.na(VALUEH) ~ NA),
      .names = "owner_affordable_{.col}"),
    # convert booleans to integers
    across(matches("affordable"), ~ as.integer(.x)))
```

## Step 5: Aggregate and calculate metrics

```{r}
household_affordability_summed = household_affordability %>% 
  group_by(statefip, .data[[geography]], year) %>%
  summarize( 
    # get unweighted counts for quality flags, adjusting for spatial interpolation using afact
    across(
      .cols = matches("below"), 
      .fns = ~ sum(.x * afact, na.rm = TRUE),
      .names = "{.col}_quality"),
    # get weighted counts for actual statistics/estimates
    across(
      .cols = c(matches("below|affordable|available"), -matches("quality")), 
      .fns = ~ sum(.x * HHWT, na.rm = TRUE))) %>% 
  ungroup() %>%
  rename("state" = "statefip")

vacant_affordability_summed = vacant_affordability %>% 
  group_by(statefip, .data[[geography]], year) %>%
  summarize(
    across(
      .cols = matches("affordable"), 
      .fns = ~ sum(.x * HHWT, na.rm = TRUE), 
      .names = "{.col}_vacant")) %>% 
  ungroup() %>%
  rename("state" = "statefip")

## here we (finally) combine our occupied and vacant data
housing_summed = tidylog::left_join(
    household_affordability_summed, 
    vacant_affordability_summed, 
    by = c("state", geography, "year"),
    relationship = "one-to-one") %>% 
  ungroup() %>%
  mutate(
    ## share affordable and available
    across(
      .cols = matches("available"),
      # available and affordable occupied units + all vacant units (by definition 
      # available) / all affordable units
      .fns = ~ (
        .x + ## available, occupied units
        ## vacant units
        get(str_c(cur_column() %>% str_replace("available", "affordable"), "_vacant"))) / 
        ## households at or below income level
        get(str_replace(cur_column(), "available_level", "below")), 
      .names = "share_{.col}"),
    ## all households
    ## the sum of housing units -- both vacant and occupied -- that are affordable
    ## at a given AMI level divided by the number of households below that AMI level
    across(
      .cols = c(matches("below"), -matches("quality")),
      .fns = ~ 
        (get(str_c(str_replace(cur_column(), "below", "affordable_level"))) +
        get(str_c(str_replace(cur_column(), "below", "affordable_level"), "_vacant"))) / .x,
      .names = "share_{.col %>% stringr::str_replace('below', 'affordable_level')}")) 
```

## Step 6: Finalize and export data

If the unweighted sum of interpolated households is under 30, we suppress that cell because it is likely to be highly imprecise.

```{r}
# read in the puma interpolation quality files, these contain `puma_flag`, 
# which provides a score from 1-3 describing the mean geographic allocation quality 
# for each 
years = if_else(
  geography == "county", 
  paste0(county_years, collapse = "|"), 
  paste0(place_years, collapse = "|"))

puma_interpolation_quality = list.files(here(temporary_data_path), full.names = TRUE) %>%
  # keep all file names that match the appropriate geography and one of the data years
  keep(
    ~ str_detect(
        .x, 
        str_c("crosswalked_pumas_quality_", geography, "_", str_c("(", years, ")")))) %>%
  map_dfr(
    ~ read_csv(.x) %>%
      mutate(year = str_extract(.x, "[0-9]{4}"))) %>%
  rename(state = statefip)

# combine minimum cell size standards (n = 30) with the puma interpolation quality 
# scores to assign each cell a quality flag
housing_summed_quality =  tidylog::left_join(
    housing_summed,
    puma_interpolation_quality, 
    by = c("state", geography, "year"),
    relationship = "one-to-one") %>%
  mutate(
    ## if there are fewer than 30 unweighted observations, assign the quality variable 
    ## a score of one
    across(
      .cols = matches("quality"),
      .fns = ~ if_else(.x < 30, 1, 0)),
    ## if the quality score is 1, suppress the data (set the cell to NA), otherwise
    ## assign the quality variable the value of the mean geographic allocation quality 
    ## variable 
    across(
      .cols = matches("quality"), 
      .fns = ~ if_else(.x == 1, NA, puma_flag)))

# turn long for subgroup output
housing_subgroups = housing_summed_quality %>%
  select(state, !!geography, year, matches("share|quality")) %>% 
  ## rename columns to facilitate re-structuring
  rename_with(
    .cols = matches("quality"),
    .fn = ~ .x %>% str_remove("_quality") %>% 
      str_replace("below", "affordable_quality_level") %>% str_c("share_", .)) %>% 
  ## the quality values are the same for available and affordable, but we duplicate them
  ## (with different column names) for the available estimates, for consistency
  mutate(
    across(
      .cols = matches("quality"),
      .fns = ~ .x,
      .names = "{.col %>% stringr::str_replace('affordable', 'available')}")) %>% 
  ## restructure so that each row is a geography x year x subgroup combination
  pivot_longer(
    cols = matches("share_"), 
    names_to = c("subgroup", "measure_type", "ami"),
    names_pattern = "share_(all|renter|owner)_(affordable_|affordable_quality_|available_|available_quality_)level_([0-9]{2}ami)",
    values_to = "value") %>%
  pivot_wider(
    names_from = c(measure_type, ami),
    names_sep = "", 
    values_from = value) %>%
  ## convert from "share" to "ratio" in metric names; these are not shares, they're ratios
  rename_with(
    .cols = matches("affordable|available"), 
    .fn = ~ str_c("ratio_", .x)) %>%
  mutate(
    subgroup_type = "tenure",
    subgroup = subgroup %>% str_to_sentence,
    # suppress cells with insufficient quality scores
    across(
      .cols = c(matches("ratio"), -matches("quality")), 
      .fns = ~ if_else(
        is.na(get(cur_column() %>% str_replace_all(
          c("affordable" = "affordable_quality", "available" = "available_quality")))), 
        NA, 
        .x))) %>%
  ## clean up variable names slightly and reorder columns for export
  rename_with(
    .cols = matches("quality"),
    .fn = ~ str_remove(.x, "quality_") %>% str_c(., "_quality")) %>%
  ## if the metric is missing, set the corresponding quality variable to missing
  mutate(
    across(
      .cols = matches("quality"), 
      .fns = ~ if_else(is.na(get(cur_column() %>% str_remove("_quality"))), NA, .x))) %>%
  select(year, state, !!geography, subgroup_type, subgroup, matches("ratio")) %>%
  arrange(state, .data[[geography]], subgroup, desc(year))

housing_overall = housing_subgroups %>% 
  filter(subgroup == "All")

years = if_else(
  geography == "county", 
  paste0(county_years, collapse = "_"), 
  paste0(place_years, collapse = "_"))

# export the final data
write_csv(
  housing_overall, 
  here("02_housing", "data", "final", str_c("housing_", geography, "_", years, ".csv")))
write_csv(
  housing_subgroups, 
  here("02_housing", "data", "final", str_c("housing_", geography, "_", years, "_subgroups.csv")))
```

## Step 7: Conduct quality checks

The final dataset, including all subgroups, meets all the assertions contained in `evaluate_final_data.R`.

```{r}
# test_that(
#   "The final data passes standardized QC checks", {
#     expect_no_error(
#       evaluate_final_data(
#         exp_form_path = here(
#           "02_housing", "housing_affordability_tenure_final_data_evaluation_form.csv"),
#         data = housing_subgroups,
#         geography = geography,
#         subgroups = TRUE,
#         confidence_intervals = FALSE))})
```

### Data Assertions

***Geographic Universe Alignment***

The counts of distinct geographies (places/counties) align with expected counts for each geography for each year.

```{r}
population_listing = read_csv(here("geographic-crosswalks", "data", paste0(geography, "-populations.csv"))) %>%
  mutate(
    year = as.character(year),
    geoid = str_c(state, .data[[geography]]))

geography_universe = population_listing %>%
  group_by(year) %>%
  summarize(geography_count = n_distinct(geoid))

# This fails because of Valdez-Cordova, AK (2014-2019)
# for counties
# For places, this fails because of South Fulton
test_that(
  "Counts of places/counties are correct for each year", {
  expect_true(
    all(
      housing_subgroups %>%
        group_by(year, subgroup) %>%
        summarize(
          geography_count_analysis = n_distinct(state, .data[[geography]])) %>%
        tidylog::left_join(geography_universe, by = "year") %>%
        mutate(check = geography_count == geography_count_analysis) %>%
        pull(check)))})
```

***Values Are Not Negative***

Both metrics are ratios and cannot be negative. We extend the assumption and assert that no ratios are equal to zero, which mathematically is feasible but practically is highly unlikely.

```{r}
test_that(
  "No ratios are negative or zero", {
  expect_true(
    housing_overall %>%
      filter(if_any(.cols = c(matches("ratio"), -matches("quality")), .fns = ~ .x <= 0)) %>%
      nrow() == 0)})
```

***Ratio of Available is Not Greater than Ratio of Affordable***

Affordable-and-available ratios by definition must be equal to or lesser than the corresponding affordable ratio.

```{r}
test_that(
  "Affordable-and-available ratios are less than or equal to affordable ratios", {
  expect_true(
    housing_overall %>%
      select(-matches("quality")) %>%
      mutate(
        across(
          .cols = c(matches("ratio_affordable"), ),
          .fns = ~ .x - get(str_replace(cur_column(), "affordable", "available")),
          .names = "{.col}_difference")) %>%
      arrange(ratio_affordable_80ami_difference) %>%
      filter(if_any(.cols = matches("difference"), .fns = ~ .x < 0)) %>% 
      nrow() == 0)})
```

***There Are No Breaking Changes to Prior Years' Estimates***

Unless substantive changes have been made to the process of calculating the metrics, every metric value for every geography calculated during the current cycle should be exactly the same as the value calculated during the preceding year.

```{r}
## data are available from this URL: https://datacatalog.urban.org/dataset/mobility-metrics-data-upward-mobility-framework
## specific links used in the code will likely need to be updated year-to-year

if (geography == "place") {
  metrics_prior1 = read_csv(
    ## this corresponds to longitudinal, place-level metrics that are broken down by tenure
    "https://urban-data-catalog.s3.amazonaws.com/drupal-root-live/2024/09/67_mobility-metrics_place_tenure_longitudinal.csv")
} else {
    metrics_prior1 = read_csv(
    ## this corresponds to longitudinal, county-level metrics that are broken down by tenure
    "https://urban-data-catalog.s3.amazonaws.com/drupal-root-live/2024/09/17_mobility-metrics_county_tenure_longitudinal.csv")
}

metrics_prior = metrics_prior1 %>%
  select(
    state, state_name, year, any_of(c("place", "place_name", "county", "county_name")),
    subgroup, subgroup_type, share_affordable_80_ami, share_affordable_50_ami,
    share_affordable_30_ami, share_affordable_available_80_ami, share_affordable_available_50_ami,
    share_affordable_available_30_ami) %>%
  ## just looking at the subgroups; if they pass these tests, then the "All" subgroup
  ## should as well
  filter(year %in% c(place_years, county_years), subgroup != "All") %>%
  rename_with(
    .cols = matches("share"),
    .fn = ~ str_replace_all(
      .x, c("share" = "ratio", "affordable_available" = "available", "_ami" = "ami")) %>% str_c("_prior")) %>%
  mutate(year = as.character(year))

metrics_differences_wide = metrics_prior %>%
  tidylog::left_join(
    housing_subgroups %>%
      mutate(subgroup = subgroup %>% str_to_sentence) %>%
      select(-subgroup_type, -matches("quality")),
    by = c("state", geography, "year", "subgroup")) %>%
  filter(year == 2022)

metrics_differences_wide_plot = metrics_differences_wide %>%
  transmute(
    state, state_name, year, 
    !!geography,
    !!(str_c(geography, "_name")),
    subgroup,
    across(
    .cols = matches("prior"),
      .fns = ~ round((.x - get(cur_column() %>% str_remove("_prior"))), digits = 2),
      .names = "{.col %>% stringr::str_remove('_prior')}_difference"),
    across(
      .cols = matches("_difference"),
      .fns = ~ if_else(.x != 0, 1, 0),
      .names = "{.col}_flag"))

metrics_differences_wide_plot %>%
  pivot_longer(cols = matches("difference_flag")) %>%
  group_by(name, subgroup) %>%
  summarize(
    count = sum(!is.na(value)), 
    value = sum(value, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(
    name = name %>% str_replace_all("_", " ") %>% str_to_sentence %>% str_remove(" difference flag"),
    percent = value / count) %>%
  ggplot() +
  geom_col(aes(x = name, y = percent, fill = subgroup), position = "dodge") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Share of non-missing geographies with differences in calculated values for 2022 data, 2024 vs. 2023" %>% str_wrap(90),
    y = "", x = "") +
  theme_urbn_print()

metrics_differences_wide_plot %>%
  pivot_longer(cols = matches("difference$")) %>%
  arrange(value) %>%
  mutate(name = name %>% str_replace_all("_", " ") %>% str_to_sentence) %>%
  ggplot() +
    geom_histogram(aes(x = value, fill = name)) +
    facet_wrap(~ subgroup) +
  scale_y_continuous(labels = scales::comma) +
  theme_urbn_print() +
  labs(
    title = "Differences in calculated values for 2022 data, 2023 vs. 2024",
    x = "Difference in value, 2023 vs 2024",
    y = "Count")
```

```{r}
# test_that(
#   "Values produced for the most recent year's data, using the current year's codebase,
#   are the same as those produced the prior year", {
#   expect_true(
#     metrics_prior %>%
#       tidylog::left_join(
#         housing_subgroups %>%
#           mutate(subgroup = subgroup %>% str_to_sentence) %>%
#           select(-subgroup_type, -matches("quality")),
#         by = c("state", geography, "year", "subgroup")) %>%
#       transmute(
#         year,
#         state,
#         !!geography,
#         across(
#           .cols = matches("prior"),
#           .fns = ~ if_else(.x != get(cur_column() %>% str_remove("_prior")), 1, 0))) %>%
#       summarize(across(matches("prior"), ~ sum(.x, na.rm = TRUE))) %>%
#       pivot_longer(everything()) %>%
#       pull(value) %>%
#       max() == 0)
#   })
```

### Data descriptions

***Missingness***

We anticipate that county-level data will have greater missingness than place-level data as there are many counties with very small populations, whereas our places are by definition reasonably large. We also anticipate that subgroup metrics have greater missingness as compared to our overarching metrics because they rely on subsets of the total population of households.

```{r}
housing_subgroups %>% 
  group_by(year) %>%
  select(c(matches("ratio"), -matches("quality"))) %>%
  summarize(
    across(
      .cols = everything(), 
      .fns = ~ round(sum(is.na(.)) / n() * 100, 0),
      .names = "{.col}_percent_missing"))
```

***Distributions***

We anticipate the the distributions for a given metric will be similar across years, and that the peaks of distributions will be generally be lower for lower AMI levels.

```{r}
housing_subgroups %>% 
  select(c(subgroup, year, matches("ratio"), -matches("quality"))) %>%
  pivot_longer(-c(subgroup, year)) %>%
  filter(str_detect(name, "affordable")) %>%
  mutate(name = name %>% str_replace_all("_", " ") %>% str_to_sentence()) %>%
  ggplot() +
    geom_histogram(aes(x = value, fill = subgroup)) +
    facet_wrap(~ name + year, ncol = 9) +
    labs(title = "Distribution of affordable ratios, by subgroup", y = "Frequency", x = "Ratio") +
    scale_y_continuous(labels = scales::comma) +
    theme_urbn_print()

housing_subgroups %>% 
  select(c(subgroup, year, matches("ratio"), -matches("quality"))) %>%
  pivot_longer(-c(subgroup, year)) %>%
  filter(str_detect(name, "available")) %>%
  mutate(name = name %>% str_replace_all("_", " ") %>% str_to_sentence()) %>%
  ggplot() +
    geom_histogram(aes(x = value, fill = subgroup)) +
    facet_wrap(~ name + year, ncol = 9) +
    labs(title = "Distribution of available ratios, by subgroup", y = "Frequency", x = "Ratio") +
    scale_y_continuous(labels = scales::comma) +
    theme_urbn_print()
```

***Year-over-year Changes***

Metrics generally should not exhibit huge year-over-year changes within the same geography (or across geographies). We expect that:

-   The distribution of year-over-year changes in the 80% AMI ratios should show the least variation.

-   Conversely, the 30% AMI ratios should show the most variation because this AMI threshold encompasses fewer households and housing units, leading to greater percentage variability year-over-year.

```{r}
if (length(c(county_years, place_years) %>% unique) > 1) {

housing_subgroups %>%
  select(-matches("quality")) %>%
  pivot_longer(cols = c(matches("ratio"))) %>%
  filter(value > .01) %>%
  arrange(desc(year), state, .data[[geography]], subgroup, name) %>%
  group_by(state, .data[[geography]], subgroup, name) %>%
  mutate(year_over_year_change = (value - lead(value)) / lead(value)) %>%
  filter(!is.na(year_over_year_change)) %>%
  ungroup() %>%
 ## without this exception, some places have huge percentage changes year-over-year
  arrange(desc(abs(year_over_year_change))) %>%
  ggplot() +
    geom_histogram(aes(x = year_over_year_change, fill = subgroup)) +
    facet_wrap(~ name) +
    urbnthemes::theme_urbn_print() +
    labs(
      x = "Percent annual change in metric",
      y = "Count",
      title = "Metrics should show relatively little year-over-year variation with distributions clustered around 0%",
      subtitle = "Distributions of year-over-year changes in housing affordability and availability metrics, by AMI level and subgroup") +
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(labels = scales::percent)
}
```

***Alignment with NLIHC Estimates***

Estimates should generally align with estimates produced by NLIHC as part of their "The GAP" series. We've provided values from their most recent (as of writing) publication, which relies on 2022 data.

```{r}
# data from: https://nlihc.org/sites/default/files/gap/2024/Gap-Report_2024.pdf
#  Appendix B

if (geography == "county") {

nlihc_estimates_metro = tribble(
  ~`Metro Area`, ~`At or below ELI`, ~`At or below 50% AMI`, ~`At or below ELI`,
  ~`At or below 50% AMI`, ~`At or below 80% AMI`, ~`At or below 100% AMI`,
  ~`At or below ELI`, ~`31% to 50% AMI`, ~`51% to 80% AMI`, ~`81% to 100% AMI`,
  "Atlanta-Sandy Springs-Alpharetta, GA", -122791, -161422, 25, 44, 90, 104, "81%", "45%", "10%", "2%",
  "Austin-Round Rock-Georgetown, TX", -60429, -74883, 21, 46, 95, 101, "87%", "32%", "6%", "2%",
  "Baltimore-Columbia-Towson, MD", -65241, -68527, 33, 57, 94, 100, "73%", "33%", "9%", "1%",
  "Boston-Cambridge-Newton, MA-NH", -117411, -147169, 46, 56, 87, 97, "64%", "36%", "9%", "3%",
  "Buffalo-Cheektowaga, NY", -33156, -22727, 37, 72, 98, 100, "73%", "28%", "4%", "4%",
  "Charlotte-Concord-Gastonia, NC-SC", -45765, -58064, 35, 55, 95, 105, "75%", "39%", "7%", "2%",
  "Chicago-Naperville-Elgin, IL-IN-WI", -239240, -230890, 29, 58, 93, 98, "77%", "31%", "7%", "3%",
  "Cincinnati, OH-KY-IN", -49510, -32868, 41, 76, 98, 101, "72%", "22%", "5%", "3%",
  "Cleveland-Elyria, OH", -56560, -33012, 38, 77, 98, 100, "70%", "21%", "6%", "2%",
  "Columbus, OH", -52694, -48343, 26, 62, 99, 103, "75%", "29%", "6%", "2%",
  "Dallas-Fort Worth-Arlington, TX", -179108, -244497, 17, 40, 91, 104, "86%", "41%", "8%", "2%",
  "Denver-Aurora-Lakewood, CO", -65454, -93256, 27, 41, 92, 103, "75%", "43%", "5%", "3%",
  "Detroit-Warren-Dearborn, MI", -99583, -85325, 32, 63, 98, 102, "74%", "24%", "5%", "3%",
  "Hartford-East Hartford-Middletown, CT", -32956, -22866, 34, 70, 98, 100, "71%", "24%", "5%", "2%",
  "Houston-The Woodlands-Sugar Land, TX", -184283, -230680, 15, 40, 91, 103, "83%", "37%", "7%", "3%",
  "Indianapolis-Carmel-Anderson, IN", -50554, -38789, 23, 67, 100, 103, "82%", "21%", "4%", "2%",
  "Jacksonville, FL", -32328, -40303, 29, 47, 87, 102, "79%", "48%", "14%", "2%",
  "Kansas City, MO-KS", -46042, -43045, 36, 66, 99, 103, "76%", "28%", "7%", "3%",
  "Las Vegas-Henderson-Paradise, NV", -60344, -91209, 13, 23, 67, 93, "88%", "59%", "19%", "8%",
  "Los Angeles-Long Beach-Anaheim, CA", -380006, -582884, 21, 27, 55, 75, "80%", "59%", "23%", "8%",
  "Louisville/Jefferson County, KY-IN", -30218, -20647, 31, 70, 99, 102, "72%", "20%", "4%", "2%",
  "Memphis, TN-MS-AR", -29064, -29323, 36, 59, 95, 103, "79%", "42%", "15%", "1%",
  "Miami-Fort Lauderdale-Pompano Beach, FL", -140763, -226085, 23, 25, 50, 74, "81%", "72%", "29%", "12%",
  "Milwaukee-Waukesha, WI", -44596, -28174, 30, 75, 97, 100, "75%", "30%", "4%", "3%",
  "Minneapolis-St. Paul-Bloomington, MN-WI", -79282, -73248, 28, 61, 96, 101, "73%", "33%", "4%", "2%",
  "Nashville-Davidson--Murfreesboro--Franklin, TN", -35086, -46507, 36, 53, 91, 102, "74%", "37%", "7%", "2%",
  "New Orleans-Metairie, LA", -35856, -44558, 29, 43, 93, 104, "77%", "42%", "11%", "1%",
  "New York-Newark-Jersey City, NY-NJ-PA", -656458, -802969, 32, 46, 80, 93, "74%", "41%", "13%", "5%",
  "Oklahoma City, OK", -34735, -28604, 33, 66, 103, 105, "78%", "29%", "4%", "4%",
  "Orlando-Kissimmee-Sanford, FL", -56895, -94715, 18, 24, 61, 88, "87%", "63%", "23%", "4%",
  "Philadelphia-Camden-Wilmington, PA-NJ-DE-MD", -153236, -142974, 34, 61, 93, 101, "74%", "31%", "6%", "2%",
  "Phoenix-Mesa-Chandler, AZ", -89838, -128908, 19, 34, 77, 98, "82%", "50%", "13%", "4%",
  "Pittsburgh, PA", -44088, -21259, 49, 84, 105, 106, "67%", "17%", "3%", "1%",
  "Portland-Vancouver-Hillsboro, OR-WA", -56972, -80971, 25, 39, 91, 100, "77%", "44%", "7%", "2%",
  "Providence-Warwick, RI-MA", -39709, -40786, 49, 66, 96, 100, "59%", "29%", "4%", "0%",
  "Raleigh-Cary, NC", -23357, -18385, 37, 74, 121, 123, "71%", "29%", "4%", "1%",
  "Richmond, VA", -37164, -30226, 24, 60, 96, 101, "77%", "39%", "6%", "2%",
  "Riverside-San Bernardino-Ontario, CA", -72055, -113722, 21, 34, 66, 82, "81%", "52%", "23%", "8%",
  "Rochester, NY", -29134, -22090, 35, 68, 97, 101, "71%", "32%", "3%", "1%",
  "Sacramento-Roseville-Folsom, CA", -56693, -75930, 23, 38, 79, 96, "81%", "49%", "14%", "3%",
  "San Antonio-New Braunfels, TX", -55338, -82623, 28, 37, 89, 104, "75%", "43%", "12%", "2%",
  "San Diego-Chula Vista-Carlsbad, CA", -82307, -126617, 20, 27, 64, 84, "82%", "59%", "20%", "7%",
  "San Francisco-Oakland-Berkeley, CA", -132227, -153670, 32, 48, 85, 96, "69%", "34%", "9%", "2%",
  "San Jose-Sunnyvale-Santa Clara, CA", -45752, -57912, 33, 48, 87, 100, "73%", "29%", "9%", "2%",
  "Seattle-Tacoma-Bellevue, WA", -101139, -143381, 26, 39, 90, 99, "76%", "42%", "6%", "2%",
  "St. Louis, MO-IL", -63984, -31506, 35, 80, 100, 102, "71%", "17%", "4%", "2%",
  "Tampa-St. Petersburg-Clearwater, FL", -69630, -94696, 21, 36, 74, 94, "83%", "50%", "21%", "6%",
  "Tucson, AZ", -26615, -34568, 24, 45, 92, 101, "78%", "40%", "7%", "3%",
  "Virginia Beach-Norfolk-Newport News, VA-NC", -42532, -54300, 26, 43, 89, 101, "80%", "48%", "8%", "2%",
  "Washington-Arlington-Alexandria, DC-VA-MD-WV", -144435, -156133, 26, 53, 96, 102, "77%", "27%", "4%", "2%") %>%
  clean_names() %>%
  select(
    metro_area,
    ratio_available_30ami_nlihc = at_or_below_eli_2,
    ratio_available_50ami_nlihc = at_or_below_50_percent_ami_2,
    ratio_available_80ami_nlihc = at_or_below_80_percent_ami) %>%
  mutate(
    county_match_geoid = case_when(
      str_detect(metro_area, "Tucson") ~ "04019",
      str_detect(metro_area, "Denver") ~ "08031",
      str_detect(metro_area, "Hartford") ~ "09003",
      str_detect(metro_area, "Washington") ~ "13121",
      str_detect(metro_area, "Jacksonville") ~ "12031",
      str_detect(metro_area, "Atlanta") ~ "13121",
      str_detect(metro_area, "Indianapolis") ~ "18097",
      str_detect(metro_area, "Baltimore") ~ "24005",
      str_detect(metro_area, "Detroit") ~ "26163",
      str_detect(metro_area, "Las Vegas") ~ "32003",
      str_detect(metro_area, "Rochester") ~ "36055",
      str_detect(metro_area, "Pittsburgh") ~ "42003",
      str_detect(metro_area, "Richmond") ~ "51159",
      str_detect(metro_area, "Milwaukee") ~ "55079",
      str_detect(metro_area, "Oklahoma") ~ "40109",
      str_detect(metro_area, "Columbus") ~ "39049")) %>%
  filter(!is.na(county_match_geoid))

nlihc_estimates_metro %>%
  tidylog::left_join(
    housing_subgroups %>% 
      filter(year == 2022, subgroup == "Renter") %>%
      mutate(geoid = str_c(state, county)) %>%
      select(c(matches("ratio_available"), -matches("quality")), geoid),
    by = c("county_match_geoid" = "geoid")) %>%
  filter(!is.na(ratio_available_30ami)) %>%
  mutate(
    across(matches("nlihc"), ~ .x / 100),
    across(matches("nlihc"), .fns = ~ .x - get(cur_column() %>% str_remove("_nlihc")), .names = "{.col}_diff")) %>%
  select(metro_area, matches("diff")) %>%
  pivot_longer(matches("diff")) %>%
  mutate(name = name %>% str_replace_all("_", " ") %>% str_to_sentence %>% str_remove_all(" nlihc diff")) %>%
  ggplot() +
    geom_point(aes(x = metro_area, y = value, color = name)) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
    coord_flip() +
    labs(x = "Metro area", y = "Ratio difference (NLIHC - Urban)") +
    theme_urbn_print()
}
```