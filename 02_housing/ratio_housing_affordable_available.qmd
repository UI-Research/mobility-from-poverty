---
title: "Ratios of Housing Units Affordable--and Affordable and Available--to Low-Income Households, by Income Thresholds and Tenure"
author: Will Curran-Groome
date: today
abstract: "This file produces two interrelated metrics describing housing affordability: 1) the ratio between housing units affordable at various income levels and the number of households at or below those income levels; and 2) the ratio between housing units affordable and available at various income levels and the number of households at or below those income levels."
date-format: "MMM YYYY"
params: 
  geography: "place"
  county_years: !expr c(2021, 2022)
  place_years: !expr c(2021, 2022)
format: 
  html:
    toc: true
    code-line-numbers: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Overview

> "These \[metrics\] reflect the availability (or shortage) of housing affordable to households with low incomes. Housing is considered “affordable” when monthly costs fall at or below 30 percent of a household’s income. Affordability addresses whether a community’s housing stock would be sufficient if units were allocated solely to people that could afford them. A unit is affordable and available at a given income level if it (1) meets our definition of affordable for that income level and (2) is either vacant or occupied by a renter or owner with the same or a lower income. Income groups are defined for a family of four." ([Source](https://upward-mobility.urban.org/sites/default/files/2024-09/Upward_Mobility_Data_Dashboard_Appendix.pdf))

First, we aim to describe the ratio of units that are affordable (i.e., cost less than or equal to 30% of household income) to the number of low-income households. We provide these estimates at three income thresholds: 30%, 50%, and 80% of the area median income (AMI), and subset by tenure.

This first metric is insightful but does not account for affordable units that are occupied by households above the low-income AMI thresholds; for example, a household earning 100% of AMI might be renting a housing unit that would be affordable to a household earning 80% of AMI. However, such a unit is not meaningfully available to households earning 80% AMI because it's already occupied. When this phenomenon exists at scale, a community's stock of affordable housing--as measured in the first metric--may appear appropriate relative to its number of low-income households, but many of these low-income household may be unable to access this affordable housing due to competition from relatively higher-income households.

Our second metric accounts for this dynamic and measures the ratio of units that are affordable *and available* to the number of low-income households. We provide these estimates at the same income thresholds (30%, 50%, and 80% of AMI), and subset by tenure.

Below is an example of the structure of the data we will produce. Note that the final data also includes quality indicators for each of the metrics (not shown here). This script is used to produce both county- and place-level estimates, though it must be re-run to generate estimates for each geography, with the geography specified in the file `params` at top.

```{r, echo = FALSE}
tibble::tribble(
  ~ year, ~ state, ~ county, ~subgroup, ~subgroup_type, ~ ratio_affordable_30ami,
  ~ ratio_affordable_50ami, ~ ratio_affordable_80ami, ~ ratio_affordable_available_30ami, 
  ~ ratio_affordable_available_50ami, ~ ratio_affordable_available_80ami,
  2022, "01", "01000", "tenure", "owner", 0.5, 0.6, 0.7, 0.4, 0.5, 0.6) |>
  knitr::kable()
```

### Analysis notes

-   Unlike some other scripts and metrics in the Upward Mobility Metrics repository, this script produces two metrics. This is because these metrics, and the underlying data used to generate them, are closely interrelated. This script also produces estimates at two geographies (the place and county levels). To specify the intended geography, users need only change the `geography` variable in the YAML `params` section at the top of the document. Similarly, the years can be specified in the `params` section.

-   This analysis relies on 1-year American Community Survey (ACS) microdata from IPUMS. These data are used to generate estimates of housing units and households by income at the Public Use Microdata Area (PUMA) geography. We then attribute PUMA-level estimates to our geography of interest (either places or counties).

-   Some of the key features of this analysis include:

    -   Microdata are provided for occupied and vacant housing units separately, so we need to submit two queries for microdata from IPUMS.

    -   Housing costs are captured under multiple variables in the microdata, and some housing costs are not itemized in the microdata. Further, housing cost-related variables differ based on tenure. We standardize housing costs across vacant and occupied units and for rented and owned units so that we can compare annual housing costs to annual household incomes, which we benchmark against Department of Housing and Urban Development (HUD)-defined income thresholds.

    -   These income thresholds are defined by HUD relative to the area median income (AMI). Generally, HUD calculates AMI thresholds at the county level, but in some states in New England, AMI thresholds vary at the sub-county level. We need to interpolate these AMI threshold to our geography of interest (either places or counties).

    -   Our estimates of affordable and available units are by definition a subset of our estimate affordable units. That is to say: every affordable and available unit is affordable, but not every affordable unit is available.

    -   Quality checks are consolidated in a single sub-section at the end of this file. Users should refer to comments in the code for clarity on programming decisions and other technical notes (e.g., descriptions relating to joins between datasets). Because joins are such a frequent source of error, every join in this script leverages the `tidylog` wrapper around `dplyr::left_join()`, which automatically generates output describing the join. If undesired, CTRL+F "tidylog::" and replace-all with "".

### Analysis process

0.  [**Configuration and setup**]{.underline}, including specifying parameters for output data (years and geographies) and loading dependencies

1.  [**Download microdata**]{.underline} from the IPUMS API and crosswalk it to our geographies of interest

2.  [**Import microdata**]{.underline}, separately for vacant and occupied units

    -   For vacant units for sale, sum mortgage, taxes, and insurance estimates to produce a `total_monthly_cost` estimate

    -   For vacant units for rent, adjust the existing monthly gross rent variable to account for inconsistencies in measurement of utilities and fuels costs as part of gross rent:

        -   Using the occupied rental unit data, calculate average ratio of monthly cost vs advertised price of renting, i.e., `ratio = RENTGRS / RENT`, by place or county

        -   Join these averages calculated above back to our vacant rental microdata and adjust `RENTGRS` such that `RENTGRS = RENT * ratio`. This improves the comparability of housing costs for vacant rental units to the housing costs of other housing units in our data

3.  [**Import AMI levels**]{.underline} for each Fair Market Rent (FMR) area (the geography at which FMRs are calculated)

    1.  Where there are AMIs at the sub-county level, group by county and take the mean of the sub-county AMIs
    2.  When producing place-level estimates, interpolate county-level AMIs to the place level using a county-place, population-weighted crosswalk

4.  [**Generate AMI indicators**]{.underline} for our vacant and occupied microdata that capture whether each household or housing unit is affordable and, separately, available at each of our three AMI thresholds

5.  [**Aggregate and calculate metrics**]{.underline}, summarizing by county/place and combining the two datasets so that we have a single dataset with counts of households/units by affordability/availability

6.  [**Finalize and export the data**]{.underline}, creating data quality flags, applying data suppression for geographies with unreliable data, and clean and restructuring the data into its final form

7.  [**Conduct quality checks**,]{.underline} with an emphasis on testable assertions (expectations for the form of the data) that return explicit error messages on failure

### Code authorship and updates

-   Will Curran-Groome (2024-2025)

    -   Added estimates based on 2023 microdata.
    -   Reorganized scripts and added additional quality checks.

-   Amy Rogin (2023-2024)

-   Tina Chelidze (2022-2023)

-   Based on processes developed by Paul Johnson and Kevin Werner in SAS.

## Step 0: Configuration and setup

```{r}
library(tidyverse)
library(ipumsr)
library(readxl)
library(here)
library(urbnthemes)
library(openxlsx) 
library(testthat)
library(survey)
library(srvyr)
options(scipen = 99999) ## no scientific notation

geography = params$geography
place_years = params$place_years %>% unlist()
county_years = params$county_years %>% unlist()

source(here("functions", "testing", "evaluate_final_data.R"))
temporary_data_path = here("02_housing", "data", "temp")
```

## Step 1: Download microdata

-   Submit queries to the API, separately, for both occupied and vacant housing unit data
-   Crosswalk the microdata from PUMAs to the geography of interest

### Basic setup

```{r}
####----Setup-----####
temporary_data_path = here("02_housing", "data", "temp")

if (!dir.exists(temporary_data_path)) {
  dir.create(temporary_data_path, recursive = TRUE)
}
```

### Download occupied housing microdata from the IPUMS API

More information on the API can be found here: <https://cran.r-project.org/web/packages/ipumsr/vignettes/ipums-api.html> If you don't already have one, you will need register for an IPUMS API key here: <https://uma.pop.umn.edu/usa/registration/new>

```{r}
extract_housing_microdata = function(year) {
  define_extract_micro(
    collection = "usa",
    description = "Housing microdata extract - with replicate weights", # description of extract
    samples = c(paste0("us", year, "a")), # use ACS data
    variables = c(
      "HHWT", ## household weight -- appropriate for statements about households
      "PERWT", ## person weight -- appropriate for statements about individuals
      "REPWT",
      "PERNUM", 
      "ADJUST", 
      "STATEFIP", ## 2-character state FIPS code
      "PUMA", ## code identifying the public-use microdata area (PUMA)
      "GQ", ## "general quarters"--identifies the household type
      "OWNERSHP", 
      "OWNCOST", 
      "RENT", 
      "RENTGRS", 
      "HHINCOME",
      "VALUEH", 
      "VACANCY", 
      "EDUC", 
      "EDUCD", 
      "GRADEATT", 
      "EMPSTAT", 
      "AGE", 
      "KITCHEN", 
      "PLUMBING"),
    data_structure = "rectangular") %>% 
    submit_extract() %>% 
    wait_for_extract() %>% 
    download_extract(download_dir = temporary_data_path) %>% 
    read_ipums_ddi() %>% 
    # roughly 3.3 million records
    read_ipums_micro() %>% 
    rename(
      "puma" = "PUMA",
      "statefip" = "STATEFIP") %>%
    mutate(
      statefip = sprintf("%0.2d", as.numeric(statefip)),
      puma = sprintf("%0.5d", as.numeric(puma))) %>% 
    arrange(statefip, puma) %>%
    # save temp file with API pull
    write_csv(here(temporary_data_path, paste0("housing_microdata_", year, ".csv")))
}
  
# Helper function to check for the presence of already-downloaded microdata
get_years_to_query = function(
  directory = here("02_housing", "data", "temp"), 
  years, 
  geography) {
  
  extant_years = list.files(directory) %>%
    keep(~ str_detect(.x, str_c("crosswalked_pumas_", geography, "_(", paste0(years, collapse = "|"), ").csv"))) %>%
    str_extract("[0-9]{4}")
  
  years_to_query = years[!years %in% (extant_years)]
}

# If microdata have not been previously queried and stored locally, do so now
# by appplying our microdata function across all outstanding years
years_to_query = get_years_to_query(years = county_years, geography = geography)
if (length(years_to_query) > 0) {
  walk(c("2021", "2022"), extract_housing_microdata)
}
```

### Download vacant housing microdata from the IPUMS API

```{r}
# Function for querying the API - vacant unit data
extract_vacancy_microdata = function(year) {
  define_extract_micro(
    collection = "usa",
    description = "Vacancy microdata extract - with replicate weights",
    samples = c(paste0("us", year, "a")),
    variables = list( ## a list is necessary to accommodate the var_spec() object
      "HHWT", 
      "REPWT",
      var_spec("GQ", case_selections = c("0")), # just download cases where GQ == 0 (vacant)
      "ADJUST", 
      "STATEFIP", 
      "PUMA", 
      "VALUEH", 
      "VACANCY",
      "RENTGRS",
      "RENT", 
      "KITCHEN", 
      "PLUMBING"),
    data_structure = "hierarchical") %>% 
    submit_extract() %>% 
    wait_for_extract() %>% 
    download_extract(download_dir = temporary_data_path) %>% 
    read_ipums_ddi() %>% 
    read_ipums_micro() %>% 
    rename(
      "puma" = "PUMA",
      "statefip" = "STATEFIP") %>%
    mutate(
      statefip = sprintf("%0.2d", as.numeric(statefip)),
      puma = sprintf("%0.5d", as.numeric(puma))) %>% 
    arrange(statefip, puma) %>%
    write_csv(here(temporary_data_path, paste0("vacancy_microdata_", year, ".csv")))
}
  
# If microdata have not been previously queried and stored locally, do so now
# by appplying our microdata function across all outstanding years
if (length(years_to_query) > 0) {
  walk(years_to_query, extract_vacancy_microdata)
}
```

### Crosswalk microdata from PUMAs to geography of interest

```{r}
# Function for writing lightly tailored crosswalks to a temporary folder for subsequent use
puma_geography_crosswalk = function(year, geography) {
  crosswalk_period = year
  
  if (as.numeric(crosswalk_period) < 2022) {
    crosswalk_period = "pre-2022"
  } 
  
  crosswalk = here("geographic-crosswalks", "data", paste0("crosswalk_puma_to_", geography, ".csv")) %>%
    read_csv() %>% 
    filter(
      statefip != 72, ## dropping PR-based records
      crosswalk_period == !!crosswalk_period,
      afact != 0) 
  
  crosswalk %>%
    write_csv(here(temporary_data_path, paste0("crosswalked_pumas_", geography, "_", year, ".csv")))
  
  crosswalk %>%
    { if (geography == "place") group_by(., statefip, place) else group_by(., statefip, county) } %>%
    summarize(puma_flag = mean(geographic_allocation_quality)) %>%
    write_csv(here(temporary_data_path, paste0("crosswalked_pumas_quality_", geography, "_", year, ".csv")))
}

## Apply the function across all relevant geography-years
walk(place_years, ~ puma_geography_crosswalk(year = .x, geography = "place"))
walk(county_years, ~ puma_geography_crosswalk(year = .x, geography = "county"))
  
message(
"2021 is missing data for place fips 72122 in Georgia. That city was incorporated 
in 2016 and the pre-2022 crosswalk uses places from 2014 so it is not captured. 
Given the limitations from GeoCorr I (Amy Rogin) don't think we can manually add it back in.")

# Quality-check the rows in each generate crosswalk
# check number of unique places in data
stopifnot(
  # 2022 data
  read_csv(here(temporary_data_path, "crosswalked_pumas_place_2022.csv")) %>% 
    distinct(statefip, place) %>% nrow() == 486,
  # 2021 data
  read_csv(here(temporary_data_path, "crosswalked_pumas_place_2021.csv")) %>% 
    distinct(statefip, place) %>% nrow() == 485)

# check number of unique counties in data
walk(
  county_years,
  ~ stopifnot(
    read_csv(here(temporary_data_path, paste0("crosswalked_pumas_county_", .x, ".csv"))) %>% 
      distinct(statefip, county) %>% nrow() == 3143))
  
# Function for applying crosswalks to microdata
crosswalk_microdata = function(year, geography) {
  
  # read in the appropriate crosswalk 
  puma_crosswalk = read_csv(here(temporary_data_path, paste0("crosswalked_pumas_", geography, "_", year, ".csv")))
  
  # keep only the variables we need
  acs_data = read_csv(here(temporary_data_path, paste0("housing_microdata_", year, ".csv"))) %>% 
    select(
      HHWT,
      ADJUST,
      statefip,
      puma,
      GQ,
      OWNERSHP,
      OWNCOST,
      RENT,
      RENTGRS,
      HHINCOME,
      VALUEH,
      VACANCY,
      PERNUM,
      PERWT,
      EDUC,
      EDUCD,
      GRADEATT,
      EMPSTAT,
      AGE) %>%
      #matches("REPWT")) %>% ## integrate this if calculating CIs
    mutate(
      microdata_id = row_number(),
      statefip = str_pad(statefip, side = "left", width = 2, pad = "0"),
      puma = str_pad(puma, side = "left", width = 5, pad = "0")) %>%
    # Join our PUMA-to-place/county crosswalk to our PUMA-level microdata
    tidylog::left_join(
      puma_crosswalk, 
      by = c("statefip", "puma"),
      relationship = "many-to-many") %>%
    { if (geography == "place") mutate(., geography_code = str_c(statefip, place)) else mutate(., geography_code = str_c(statefip, county)) } %>%
    filter(
      !is.na(afact),
      afact > 0) %>%
    mutate(
      # the weight of each person/household is adjusted by the area of the PUMA that falls into a given place
      across(.cols = c(PERWT, HHWT), .fns = ~ .x * afact), 
      # adjusts dollar-denominated variables by the Census's 12-month adjustment factor
      across(.cols = c(HHINCOME, RENTGRS, OWNCOST), .fns = ~ .x * ADJUST)) %>%
    write_csv(here(temporary_data_path, paste0(geography, "_prepared_microdata_", year, ".csv")))
}
  
# Apply crosswalks to all geography-year combinations
walk(county_years, ~ crosswalk_microdata(year = .x, geography = "county"))
walk(place_years, ~ crosswalk_microdata(year = .x, geography = "place"))
```

## Step 2: Prepare microdata

-   Combine data across years
-   Filter to only include "households"--i.e., where `GQ` values are less than 3--and to exclude various types of group quarters, which do not comprise part of the typical housing market
-   Filter to retain only a single record per household--i.e., where `PERNUM == 1`--to avoid double-counting households

For more information: [https://usa.ipums.org/usa-action/variables/GQ#codes_section](https://usa.ipums.org/usa-action/variables/GQ#codes_sectionhttps://usa.ipums.org/usa-action/variables/GQ#codes_section)

```{r}
## combine microdata across years
housing_microdata = list.files(here(temporary_data_path), full.names = TRUE) %>%
  # keep all file names that match the appropriate geography and one of the data years
  keep(
    ~ str_detect(
        .x, 
        str_c(geography, "_prepared_microdata_", 
          str_c("[", paste0(get(str_c(geography, "_years")), collapse = "|"), "]")))) %>%
  # for each filename, read in the data, add the year from the filename,
  # filter to relevant records, and drop unneeded columns
  map_dfr(
    ~ read_csv(.x) %>% 
        mutate(
          # "0" represents NA: https://usa.ipums.org/usa-action/variables/RENT#codes_section
          across(
            .cols = c(RENT, RENTGRS), 
            .fns = ~ if_else(.x == 0, NA, .x)),
          year = str_extract(.x, "[0-9]{4}"),
          VALUEH = if_else(VALUEH == 9999999, NA, VALUEH),
          crosswalk_period = as.character(crosswalk_period)) %>%
        filter(
          PERNUM == 1, # one observation per household
          GQ < 3) %>% # exclude group quarters
        ## dropping columns we don't use in this analysis
        select(-c(PERWT, EDUC, EDUCD, GRADEATT, EMPSTAT, AGE)))
```

The housing microdata does not include vacant units, which we query separately from the IPUMS API. Here, we prepare the vacant unit-specific microdata. Later, we will combine vacant units with occupied units to produce estimates of the whole housing stock.

-   Filter to only include units that are vacant for rent, vacant for sale, or rented/sold but not yet occupied (`VACANCY %in% c(1:3)`) -- these are the units that are part of the conventional housing market.
-   Derive an estimate of total monthly housing costs for each vacant unit, incorporating mortgage costs, insurance costs, and property taxes.

Note: `ADJUST` standardizes income variables within a calendar year. See here for more information: <https://usa.ipums.org/usa/acsincadj.shtml>.

```{r}
vacancy_microdata = list.files(here(temporary_data_path), full.names = TRUE) %>%
  # keep all file names that match the appropriate geography and one of the data years
  keep(
    ~ str_detect(
        .x, 
        str_c("vacancy_microdata_", 
          str_c("[", paste0(get(str_c(geography, "_years")), collapse = "|"), "]")))) %>%
  # for each filename, read in the data, add the year from the filename,
  # filter to relevant records, calculate a total monthly cost variable,
  # and drop unneeded columns
  map_dfr(
    ~ read_csv(.x) %>% 
      filter(
        VACANCY %in% c(
          1, # for rent
          2, # for sale
          3)) %>% # rented or sold but not yet occupied
      # Convert 9999999 to NA and then multiply by ADJUST for all non-missing observations
      mutate(
        year = YEAR,
        RENT = if_else(RENT == 0, NA, RENT),
        VALUEH = if_else(VALUEH == 9999999, NA, VALUEH * ADJUST),
        loan_amount = 0.9 * VALUEH,
        monthly_mortgage_cost = .005, # monthly interest
        # this calculates monthly compounding interest on a 30-year fixed-rate mortgage
        monthly_principal_interest_cost = loan_amount * monthly_mortgage_cost * 
          ((1 + monthly_mortgage_cost) ** 360) / (((1 + monthly_mortgage_cost) ** 360) - 1),
        # typical annual private mortgage insurance is .007 of loan amount per year
        monthly_private_mortgage_insurance_cost = (.007 * loan_amount) / 12, 
        # taxes assumed to be 25% of monthly principal and interest
        monthly_taxes_cost = .25 * monthly_principal_interest_cost, 
        monthly_cost_total = monthly_principal_interest_cost + 
          monthly_private_mortgage_insurance_cost + monthly_taxes_cost) %>%
      # drop unneeded columns
      select(year, puma, statefip, HHWT, ADJUST, RENT, RENTGRS, VALUEH, monthly_cost_total))
```

`RENTGRS` provides a more comparable estimate of total rental costs than does `RENT`, which may or may not include utilities and fuels. While `RENTGRS` is available for rented units, it is not available for vacant units. To improve the comparability of rental costs for vacant units, we:

-   Calculate the ratio between `RENTGRS` and `RENT` for each rented unit

-   Group by state, geography (county/place), and year, and calculate a weighted average of this `RENTGRS`/`RENT` ratio (weighted by our `HHWT` variable)

-   In a following step, we join these weighted averages back to our vacant unit data and use them to adjust the `RENT` variable

For more information see: [https://usa.ipums.org/usa-action/variables/RENTGRS#description_section](https://usa.ipums.org/usa-action/variables/RENTGRS#description_sectionhttps://usa.ipums.org/usa-action/variables/RENTGRS#description_section)

```{r}
# Import crosswalks to merge PUMAs to places and counties
crosswalk_path = if_else(
  geography == "place", 
  here("geographic-crosswalks", "data", "crosswalk_puma_to_place.csv"),
  here("geographic-crosswalks", "data", "crosswalk_puma_to_county.csv"))

puma_crosswalk = read_csv(crosswalk_path) %>%
  # recode to match 2021 data
  mutate(
    crosswalk_period = if_else(
      crosswalk_period == "pre-2022", "2021", crosswalk_period) %>% as.numeric(),
    GEOID = str_c(statefip, .data[[geography]])) %>%
  # omitting Puerto Rico PUMAs, for which we do not calculate estimates
  filter(statefip != 72)

# Calculate RENTGRS/RENT ratios and associated weighted means by geography for 
# occupied units
rent_ratio = housing_microdata %>%
  # Keep only renter households
  filter(OWNERSHP == 2) %>%
  mutate(
    year = year %>% as.numeric,
    ratio_rentgrs_rent = RENTGRS / RENT) %>% 
  # Calculate weighted mean ratio by geography x year - values are multiplied by 
  # afact in 0_housing_microdata.qmd so summarizing gets the place- or county-level value 
  group_by(statefip, .data[[geography]], year) %>% 
  summarize(
    weighted_mean_ratio_rentgrs_rent = weighted.mean(
      ratio_rentgrs_rent, w = HHWT, na.rm = TRUE)) %>%
  ungroup()

# join places/counties to pumas using the crosswalk
## county-level join summaries - 2021:2022
  # all rows in the vacancy microdata join to the puma crosswalk
  # 32 rows in the crosswalk do not join to the microdata 
  #   (PUMA-years without vacant units, not an issue)
  # all rows in the joint data join to the rent ratio data
  # 2 rows in the rent_ratio data do not join to the joint data 
  #   (these don't have any vacant units, not an issue)
## place-level join summaries - 2021:2022
  # 26050 rows in the vacancy microdata don't join to the crosswalk because these
  #   PUMAs fall outside of places of interest
  # 11 rows in the crosswalk don't join to the vacancy microdata  
  #   (PUMA-years without vacant units, not an issue)
  # all rows in the joint data join to the rent ratio data
  # 1 row in the rent_ratio data does not join to the joint data 
  #   (this place doesn't have any vacant units, not an issue)
vacant_crosswalk = tidylog::left_join(
    vacancy_microdata, 
    puma_crosswalk, 
    by = c("statefip", "puma", "year" = "crosswalk_period"),
    relationship = "many-to-many") %>%
  mutate(
    year = year %>% as.numeric,
    GEOID = str_c(statefip, .data[[geography]])) %>%
  # limit only to places/counties of interest
  filter(GEOID %in% puma_crosswalk$GEOID) %>%
  tidylog::left_join(rent_ratio, by = c("statefip", geography, "year")) %>%
  mutate(
    across(.cols = c(year, statefip, !!geography), .fns = as.character),
    RENTGRS = RENT * weighted_mean_ratio_rentgrs_rent)
```

## Step 3: Import AMI data

HUD publishes annual AMI levels and associated thresholds for 30%, 50%, and 80% of AMI. These levels are available for "Fair Market Rent" (FMR) geographies, which are typically but not always counties.

In this section, we:

-   Import the AMI data from HUD

-   Crosswalk the AMI thresholds to our geographies of interest

```{r}
# Access via https://www.huduser.gov/portal/datasets/il.html#data_2022
urls_fmr_income_limits = c(
  "https://www.huduser.gov/portal/datasets/il/il14/Poverty.xls",
  "https://www.huduser.gov/portal/datasets/il/il15/Section8_Rev.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il16/Section8-FY16.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il17/Section8-FY17.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il18/Section8-FY18.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il19/Section8-FY19.xlsx",
# "https://www.huduser.gov/portal/datasets/il/il21/Section8-FY20.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il21/Section8-FY21.xlsx",
  "https://www.huduser.gov/portal/datasets/il/il22/Section8-FY22.xlsx")

download_hud_income_limits = function(year, url) {
  filename = str_split(url, "/") %>% .[[1]] %>% .[[length(.)]]
  download.file(url = url, destfile = here(temporary_data_path, filename), mode = "wb")

  # Import the data file as a dataframe
  fmr_income_limits = readxl::read_excel(path = here(temporary_data_path, filename)) %>% 
    janitor::clean_names() %>%
    transmute(
      year = year,
      fips = fips2010,
      across(
        .cols = c(state, county), 
        .fns = as.character),
      state = str_pad(state, side = "left", width = 2, pad = "0"), 
      county = str_pad(county, side = "left", width = 3, pad = "0"),
      sub_county = str_sub(fips, 6, 10) %>% if_else(. == "99999", NA, .),
      # _4 denotes the level applies to a four-person household
      # ELI_4 is 30% of median rent: Extremely low-income
      # l50_4 is 50% of median rent: Very low-income
      # l80_4 is 80% of median rent: Low-income
      level_30ami = eli_4,
      level_50ami = l50_4,
      level_80ami = l80_4)
  
  return(fmr_income_limits)
}

# download and combine income limits data into one file
fmr_income_limits = map2_dfr(
    county_years, urls_fmr_income_limits[7:8], 
    download_hud_income_limits) %>%
  filter(year %in% c(county_years, place_years))
```

Income limits are specified at one of two geographies: the county (mostly), or the sub-county (in some areas in New England). We need to translate the income limits to our geography of interest (either the county-level or the place-level). We do this as follows:

-   We aggregate our income limits to the county level. For most counties, this doesn't require any work, because there's only a single income limit for the county. For counties with sub-county-level income limits, we take the mean of these limits.

-   For the case where we're producing place-level estimates, we then interpolate the county-level income limits to the place level, weighting by population.

```{r}
county_income_limits1 = fmr_income_limits %>%
  group_by(year, state, county) %>%
  summarize(
    across(
      .cols = matches("ami"),
      .fns = mean)) %>%
  ungroup()
  
geography_pad_width = if_else(geography == "place", 5, 3)

county_income_limits2 = county_income_limits1 %>%
  transmute(
    county,
    GEOID = str_c(state, county),
    statefip = state,
    # "{geography}" := str_pad(
    #   as.numeric(.data[[geography]]), side = "left", width = geography_pad_width, pad = "0"),
    year,
    across(.cols = matches("ami"))) %>%
  filter(!str_detect(statefip, "^72"))

## in 2017, Valdez-Cordova Census Area -- a county-equivalent geography -- is abolished
## and is replaced by Chugach Census Area and Copper River Census Area, both of which
## are also county-equivalent geographies. While Valdez-Cordova is listed in the HUD
## AMI limits data, our ACS microdata are crosswalked to the current Census Areas.
## Accordingly, we adjust our income limits data such that the AMI thresholds for 
## Valdez-Cordova are associated both with Chugach and Copper River Census Areas.

county_income_limits3 = tibble(
  county_current = c("063", "066"),
  county_old = c("261")) %>%
  left_join(
    county_income_limits2 %>%
      filter(statefip == "02"),
    by = c("county_old" = "county"),
    relationship = "many-to-many") %>%
  select(-county_old) %>%
  rename(county = county_current) %>%
  mutate(GEOID = str_c(statefip, county))
  
county_income_limits = county_income_limits2 %>%  
  filter(!(statefip == "02" & county == "261")) %>%
  bind_rows(county_income_limits3) %>%
  rename(state = statefip) %>%
  # american samoa, guam, northern mariana islands, virgin islands
  filter(!state %in% c("60", "66", "69", "78")) %>%
  mutate(across(.cols = c(state, county, year), .fns = as.character))

if (geography == "place") {
  county_place_crosswalk = read_csv(
      here("geographic-crosswalks", "data", "geocorr2022_county_place.csv")) %>% 
    mutate(
      state = str_pad(as.numeric(state), side = "left", width = 2, pad = "0"),
      place = str_pad(as.numeric(place), side = "left", width = 5, pad = "0"))
  
  ## place-level join summaries - 2021:2022
  # 1 row only in county_income_limits - 29056 - but this isn't a valid county FIPS code
  # 0 rows only in county_place crosswalk
  place_income_limits = county_income_limits %>%
    tidylog::left_join(county_place_crosswalk, by = c("state", "county")) %>%
    group_by(state, place, year) %>%
    summarize(
      across(
        .cols = matches("ami"),
        .fns = ~ weighted.mean(x = .x, na.rm = TRUE, w = pop20))) %>%
    ungroup() %>%
    mutate(
      across(.cols = c(state, place, year), .fns = as.character),
      GEOID = str_c(state, place))
  
  crosswalked_income_limits = place_income_limits
} else { crosswalked_income_limits = county_income_limits }
```

## Step 4: Generate AMI indicators

Here we calculate which units are affordable for a family of four at 80%, 50%, and 30% of AMI (regardless of the actual unit size). We also create variables for total population at 80% AMI, 50% AMI, and 30% AMI, including breakdowns for renter and owner subgroups. "Affordable" means costs are \<= 30% of the household's income. For owners, we use the housing cost, and for renters, we use the gross rent.

```{r}
## these are data on occupied housing units
## county-level join summaries - 2021:2022
  # 0 rows only in housing_microdata 
  # 1 rows only in crosswalked_income_limits -- a nonexistent county in Missouri
household_affordability = tidylog::left_join(
    housing_microdata, 
    crosswalked_income_limits, 
    by = c("statefip" = "state", geography, "year"),
    relationship = "many-to-one") %>%
  mutate(
    ## all households below ami levels
    across(
      .cols = matches("ami$"),
      # Note: I (Will) have changed this logic to be inclusive of the AMI threshold;
      # previously, I think such values would have defaulted to NAs (an error) 
      .fns = ~ if_else(HHINCOME <= .x, 1, 0),
      .names = "all_below_{.col %>% stringr::str_extract('[0-9]{2}ami')}"),
    ## renters below ami levels
    across(
      .cols = c(all_below_80ami, all_below_50ami, all_below_30ami),
      .fns = ~ if_else(.x == 1 & OWNERSHP == 2, 1, 0),
      .names = "renter_{.col %>% stringr::str_remove('all_')}"),
    ## owners below ami levels
    across(
      .cols = c(all_below_80ami, all_below_50ami, all_below_30ami),
      .fns = ~ if_else(.x == 1 & OWNERSHP == 1, 1, 0),
      .names = "owner_{.col %>% stringr::str_remove('all_')}"),
    ## this standardized cost variable simplifies subsequent calculations
    applicable_housing_cost = if_else(OWNERSHP == 2, RENTGRS, OWNCOST),
    ## renter households with affordable housing costs
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        OWNERSHP == 1 ~ NA, ## if it is a owner-occupied household, return NA
        RENTGRS == 0 ~ 99999999999,
        OWNERSHP == 2 & applicable_housing_cost * 12 <= .x * .3 ~ 1,
        TRUE ~ 0), 
      .names = "renter_affordable_{.col}"),
    ## owner households with affordable housing costs
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        OWNERSHP == 2 ~ NA, ## if it is a renter-occupied household, return NA
        OWNERSHP == 1 & applicable_housing_cost * 12 <= .x * .3 ~ 1,
        OWNERSHP == 1 & !is.na(applicable_housing_cost) ~ 0,
        is.na(applicable_housing_cost) ~ 99999999999), 
      .names = "owner_affordable_{.col}"),
    ## any households with affordable housing costs
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ if_else(
        !is.na(applicable_housing_cost) & applicable_housing_cost * 12 <= .x * .3, 
        1, 
        0), 
      .names = "all_affordable_{.col}"),
    ## calculating affordable and available across all subgroups (and overall)
    across(
      .cols = matches("affordable"), # e.g., all_affordable_level_80ami
      # if the unit is affordable at the given AMI level and is occupied by a household 
      # at or below that AMI level
      .fns = ~ if_else(
        .x == 1 & get(str_replace(cur_column(), "affordable_level", "below")) == 1, 1, 0),
      .names = "{.col %>% stringr::str_replace('affordable', 'available')}"))

## we check that no rows have this error placeholder value (none should)
stopifnot(
  household_affordability %>%
    filter(if_any(.cols = everything(), .fn = ~ .x == 99999999999)) %>%
    nrow == 0)
```

```{r}
## these are data on vacant housing units
## county-level join summaries - 2021:2022
  # 0 rows only in vacant_microdata 
  # 3 rows only in crosswalked_income_limits -- these areas don't have any vacant 
  #   units (no issue)
vacant_affordability = tidylog::left_join(
    vacant_crosswalk, 
    crosswalked_income_limits, 
    by = c("statefip" = "state", geography, "year"),
    relationship = "many-to-one") %>%
  mutate(
    ## binary indicators 
    ## for rental units, if adjusted annual rent is less than or equal to the given 
      ## AMI level
    ## for ownership units, if estimated annual housing cost is less than or equal
      ## to the given AMI level for all units
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        RENTGRS > 0 ~ (RENTGRS * 12) <= (.x * .3),
        !is.na(VALUEH) ~ (monthly_cost_total * 12) <= (.x * .3), 
        is.na(VALUEH) ~ NA),
      .names = "all_affordable_{.col}"),
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        RENTGRS > 0 ~ (RENTGRS * 12) <= (.x * .3)),
      .names = "renter_affordable_{.col}"),
    across(
      .cols = c(level_30ami, level_50ami, level_80ami),
      .fns = ~ case_when(
        is.na(.x) ~ NA,
        !is.na(VALUEH) ~ (monthly_cost_total * 12) <= (.x * .3), 
        is.na(VALUEH) ~ NA),
      .names = "owner_affordable_{.col}"),
    # convert booleans to integers
    across(matches("affordable"), ~ as.integer(.x)))
```

## Step 5: Aggregate and calculate metrics

```{r}
household_affordability_summed = household_affordability %>% 
  group_by(statefip, .data[[geography]], year) %>%
  summarize( 
    # get unweighted counts for quality flags, adjusting for spatial interpolation using afact
    across(
      .cols = matches("below"), 
      .fns = ~ sum(.x * afact),
      .names = "{.col}_quality"),
    # get weighted counts for actual statistics/estimates
    across(
      .cols = c(matches("below|affordable|available"), -matches("quality")), 
      .fns = ~ sum(.x * HHWT, na.rm = TRUE))) %>% 
  ungroup() %>%
  rename("state" = "statefip")

vacant_affordability_summed = vacant_affordability %>% 
  group_by(statefip, .data[[geography]], year) %>%
  summarize(
    across(
      .cols = matches("affordable"), 
      .fns = ~ sum(.x * HHWT, na.rm = TRUE), 
      .names = "{.col}_vacant")) %>% 
  ungroup() %>%
  rename("state" = "statefip")

## here we (finally) combine our occupied and vacant data
## county-level join summaries - 2021:2022
  # 2 rows only in household_affordability_summed -- these areas don't have any 
  #   vacant units (no issue)
  # 0 rows only in vacant_affordability_summed
housing_summed = tidylog::left_join(
    household_affordability_summed, 
    vacant_affordability_summed, 
    by = c("state", geography, "year"),
    relationship = "one-to-one") %>% 
  ungroup() %>%
  mutate(
    ## share affordable and available
    across(
      .cols = matches("available"),
      # available and affordable occupied units + all vacant units (by definition 
      # available) / all affordable units
      .fns = ~ (
        .x + ## available, occupied units
        ## vacant units
        get(str_c(cur_column() %>% str_replace("available", "affordable"), "_vacant"))) / 
        ## households at or below income level
        get(str_replace(cur_column(), "available_level", "below")), 
      .names = "share_{.col}"),
    ## all households
    ## the sum of housing units -- both vacant and occupied -- that are affordable
    ## at a given AMI level divided by the number of households below that AMI level
    across(
      .cols = c(matches("below"), -matches("quality")),
      .fns = ~ 
        (get(str_c(str_replace(cur_column(), "below", "affordable_level"))) +
        get(str_c(str_replace(cur_column(), "below", "affordable_level"), "_vacant"))) / .x,
      .names = "share_{.col %>% stringr::str_replace('below', 'affordable_level')}")) 
```

## Step 6: Finalize and export data

If the unweighted sum of interpolated households (reflected in `afact`) is under 30, we suppress that cell because it is likely to be highly unreliable.

```{r}
# read in the puma interpolation quality files, which are calculated in 
# 02_get_housing_microdata.R. these contain `puma_flag`, which provides a score
# from 1-3 describing the mean geographic allocation quality for each 
puma_interpolation_quality = bind_rows(
  read_csv(here(
    temporary_data_path, paste0("crosswalked_pumas_quality_", geography, "_2021.csv"))) %>% 
    mutate(year = "2021"), 
  read_csv(here(
    temporary_data_path, paste0("crosswalked_pumas_quality_", geography, "_2022.csv"))) %>% 
    mutate(year = "2022")) %>%
  rename("state" = "statefip")

# combine minimum cell size standards (n = 30) with the puma interpolation quality 
# scores to assign each cell a quality flag
## county-level join summaries - 2021:2022
  # 0 rows only in housing_summed
  # 0 rows only in puma_interpolation_quality
housing_summed_quality =  tidylog::left_join(
    housing_summed,
    puma_interpolation_quality, 
    by = c("state", geography, "year"),
    relationship = "one-to-one") %>%
  mutate(
    ## if there are fewer than 30 unweighted observations, assign the quality variable 
    ## a score of one
    across(
      .cols = matches("quality"),
      .fns = ~ if_else(.x < 30, 1, 0)),
    ## if the quality score is 1, suppress the data (set the cell to NA), otherwise
    ## assign the quality variable the value of the mean geographic allocation quality 
    ## variable 
    across(
      .cols = matches("quality"), 
      .fns = ~ if_else(.x == 1, NA, puma_flag)))

# turn long for subgroup output
housing_subgroups = housing_summed_quality %>%
  select(state, !!geography, year, matches("share|quality")) %>% 
  ## rename columns to facilitate re-structuring
  rename_with(
    .cols = matches("quality"),
    .fn = ~ .x %>% str_remove("_quality") %>% 
      str_replace("below", "affordable_quality_level") %>% str_c("share_", .)) %>% 
  ## the quality values are the same for available and affordable, but we duplicate them
  ## (with different column names) for the available estimates, for consistency
  mutate(
    across(
      .cols = matches("quality"),
      .fns = ~ .x,
      .names = "{.col %>% stringr::str_replace('affordable', 'available')}")) %>% 
  ## restructure so that each row is a geography x year x subgroup combination
  pivot_longer(
    cols = matches("share_"), 
    names_to = c("subgroup", "measure_type", "ami"),
    names_pattern = "share_(all|renter|owner)_(affordable_|affordable_quality_|available_|available_quality_)level_([0-9]{2}ami)",
    values_to = "value") %>%
  pivot_wider(
    names_from = c(measure_type, ami),
    names_sep = "", 
    values_from = value) %>%
  ## convert from "share" to "ratio" in metric names; these are not shares, they're ratios
  rename_with(
    .cols = matches("affordable|available"), 
    .fn = ~ str_c("ratio_", .x)) %>%
  mutate(
    subgroup_type = "tenure",
    subgroup = subgroup %>% str_to_sentence,
    # suppress cells with insufficient quality scores
    across(
      .cols = c(matches("ratio"), -matches("quality")), 
      .fns = ~ if_else(
        is.na(get(cur_column() %>% str_replace_all(
          c("affordable" = "affordable_quality", "available" = "available_quality")))), 
        NA, 
        .x))) %>%
  ## clean up variable names slightly and reorder columns for export
  rename_with(
    .cols = matches("quality"),
    .fn = ~ str_remove(.x, "quality_") %>% str_c(., "_quality")) %>%
  ## if the metric is missing, set the corresponding quality variable to missing
  mutate(
    across(
      .cols = matches("quality"), 
      .fns = ~ if_else(is.na(get(cur_column() %>% str_remove("_quality"))), NA, .x))) %>%
  select(year, state, !!geography, subgroup_type, subgroup, matches("ratio")) %>%
  arrange(state, .data[[geography]], subgroup, desc(year))

housing_overall = housing_subgroups %>% 
  filter(subgroup == "All")

years = if_else(
  geography == "county", 
  paste0(county_years, collapse = "_"), 
  paste0(place_years, collapse = "_"))

# export the final data
write_csv(
  housing_overall, 
  here("02_housing", "data", "final", str_c("housing_", geography, "_", years, ".csv")))
write_csv(
  housing_subgroups, 
  here("02_housing", "data", "final", str_c("housing_", geography, "_", years, "_subgroups.csv")))
```

## Step 7: Conduct quality checks

The final dataset, including all subgroups, meets all the assertions contained in `evaluate_final_data.R`.
```{r}
test_that(
  "The final data passes standardized QC checks", {
    expect_no_error(
      evaluate_final_data(
        exp_form_path = here(
          "02_housing", "housing_affordability_tenure_final_data_evaluation_form.csv"),
        data = housing_subgroups,
        geography = geography,
        subgroups = TRUE,
        confidence_intervals = FALSE))})
```
### Data descriptions (not assertions)

Missingness 

We anticipate that county-level data will have greater missingness than place-level 
data as there are many counties with very small populations, whereas our places 
are by definition reasonably large. We also anticipate that subgroup metrics have 
greater missingness as compared to our overarching metrics because they rely on 
subsets of the total population of households.

```{r}
housing_subgroups %>% 
  group_by(year) %>%
  select(c(matches("ratio"), -matches("quality"))) %>%
  summarize(across(everything(), ~ round(sum(is.na(.)) / n() * 100, 0)))
```

Distributions

We anticipate the the distributions for a given metric will be similar across years,
and that the peaks of distributions will be progressively lower for lower AMI levels.

```{r}
housing_subgroups %>% 
  select(c(subgroup, matches("ratio"), -matches("quality"))) %>%
  pivot_longer(-subgroup) %>%
  filter(str_detect(name, "affordable")) %>%
  mutate(name = name %>% str_replace_all("_", " ") %>% str_to_sentence()) %>%
  ggplot() +
    geom_histogram(aes(x = value, fill = subgroup)) +
    facet_wrap(~ name) +
    labs(title = "Distribution of affordable ratios, by subgroup", y = "Frequency", x = "Ratio") +
    scale_y_continuous(labels = scales::comma) +
    theme_urbn_print()

housing_subgroups %>% 
  select(c(subgroup, matches("ratio"), -matches("quality"))) %>%
  pivot_longer(-subgroup) %>%
  filter(str_detect(name, "available")) %>%
  mutate(name = name %>% str_replace_all("_", " ") %>% str_to_sentence()) %>%
  ggplot() +
    geom_histogram(aes(x = value, fill = subgroup)) +
    facet_wrap(~ name) +
    labs(title = "Distribution of available ratios, by subgroup", y = "Frequency", x = "Ratio") +
    scale_y_continuous(labels = scales::comma) +
    theme_urbn_print()
```


The counts of observations align with expected counts for each geography for each year.
```{r}
population_universe = read_csv(here("geographic-crosswalks", "data", paste0(geography, "-populations.csv"))) %>%
  mutate(
    year = as.character(year),
    geoid = str_c(state, .data[[geography]])) %>%
  group_by(year) %>%
  summarize(population_count = n_distinct(geoid))
# 
# ## This fails because of South Fulton missing from 
# test_that(
#   "Counts of places/counties are correct for each year", {
#   expect_true(
#     all(
#       housing_subgroups %>%
#         group_by(year, subgroup) %>%
#         summarize(
#           geography_count = n_distinct(state, .data[[geography]])) %>%
#         tidylog::left_join(population_universe, by = "year") %>%
#         mutate(check = population_count == geography_count) %>% 
#         pull(check)))})
```

Both metrics are ratios and cannot be negative. We extend the assumption and assert that no ratios are equal to zero, which mathematically is feasible but practically is highly unlikely.
```{r}
test_that(
  "No ratios are negative or zero", {
  expect_true(
    housing_overall %>%
      filter(if_any(.cols = c(matches("ratio"), -matches("quality")), .fns = ~ .x <= 0)) %>%
      nrow() == 0)})
```

Affordable-and-available ratios by definition must be equal to or lesser than the corresponding affordable ratio.
```{r}
test_that(
  "Affordable-and-available ratios are less than or equal to affordable ratios", {
  expect_true(
    housing_overall %>%
      select(-matches("quality")) %>%
      mutate(
        across(
          .cols = c(matches("ratio_affordable"), ),
          .fns = ~ .x - get(str_replace(cur_column(), "affordable", "available")),
          .names = "{.col}_difference")) %>%
      arrange(ratio_affordable_80ami_difference) %>%
      filter(if_any(.cols = matches("difference"), .fns = ~ .x < 0)) %>% 
      nrow() == 0)})
```

Unless substantive changes have been made to the process of calculating the metrics, every metric value for every geography calculated during the current cycle should be exactly the same as the value calculated during the preceding year.
```{r}
## data are available from this URL: https://datacatalog.urban.org/dataset/mobility-metrics-data-upward-mobility-framework
## specific links used in the code will likely need to be updated year-to-year

# if (geography == "place") {
#   metrics_prior1 = read_csv(
#     ## this corresponds to longitudinal, place-level metrics that are broken down by tenure
#     "https://urban-data-catalog.s3.amazonaws.com/drupal-root-live/2024/09/67_mobility-metrics_place_tenure_longitudinal.csv")
# } else {
#     metrics_prior1 = read_csv(
#     ## this corresponds to longitudinal, place-level metrics that are broken down by tenure
#     "https://urban-data-catalog.s3.amazonaws.com/drupal-root-live/2024/09/17_mobility-metrics_county_tenure_longitudinal.csv")
# }
#   
# metrics_prior = metrics_prior1 %>%
#   select(
#     state, state_name, year, any_of(c("place", "place_name", "county", "county_name")), 
#     subgroup, subgroup_type, share_affordable_80_ami, share_affordable_50_ami, 
#     share_affordable_30_ami, share_affordable_available_80_ami, share_affordable_available_50_ami, 
#     share_affordable_available_30_ami) %>%
#   ## just looking at the subgroups; if they pass these tests, then the "All" subgroup
#   ## should as well
#   filter(year %in% c(place_years, county_years), subgroup != "All") %>%
#   rename_with(
#     .cols = matches("share"), 
#     .fn = ~ str_replace_all(
#       .x, c("share" = "ratio", "affordable_available" = "available", "_ami" = "ami")) %>% str_c("_prior")) %>%
#   mutate(year = as.character(year))
# 
# test_that(
#   "Values produced for the most recent year's data, using the current year's codebase,
#   are the same as those produced the prior year", {
#   expect_true(
#     metrics_prior %>%
#       tidylog::left_join(
#         housing_subgroups %>%
#           mutate(subgroup = subgroup %>% str_to_sentence) %>%
#           select(-subgroup_type, -matches("quality")),
#         by = c("state", geography, "year", "subgroup")) %>%
#       transmute(
#         year,
#         state,
#         !!geography,
#         across(
#           .cols = matches("prior"),
#           .fns = ~ if_else(.x != get(cur_column() %>% str_remove("_prior")), 1, 0))) %>%
#       summarize(across(matches("prior"), ~ sum(.x, na.rm = TRUE))) %>%
#       pivot_longer(everything()) %>%
#       pull(value) %>%
#       max() == 0)
#   })
```

Metrics generally should not exhibit huge year-over-year changes within the same geography (or across geographies). We expect that:

-   The distribution of year-over-year changes in the 80% AMI ratios should show the least variation.

-   Conversely, the 30% AMI ratios should show the most variation because this AMI threshold encompasses fewer households and housing units, leading to greater percentage variability year-over-year.
```{r, fig.height = 5, fig.width = 8}
housing_subgroups %>%
  select(-matches("quality")) %>%
  pivot_longer(cols = c(matches("ratio"), )) %>%
  pivot_wider(names_from = year, values_from = value, names_prefix = "value_") %>%
  mutate(percent_annual_change = (value_2022 - value_2021) / value_2021 * 100) %>%
  arrange(desc(percent_annual_change)) %>%
  ggplot() +
    geom_histogram(aes(x = percent_annual_change, fill = subgroup)) +
    facet_wrap(~ name) +
    urbnthemes::theme_urbn_print() +
  labs(
    x = "Percent annual change in metric",
    y = "Count",
    title = "Metrics should show relatively little year-over-year variation with distributions clustered around 0%",
    subtitle = "Distributions of year-over-year changes in housing affordability and availability metrics, by AMI level and subgroup")
```

Estimates should generally align with estimates produced by NLIHC as part of their "The GAP" series.
```{r}
## data from: https://nlihc.org/gap#summary-table
## data vintage: 2022 PUMS (per NLIHC)

nlihc_estimates = data <- tibble::tribble(
  ~state, ~eli_households, ~affordable_available_per_100_eli_renter_households, ~eli_renter_households_severe_cost_burden,
  "Alabama", 186962, 50, "70%",
  "Alaska", 19545, 25, "64%",
  "Arizona", 176191, 24, "79%",
  "Arkansas", 115342, 50, "69%",
  "California", 1282835, 24, "77%",
  "Colorado", 164750, 27, "76%",
  "Connecticut", 149475, 34, "71%",
  "Delaware", 25328, 36, "66%",
  "District of Columbia", 50011, 33, "75%",
  "Florida", 583625, 25, "82%",
  "Georgia", 325237, 34, "78%",
  "Hawaii", 40077, 34, "71%",
  "Idaho", 36607, 42, "70%",
  "Illinois", 451737, 36, "74%",
  "Indiana", 209710, 34, "76%",
  "Iowa", 101442, 42, "67%",
  "Kansas", 87991, 41, "73%",
  "Kentucky", 166739, 47, "66%",
  "Louisiana", 183322, 41, "71%",
  "Maine", 36378, 51, "63%",
  "Maryland", 197310, 32, "73%",
  "Massachusetts", 316201, 46, "64%",
  "Michigan", 299020, 37, "71%",
  "Minnesota", 173025, 34, "69%",
  "Mississippi", 108951, 55, "65%",
  "Missouri", 205433, 42, "70%",
  "Montana", 28830, 42, "69%",
  "Nebraska", 67077, 33, "73%",
  "Nevada", 91243, 14, "86%",
  "New Hampshire", 34277, 38, "64%",
  "New Jersey", 306253, 30, "74%",
  "New Mexico", 68160, 40, "70%",
  "New York", 1004253, 34, "74%",
  "North Carolina", 326751, 40, "71%",
  "North Dakota", 30401, 47, "71%",
  "Ohio", 444768, 40, "70%",
  "Oklahoma", 133048, 42, "71%",
  "Oregon", 138104, 26, "78%",
  "Pennsylvania", 447362, 41, "72%",
  "Rhode Island", 49468, 51, "56%",
  "South Carolina", 150598, 41, "73%",
  "South Dakota", 26953, 57, "51%",
  "Tennessee", 209536, 42, "70%",
  "Texas", 906885, 25, "79%",
  "Utah", 62625, 31, "75%",
  "Vermont", 17450, 30, "74%",
  "Virginia", 263914, 30, "76%",
  "Washington", 237903, 28, "75%",
  "West Virginia", 63660, 53, "66%",
  "Wisconsin", 186679, 34, "72%",
  "Wyoming", 18176, 51, "63%") %>%
  left_join(tidycensus::fips_codes %>% select(state_name, state_code) %>% distinct(), by = c("state" = "state_name"))

housing_subgroups %>% 
  filter(year == 2022, subgroup == "Renter") %>%
  select(state, ratio_available_30ami) %>%
  group_by(state) %>%
  summarize(
    total_count = n(),
    valid_count = sum(!is.na(ratio_available_30ami)),
    mean_ratio_state = round(mean(ratio_available_30ami, na.rm = TRUE) * 100, digits = 0)) %>%
  left_join(nlihc_estimates, by = c("state" = "state_code")) %>%
  mutate(
    percent_valid = round(valid_count / total_count * 100, digits = 0),
    difference = mean_ratio_state - affordable_available_per_100_eli_renter_households) %>%
  select(state_name = state.y, difference, percent_valid,  mean_ratio_state, affordable_available_per_100_eli_renter_households) %>%
  arrange(desc(abs(difference))) %>%
  ggplot() +
  geom_point(aes(x = abs(difference), y = percent_valid, color = difference, size = abs(difference))) +
  theme_urbn_print() +
  guides(color = FALSE, size = FALSE) +
  labs(
    title = "Urban vs. NLIHC estimates of affordable and available rental units to renters at 30% AMI",
    subtitle = str_c(
      "Owing to difference in geographic units of analysis (and associated suppression), some differences are expected. ",
      "Generally, we expect states with fewer valid Urban estimates to have greater differences relative to NLIHC estimates.") %>% str_wrap(120),
    x = "Absolute difference between state average of Urban estimates and NLIHC estimate", 
    y = "Percent of geographies with valid Urban estimates")
```
